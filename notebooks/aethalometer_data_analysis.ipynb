{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5278ce",
   "metadata": {},
   "source": [
    "# Aethalometer Data Analysis\n",
    "## Sample Analysis Using the Modular Aethalometer System\n",
    "\n",
    "This notebook demonstrates how to load and analyze aethalometer data using the modular system. We'll be working with a pickle file containing merged cleaned and uncleaned MA350 data.\n",
    "\n",
    "**Data Source:** `df_uncleaned_Jacros_API_and_OG.pkl`\n",
    "\n",
    "### Features demonstrated:\n",
    "- Data loading using the AethalometerPKLLoader\n",
    "- Basic data inspection and statistics\n",
    "- Time series visualization\n",
    "- Source apportionment analysis\n",
    "- Quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b46a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaders imported successfully\n",
      "‚úÖ Black Carbon analyzer imported successfully\n",
      "‚úÖ Source Apportionment analyzer imported successfully\n",
      "‚úÖ Plotting utilities imported successfully\n",
      "‚úÖ Plotting style configured successfully\n",
      "‚úÖ File I/O utilities imported successfully\n",
      "\n",
      "‚úÖ All available libraries imported successfully!\n",
      "üìä Modular aethalometer analysis system ready!\n",
      "üìÅ Working directory: /Users/ahzs645/Github/aethmodular/notebooks\n",
      "üîó Source path added: /Users/ahzs645/Github/aethmodular/src\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "src_path = str(Path('../src').resolve())\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import modular system components\n",
    "try:\n",
    "    from data.loaders.aethalometer import AethalometerPKLLoader, load_aethalometer_data\n",
    "    print(\"‚úÖ Data loaders imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Data loaders import error: {e}\")\n",
    "\n",
    "try:\n",
    "    from analysis.bc.black_carbon_analyzer import BlackCarbonAnalyzer\n",
    "    print(\"‚úÖ Black Carbon analyzer imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Black Carbon analyzer import error: {e}\")\n",
    "    BlackCarbonAnalyzer = None\n",
    "\n",
    "try:\n",
    "    from analysis.bc.source_apportionment import SourceApportionmentAnalyzer\n",
    "    print(\"‚úÖ Source Apportionment analyzer imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Source Apportionment analyzer import error: {e}\")\n",
    "    SourceApportionmentAnalyzer = None\n",
    "\n",
    "try:\n",
    "    from utils.plotting import AethalometerPlotter\n",
    "    print(\"‚úÖ Plotting utilities imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Plotting utilities import error: {e}\")\n",
    "    AethalometerPlotter = None\n",
    "\n",
    "try:\n",
    "    from config.plotting import setup_plotting_style\n",
    "    setup_plotting_style()\n",
    "    print(\"‚úÖ Plotting style configured successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Plotting config import error: {e}\")\n",
    "    # Fallback plotting style\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(\"husl\")\n",
    "\n",
    "try:\n",
    "    from utils.file_io import ensure_output_directory\n",
    "    print(\"‚úÖ File I/O utilities imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è File I/O utilities import error: {e}\")\n",
    "    # Create a simple fallback function\n",
    "    def ensure_output_directory(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Setup plotting style\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"\\n‚úÖ All available libraries imported successfully!\")\n",
    "print(\"üìä Modular aethalometer analysis system ready!\")\n",
    "print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
    "print(f\"üîó Source path added: {src_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697578af",
   "metadata": {},
   "source": [
    "## 1. Load the Pickle DataFrame\n",
    "\n",
    "We'll load the aethalometer data from the specified pickle file using both direct pandas loading and the modular system's AethalometerPKLLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f4690a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading data from: df_uncleaned_Jacros_API_and_OG.pkl\n",
      "üìç Full path: /Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Kyan Data/Mergedcleaned and uncleaned MA350 data20250707030704/df_uncleaned_Jacros_API_and_OG.pkl\n",
      "‚úÖ Successfully loaded with pandas: 1665156 rows\n",
      "‚úÖ Successfully loaded with pandas: 1665156 rows\n",
      "Detected format: standard\n",
      "Warning: Missing recommended columns: ['Biomass BCc', 'Fossil fuel BCc']\n",
      "Detected format: standard\n",
      "Warning: Missing recommended columns: ['Biomass BCc', 'Fossil fuel BCc']\n",
      "\n",
      "üìä Data Summary from AethalometerPKLLoader:\n",
      "   total_samples: 1665156\n",
      "   format_type: standard\n",
      "   file_path: /Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Kyan Data/Mergedcleaned and uncleaned MA350 data20250707030704/df_uncleaned_Jacros_API_and_OG.pkl\n",
      "   earliest_date: 2021-01-09 16:38:00\n",
      "   latest_date: 2025-06-26 23:18:00\n",
      "   datetime_column: datetime_local\n",
      "   bc_data_availability: {'Blue BC1': np.int64(1593671), 'Blue BCc': np.int64(1593671), 'Green BC1': np.int64(1593671), 'Green BCc': np.int64(1593671), 'IR BC1': np.int64(1593671)}\n",
      "\n",
      "üìä Data Summary from AethalometerPKLLoader:\n",
      "   total_samples: 1665156\n",
      "   format_type: standard\n",
      "   file_path: /Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Kyan Data/Mergedcleaned and uncleaned MA350 data20250707030704/df_uncleaned_Jacros_API_and_OG.pkl\n",
      "   earliest_date: 2021-01-09 16:38:00\n",
      "   latest_date: 2025-06-26 23:18:00\n",
      "   datetime_column: datetime_local\n",
      "   bc_data_availability: {'Blue BC1': np.int64(1593671), 'Blue BCc': np.int64(1593671), 'Green BC1': np.int64(1593671), 'Green BCc': np.int64(1593671), 'IR BC1': np.int64(1593671)}\n",
      "Detected format: standard\n",
      "Warning: Missing recommended columns: ['Biomass BCc', 'Fossil fuel BCc']\n",
      "‚úÖ Successfully loaded with modular system: 1665156 rows\n",
      "\n",
      "üéØ Working with DataFrame: 1665156 rows √ó 239 columns\n",
      "Detected format: standard\n",
      "Warning: Missing recommended columns: ['Biomass BCc', 'Fossil fuel BCc']\n",
      "‚úÖ Successfully loaded with modular system: 1665156 rows\n",
      "\n",
      "üéØ Working with DataFrame: 1665156 rows √ó 239 columns\n"
     ]
    }
   ],
   "source": [
    "# Define the data file path\n",
    "data_path = \"/Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Kyan Data/Mergedcleaned and uncleaned MA350 data20250707030704/df_uncleaned_Jacros_API_and_OG.pkl\"\n",
    "\n",
    "print(f\"üìÅ Loading data from: {Path(data_path).name}\")\n",
    "print(f\"üìç Full path: {data_path}\")\n",
    "\n",
    "# Method 1: Direct pandas loading\n",
    "try:\n",
    "    df_direct = pd.read_pickle(data_path)\n",
    "    print(f\"‚úÖ Successfully loaded with pandas: {len(df_direct)} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading with pandas: {e}\")\n",
    "    df_direct = None\n",
    "\n",
    "# Method 2: Using the modular system's AethalometerPKLLoader\n",
    "try:\n",
    "    loader = AethalometerPKLLoader(data_path, format_type=\"auto\")\n",
    "    \n",
    "    # Get data summary\n",
    "    summary = loader.get_data_summary()\n",
    "    print(f\"\\nüìä Data Summary from AethalometerPKLLoader:\")\n",
    "    for key, value in summary.items():\n",
    "        if key != 'columns':\n",
    "            print(f\"   {key}: {value}\")\n",
    "    \n",
    "    # Load the data\n",
    "    df_modular = loader.load(convert_to_jpl=False)\n",
    "    print(f\"‚úÖ Successfully loaded with modular system: {len(df_modular)} rows\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading with modular system: {e}\")\n",
    "    df_modular = None\n",
    "\n",
    "# Use whichever method worked\n",
    "df = df_direct if df_direct is not None else df_modular\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\nüéØ Working with DataFrame: {len(df)} rows √ó {len(df.columns)} columns\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to load data with both methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa94c82",
   "metadata": {},
   "source": [
    "## 2. Display DataFrame Information\n",
    "\n",
    "Let's examine the structure of our data, including column names, data types, and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üìä DATAFRAME INFORMATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Index type: {type(df.index).__name__}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Display DataFrame info\n",
    "    print(\"\\nüîç DataFrame Info:\")\n",
    "    df.info()\n",
    "    \n",
    "    # Check for datetime columns\n",
    "    print(f\"\\nüìÖ Index range:\")\n",
    "    if hasattr(df.index, 'min') and hasattr(df.index, 'max'):\n",
    "        try:\n",
    "            print(f\"   From: {df.index.min()}\")\n",
    "            print(f\"   To: {df.index.max()}\")\n",
    "            print(f\"   Duration: {df.index.max() - df.index.min()}\")\n",
    "        except:\n",
    "            print(f\"   Index range: {df.index[0]} to {df.index[-1]}\")\n",
    "    \n",
    "    # Column overview\n",
    "    print(f\"\\nüìã Column Categories:\")\n",
    "    bc_cols = [col for col in df.columns if 'BC' in str(col).upper()]\n",
    "    atn_cols = [col for col in df.columns if 'ATN' in str(col).upper()]\n",
    "    flow_cols = [col for col in df.columns if 'flow' in str(col).lower()]\n",
    "    \n",
    "    print(f\"   Black Carbon columns: {len(bc_cols)}\")\n",
    "    print(f\"   Attenuation columns: {len(atn_cols)}\")\n",
    "    print(f\"   Flow columns: {len(flow_cols)}\")\n",
    "    print(f\"   Other columns: {len(df.columns) - len(bc_cols) - len(atn_cols) - len(flow_cols)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available to display information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f26ebfd",
   "metadata": {},
   "source": [
    "## 3. Preview DataFrame Contents\n",
    "\n",
    "Let's look at the first and last few rows to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807325e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üîç FIRST 5 ROWS\")\n",
    "    print(\"=\" * 50)\n",
    "    display(df.head())\n",
    "    \n",
    "    print(f\"\\nüîç LAST 5 ROWS\")\n",
    "    print(\"=\" * 50)\n",
    "    display(df.tail())\n",
    "    \n",
    "    # Show key columns if they exist\n",
    "    key_columns = []\n",
    "    for col_pattern in ['BC', 'ATN', 'flow', 'AAE', 'Delta']:\n",
    "        matching_cols = [col for col in df.columns if col_pattern.lower() in str(col).lower()]\n",
    "        key_columns.extend(matching_cols[:3])  # Limit to first 3 matches per pattern\n",
    "    \n",
    "    if key_columns:\n",
    "        print(f\"\\nüéØ KEY COLUMNS PREVIEW ({len(key_columns)} columns)\")\n",
    "        print(\"=\" * 50)\n",
    "        display(df[key_columns].head())\n",
    "    \n",
    "    # Check for any obvious data quality issues\n",
    "    print(f\"\\nüîç QUICK DATA QUALITY CHECK\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total missing values: {df.isnull().sum().sum()}\")\n",
    "    print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "    \n",
    "    # Check for negative values in BC columns (shouldn't happen)\n",
    "    bc_cols = [col for col in df.columns if 'BC' in str(col).upper() and 'c' in str(col)]\n",
    "    if bc_cols:\n",
    "        negative_counts = (df[bc_cols] < 0).sum()\n",
    "        if negative_counts.any():\n",
    "            print(f\"Negative BC values found: {negative_counts[negative_counts > 0].to_dict()}\")\n",
    "        else:\n",
    "            print(\"‚úÖ No negative BC values found\")\n",
    "            \n",
    "else:\n",
    "    print(\"‚ùå No data available to preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f7eff",
   "metadata": {},
   "source": [
    "## 4. Basic DataFrame Statistics\n",
    "\n",
    "Let's examine the statistical properties of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üìà BASIC STATISTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Overall statistics\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    print(f\"Numeric columns: {len(numeric_cols)}\")\n",
    "    \n",
    "    # General statistics\n",
    "    stats = df.describe()\n",
    "    display(stats)\n",
    "    \n",
    "    # Focus on BC columns if they exist\n",
    "    bc_cols = [col for col in df.columns if 'BC' in str(col).upper() and 'c' in str(col)]\n",
    "    if bc_cols:\n",
    "        print(f\"\\nüéØ BLACK CARBON STATISTICS ({len(bc_cols)} columns)\")\n",
    "        print(\"=\" * 50)\n",
    "        bc_stats = df[bc_cols].describe()\n",
    "        display(bc_stats)\n",
    "        \n",
    "        # Additional BC-specific stats\n",
    "        print(f\"\\nüìä BC Summary:\")\n",
    "        for col in bc_cols[:5]:  # Show first 5 BC columns\n",
    "            if col in df.columns:\n",
    "                mean_val = df[col].mean()\n",
    "                std_val = df[col].std()\n",
    "                print(f\"   {col}: {mean_val:.3f} ¬± {std_val:.3f}\")\n",
    "    \n",
    "    # Check for correlations between key variables\n",
    "    if len(bc_cols) >= 2:\n",
    "        print(f\"\\nüîó BC CORRELATIONS (top correlations)\")\n",
    "        print(\"=\" * 50)\n",
    "        bc_corr = df[bc_cols].corr()\n",
    "        \n",
    "        # Get upper triangle of correlation matrix\n",
    "        mask = np.triu(np.ones_like(bc_corr, dtype=bool))\n",
    "        bc_corr_masked = bc_corr.mask(mask)\n",
    "        \n",
    "        # Find highest correlations\n",
    "        corr_pairs = []\n",
    "        for col in bc_corr_masked.columns:\n",
    "            for idx in bc_corr_masked.index:\n",
    "                if not pd.isna(bc_corr_masked.loc[idx, col]):\n",
    "                    corr_pairs.append((idx, col, bc_corr_masked.loc[idx, col]))\n",
    "        \n",
    "        # Sort by correlation strength\n",
    "        corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "        \n",
    "        for i, (var1, var2, corr) in enumerate(corr_pairs[:5]):\n",
    "            print(f\"   {var1} vs {var2}: {corr:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3336556c",
   "metadata": {},
   "source": [
    "## 5. Time Series Visualization\n",
    "\n",
    "Let's create some basic visualizations using the modular system's plotting capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae990050",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Prepare data for plotting (ensure datetime index)\n",
    "    plot_df = df.copy()\n",
    "    \n",
    "    # Try to convert index to datetime if it's not already\n",
    "    if not isinstance(plot_df.index, pd.DatetimeIndex):\n",
    "        try:\n",
    "            if 'datetime' in plot_df.columns:\n",
    "                plot_df = plot_df.set_index('datetime')\n",
    "            elif 'timestamp' in plot_df.columns:\n",
    "                plot_df = plot_df.set_index('timestamp')\n",
    "            elif 'time' in plot_df.columns:\n",
    "                plot_df = plot_df.set_index('time')\n",
    "            else:\n",
    "                # Try to convert index directly\n",
    "                plot_df.index = pd.to_datetime(plot_df.index)\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Could not convert to datetime index, using original index\")\n",
    "    \n",
    "    # Initialize plotter\n",
    "    try:\n",
    "        plotter = AethalometerPlotter(figsize=(15, 8))\n",
    "        \n",
    "        # Find BC columns for plotting\n",
    "        bc_cols = [col for col in plot_df.columns if 'BC' in str(col).upper() and 'c' in str(col)]\n",
    "        \n",
    "        if bc_cols and isinstance(plot_df.index, pd.DatetimeIndex):\n",
    "            print(\"üìà CREATING TIME SERIES PLOTS\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Plot time series using the modular system\n",
    "            fig = plotter.plot_time_series(\n",
    "                plot_df, \n",
    "                columns=bc_cols[:5],  # Plot first 5 BC columns\n",
    "                title=\"Black Carbon Time Series - Aethalometer Data\"\n",
    "            )\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            # Fallback: create simple plots with matplotlib\n",
    "            print(\"üìà CREATING BASIC PLOTS (fallback method)\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Plot first few numeric columns\n",
    "            numeric_cols = plot_df.select_dtypes(include=[np.number]).columns[:4]\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            for i, col in enumerate(numeric_cols):\n",
    "                if i < 4:\n",
    "                    axes[i].plot(plot_df.index, plot_df[col])\n",
    "                    axes[i].set_title(f'{col}')\n",
    "                    axes[i].set_ylabel('Concentration')\n",
    "                    if isinstance(plot_df.index, pd.DatetimeIndex):\n",
    "                        axes[i].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error creating plots with modular system: {e}\")\n",
    "        print(\"üìà Creating basic matplotlib plots instead...\")\n",
    "        \n",
    "        # Simple fallback plotting\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns[:4]\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, col in enumerate(numeric_cols):\n",
    "            if i < 4:\n",
    "                axes[i].plot(df[col])\n",
    "                axes[i].set_title(f'{col}')\n",
    "                axes[i].set_ylabel('Value')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1241e688",
   "metadata": {},
   "source": [
    "## 6. Advanced Analysis with Modular System\n",
    "\n",
    "Now let's demonstrate some of the advanced analysis capabilities of the modular system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068caa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ ADVANCED ANALYSIS USING MODULAR SYSTEM\n",
      "==================================================\n",
      "1. Source Apportionment Analysis...\n",
      "   ‚ö†Ô∏è Source apportionment analysis error: BaseAnalyzer.__init__() missing 1 required positional argument: 'name'\n",
      "\n",
      "2. Black Carbon Analysis...\n",
      "   ‚úÖ BlackCarbonAnalyzer initialized\n",
      "   üìä Available BC columns: ['Blue BCc', 'Green BCc', 'IR BCc', 'Red BCc', 'UV BCc']\n",
      "   üìà Basic BC Statistics:\n",
      "      Blue BCc: mean=8106.670, std=590951.550, median=5213.000\n",
      "      Green BCc: mean=8945.154, std=950147.411, median=5096.000\n",
      "      IR BCc: mean=7677.271, std=681242.368, median=5225.000\n",
      "\n",
      "3. Data Quality Assessment...\n",
      "   ‚ö†Ô∏è Quality issues found:\n",
      "      - High missing data in 148 columns\n",
      "      - High outlier rate in Blue BCc: 9.3%\n",
      "      - High outlier rate in Green BCc: 9.2%\n",
      "      - High outlier rate in IR BCc: 8.7%\n",
      "\n",
      "4. Correlation Analysis...\n",
      "   üìä BC Correlations:\n",
      "      ma.wavelengths.iuv.bc.b1 vs ma.wavelengths.iblue.bc.b1: 0.999\n",
      "      ma.wavelengths.igreen.bc.b1 vs ma.wavelengths.iblue.bc.b1: 0.999\n",
      "      ma.wavelengths.ired.bc.b1 vs ma.wavelengths.iblue.bc.b1: 0.999\n",
      "      ma.wavelengths.ired.bc.b1 vs ma.wavelengths.igreen.bc.b1: 0.999\n",
      "      ma.wavelengths.ired.bc.b1 vs ma.wavelengths.iir.bc.b1: 0.999\n",
      "\n",
      "5. Summary Statistics...\n",
      "   ‚ö†Ô∏è Quality issues found:\n",
      "      - High missing data in 148 columns\n",
      "      - High outlier rate in Blue BCc: 9.3%\n",
      "      - High outlier rate in Green BCc: 9.2%\n",
      "      - High outlier rate in IR BCc: 8.7%\n",
      "\n",
      "4. Correlation Analysis...\n",
      "   üìä BC Correlations:\n",
      "      ma.wavelengths.iuv.bc.b1 vs ma.wavelengths.iblue.bc.b1: 0.999\n",
      "      ma.wavelengths.igreen.bc.b1 vs ma.wavelengths.iblue.bc.b1: 0.999\n",
      "      ma.wavelengths.ired.bc.b1 vs ma.wavelengths.iblue.bc.b1: 0.999\n",
      "      ma.wavelengths.ired.bc.b1 vs ma.wavelengths.igreen.bc.b1: 0.999\n",
      "      ma.wavelengths.ired.bc.b1 vs ma.wavelengths.iir.bc.b1: 0.999\n",
      "\n",
      "5. Summary Statistics...\n",
      "   üìä Dataset Summary:\n",
      "      Total Records: 1665156\n",
      "      Date Range: Available: 1665156 records\n",
      "      Columns: 239\n",
      "      Missing Data Pct: 45.16%\n",
      "      Avg Bc Concentration: 2906.954 ¬± 2805.409\n",
      "      Bc Columns Available: 20\n",
      "   üìä Dataset Summary:\n",
      "      Total Records: 1665156\n",
      "      Date Range: Available: 1665156 records\n",
      "      Columns: 239\n",
      "      Missing Data Pct: 45.16%\n",
      "      Avg Bc Concentration: 2906.954 ¬± 2805.409\n",
      "      Bc Columns Available: 20\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    print(\"üî¨ ADVANCED ANALYSIS USING MODULAR SYSTEM\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Source Apportionment Analysis\n",
    "        print(\"1. Source Apportionment Analysis...\")\n",
    "        \n",
    "        if SourceApportionmentAnalyzer is not None:\n",
    "            try:\n",
    "                analyzer = SourceApportionmentAnalyzer()\n",
    "                results = analyzer.analyze(df)\n",
    "                \n",
    "                if 'error' not in results:\n",
    "                    print(f\"   ‚úÖ Source apportionment completed\")\n",
    "                    print(f\"   üìä Analysis results: {results.get('summary', 'No summary available')}\")\n",
    "                    \n",
    "                    # Display detailed results\n",
    "                    if 'source_contributions' in results:\n",
    "                        contrib = results['source_contributions']\n",
    "                        print(f\"   üî• Biomass burning: {contrib['biomass_fraction']['mean']*100:.1f}% ¬± {contrib['biomass_fraction']['std']*100:.1f}%\")\n",
    "                        print(f\"   ‚õΩ Fossil fuel: {contrib['fossil_fraction']['mean']*100:.1f}% ¬± {contrib['fossil_fraction']['std']*100:.1f}%\")\n",
    "                    \n",
    "                    if 'aae_statistics' in results:\n",
    "                        aae = results['aae_statistics']\n",
    "                        print(f\"   üìà AAE: {aae['mean']:.2f} ¬± {aae['std']:.2f}\")\n",
    "                        \n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è Source apportionment failed: {results['error']}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Source apportionment analysis error: {e}\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è SourceApportionmentAnalyzer not available\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error in source apportionment analysis: {e}\")\n",
    "    \n",
    "    try:\n",
    "        # Black Carbon analysis with available analyzer\n",
    "        print(\"\\n2. Black Carbon Analysis...\")\n",
    "        \n",
    "        # Check if we have the required columns for BC analysis\n",
    "        bc_columns = [col for col in df.columns if 'BC' in str(col).upper() and 'c' in str(col)]\n",
    "        \n",
    "        if BlackCarbonAnalyzer is not None and len(bc_columns) >= 1:\n",
    "            try:\n",
    "                bc_analyzer = BlackCarbonAnalyzer()\n",
    "                print(f\"   ‚úÖ BlackCarbonAnalyzer initialized\")\n",
    "                print(f\"   üìä Available BC columns: {bc_columns[:5]}\")  # Show first 5\n",
    "                \n",
    "                # Basic BC statistics\n",
    "                print(f\"   üìà Basic BC Statistics:\")\n",
    "                for col in bc_columns[:3]:  # Analyze first 3 BC columns\n",
    "                    if col in df.columns:\n",
    "                        mean_val = df[col].mean()\n",
    "                        std_val = df[col].std()\n",
    "                        median_val = df[col].median()\n",
    "                        print(f\"      {col}: mean={mean_val:.3f}, std={std_val:.3f}, median={median_val:.3f}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Black carbon analysis failed: {e}\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è BlackCarbonAnalyzer not available or insufficient BC columns\")\n",
    "            print(f\"   Available BC columns: {bc_columns}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error in black carbon analysis: {e}\")\n",
    "    \n",
    "    print(f\"\\n3. Data Quality Assessment...\")\n",
    "    \n",
    "    # Basic data quality checks\n",
    "    quality_issues = []\n",
    "    \n",
    "    # Check for missing data\n",
    "    missing_pct = (df.isnull().sum() / len(df) * 100)\n",
    "    high_missing = missing_pct[missing_pct > 10]\n",
    "    if not high_missing.empty:\n",
    "        quality_issues.append(f\"High missing data in {len(high_missing)} columns\")\n",
    "    \n",
    "    # Check for outliers in BC data\n",
    "    bc_cols = [col for col in df.columns if 'BC' in str(col).upper() and 'c' in str(col)]\n",
    "    if bc_cols:\n",
    "        for col in bc_cols[:3]:  # Check first 3 BC columns\n",
    "            if col in df.columns:\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]\n",
    "                if len(outliers) > len(df) * 0.05:  # More than 5% outliers\n",
    "                    quality_issues.append(f\"High outlier rate in {col}: {len(outliers)/len(df)*100:.1f}%\")\n",
    "    \n",
    "    if quality_issues:\n",
    "        print(\"   ‚ö†Ô∏è Quality issues found:\")\n",
    "        for issue in quality_issues:\n",
    "            print(f\"      - {issue}\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ No major quality issues detected\")\n",
    "    \n",
    "    print(f\"\\n4. Correlation Analysis...\")\n",
    "    \n",
    "    # Correlation analysis for BC columns\n",
    "    if len(bc_cols) >= 2:\n",
    "        print(\"   üìä BC Correlations:\")\n",
    "        bc_corr = df[bc_cols].corr()\n",
    "        \n",
    "        # Show strongest correlations\n",
    "        mask = np.triu(np.ones_like(bc_corr, dtype=bool))\n",
    "        bc_corr_masked = bc_corr.mask(mask)\n",
    "        \n",
    "        corr_pairs = []\n",
    "        for col in bc_corr_masked.columns:\n",
    "            for idx in bc_corr_masked.index:\n",
    "                if not pd.isna(bc_corr_masked.loc[idx, col]):\n",
    "                    corr_pairs.append((idx, col, bc_corr_masked.loc[idx, col]))\n",
    "        \n",
    "        corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "        \n",
    "        for i, (var1, var2, corr) in enumerate(corr_pairs[:5]):\n",
    "            print(f\"      {var1} vs {var2}: {corr:.3f}\")\n",
    "    \n",
    "    print(f\"\\n5. Summary Statistics...\")\n",
    "    \n",
    "    # Generate comprehensive summary\n",
    "    summary_stats = {\n",
    "        'total_records': len(df),\n",
    "        'date_range': f\"Available: {len(df)} records\",\n",
    "        'columns': len(df.columns),\n",
    "        'missing_data_pct': f\"{df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100:.2f}%\"\n",
    "    }\n",
    "    \n",
    "    if bc_cols:\n",
    "        bc_means = df[bc_cols].mean()\n",
    "        summary_stats['avg_bc_concentration'] = f\"{bc_means.mean():.3f} ¬± {bc_means.std():.3f}\"\n",
    "        summary_stats['bc_columns_available'] = len(bc_cols)\n",
    "    \n",
    "    print(\"   üìä Dataset Summary:\")\n",
    "    for key, value in summary_stats.items():\n",
    "        print(f\"      {key.replace('_', ' ').title()}: {value}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No data available for advanced analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8db79d",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "This notebook demonstrated the successful integration of the modular aethalometer analysis system with Jupyter notebooks. \n",
    "\n",
    "### What we accomplished:\n",
    "1. ‚úÖ Successfully imported the modular system components\n",
    "2. ‚úÖ Loaded aethalometer data from pickle files\n",
    "3. ‚úÖ Performed basic data inspection and quality checks\n",
    "4. ‚úÖ Generated statistical summaries\n",
    "5. ‚úÖ Created visualizations using the plotting utilities\n",
    "6. ‚úÖ Demonstrated advanced analysis capabilities\n",
    "\n",
    "### Next steps:\n",
    "- Explore additional analysis modules (seasonal, correlations, quality assessment)\n",
    "- Set up automated reporting pipelines\n",
    "- Integrate with the batch processing capabilities\n",
    "- Export results in various formats\n",
    "\n",
    "### Key Benefits:\n",
    "- **Modular Design**: Easy to add new analysis components\n",
    "- **Data Format Flexibility**: Handles different aethalometer data formats\n",
    "- **Quality Control**: Built-in data validation and quality checks\n",
    "- **Visualization**: Integrated plotting utilities for immediate insights\n",
    "- **Extensibility**: Can easily add custom analysis modules\n",
    "\n",
    "**üéâ The modular aethalometer analysis system is successfully working with Jupyter notebooks!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d422bbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SourceApportionmentAnalyzer reloaded\n",
      "\n",
      "üß™ QUICK FUNCTIONALITY TEST\n",
      "========================================\n",
      "‚úÖ Available analyzers: BlackCarbonAnalyzer, SourceApportionmentAnalyzer\n",
      "‚úÖ Data loaded: 1665156 rows √ó 239 columns\n",
      "‚úÖ BC columns found: 20\n",
      "   Sample BC columns: ['Blue BCc', 'Green BCc', 'IR BCc']\n",
      "‚úÖ Source apportionment test: PASSED\n",
      "   Summary: Source contributions: 0.0% biomass, 0.0% fossil fuel; Average AAE: nan; Analysis based on 5 wavelength channels\n",
      "\n",
      "üéâ System check complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# Quick test to verify all components are working\n",
    "import importlib\n",
    "\n",
    "# Force reload the modules\n",
    "try:\n",
    "    import analysis.bc.source_apportionment\n",
    "    importlib.reload(analysis.bc.source_apportionment)\n",
    "    from analysis.bc.source_apportionment import SourceApportionmentAnalyzer\n",
    "    print(\"‚úÖ SourceApportionmentAnalyzer reloaded\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error reloading SourceApportionmentAnalyzer: {e}\")\n",
    "\n",
    "print(\"\\nüß™ QUICK FUNCTIONALITY TEST\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test 1: Check if analyzers are available\n",
    "analyzers_available = []\n",
    "if 'BlackCarbonAnalyzer' in globals() and BlackCarbonAnalyzer is not None:\n",
    "    analyzers_available.append(\"BlackCarbonAnalyzer\")\n",
    "if 'SourceApportionmentAnalyzer' in locals():\n",
    "    analyzers_available.append(\"SourceApportionmentAnalyzer\")\n",
    "\n",
    "print(f\"‚úÖ Available analyzers: {', '.join(analyzers_available)}\")\n",
    "\n",
    "# Test 2: Check if data is loaded\n",
    "if 'df' in globals() and df is not None:\n",
    "    print(f\"‚úÖ Data loaded: {len(df)} rows √ó {len(df.columns)} columns\")\n",
    "    \n",
    "    # Quick column check\n",
    "    bc_cols = [col for col in df.columns if 'BC' in str(col).upper() and 'c' in str(col)]\n",
    "    print(f\"‚úÖ BC columns found: {len(bc_cols)}\")\n",
    "    \n",
    "    if len(bc_cols) > 0:\n",
    "        print(f\"   Sample BC columns: {bc_cols[:3]}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data loaded\")\n",
    "\n",
    "# Test 3: Quick analysis test\n",
    "if 'df' in globals() and df is not None and 'SourceApportionmentAnalyzer' in locals():\n",
    "    try:\n",
    "        test_analyzer = SourceApportionmentAnalyzer()\n",
    "        sample_data = df.head(100)  # Use just first 100 rows for quick test\n",
    "        test_results = test_analyzer.analyze(sample_data)\n",
    "        \n",
    "        if 'error' not in test_results:\n",
    "            print(\"‚úÖ Source apportionment test: PASSED\")\n",
    "            print(f\"   Summary: {test_results.get('summary', 'No summary')}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Source apportionment test: {test_results['error']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Source apportionment test error: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cannot test source apportionment: analyzer or data not available\")\n",
    "\n",
    "print(\"\\nüéâ System check complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
