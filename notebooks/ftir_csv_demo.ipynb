{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# %%\n# Setup and imports\nimport sys\nimport os\nimport pandas as pd\nimport numpy as np\nsys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n\n# Import enhanced setup with FTIR CSV capabilities\nfrom data.qc.enhanced_pkl_processing import process_pkl_data_enhanced\nfrom config.notebook_config import NotebookConfig\nfrom notebook_utils.pkl_cleaning_integration import create_enhanced_setup\n\nprint(\"ğŸš€ Setting up environment...\")\n\n# Your existing configuration\nconfig = NotebookConfig(\n    site_code='ETAD',\n    wavelength='Red',\n    quality_threshold=10,\n    output_format='jpl',\n    min_samples_for_analysis=30,\n    confidence_level=0.95,\n    outlier_threshold=3.0,\n    figure_size=(12, 8),\n    font_size=10,\n    dpi=300\n)\n\n# Set your data paths\nbase_data_path = \"/Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data\"\n\n# FTIR CSV is in the main project directory\nconfig.ftir_csv_path = \"/Users/ahzs645/Github/aethmodular-clean/Four_Sites_FTIR_data.v2.csv\"\n\n# Create enhanced setup with FTIR capabilities\nsetup = create_enhanced_setup(config)\n\nprint(\"âœ… Setup complete!\")\nprint(f\"ğŸ“ FTIR CSV path: {config.ftir_csv_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# Load the already processed Ethiopia data\nimport pandas as pd\n\nprint(\"ğŸ“ Loading pre-processed Ethiopia aethalometer data...\")\n\n# Load the Ethiopia-processed data directly from current notebooks directory\nethiopia_pkl_path = 'pkl_data_cleaned_ethiopia.pkl'  # File is in the same directory as this notebook\n\ntry:\n    pkl_data_cleaned = pd.read_pickle(ethiopia_pkl_path)\n    print(f\"âœ… Loaded Ethiopia-processed data: {pkl_data_cleaned.shape}\")\n    print(f\"ğŸ“… Date range: {pkl_data_cleaned['datetime_local'].min()} to {pkl_data_cleaned['datetime_local'].max()}\")\n    \n    # Check for Ethiopia correction columns\n    ethiopia_cols = [col for col in pkl_data_cleaned.columns if any(x in col for x in ['corrected', 'manual', 'optimized'])]\n    print(f\"ğŸ”§ Ethiopia correction columns found: {len(ethiopia_cols)}\")\n    \n    # Store in setup for easy access\n    setup.datasets['ethiopia_processed'] = pkl_data_cleaned\n    \nexcept FileNotFoundError:\n    print(f\"âŒ File not found: {ethiopia_pkl_path}\")\n    print(\"ğŸ“ Current working directory:\", os.getcwd())\n    print(\"\\nğŸ” Looking for the file in alternative locations...\")\n    \n    # Try alternative paths\n    alternative_paths = [\n        'pkl_data_cleaned_ethiopia.pkl',\n        '../pkl_data_cleaned_ethiopia.pkl',\n        './notebooks/pkl_data_cleaned_ethiopia.pkl',\n        os.path.join(os.getcwd(), 'pkl_data_cleaned_ethiopia.pkl')\n    ]\n    \n    for alt_path in alternative_paths:\n        if os.path.exists(alt_path):\n            print(f\"âœ… Found file at: {alt_path}\")\n            pkl_data_cleaned = pd.read_pickle(alt_path)\n            print(f\"âœ… Loaded Ethiopia-processed data: {pkl_data_cleaned.shape}\")\n            setup.datasets['ethiopia_processed'] = pkl_data_cleaned\n            break\n    else:\n        print(\"âŒ Could not find pkl_data_cleaned_ethiopia.pkl in any expected location\")\n        print(\"\\nğŸ’¡ Please ensure you have run the processing with APPLY_ETHIOPIA_FIX=True first\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# Create 9am-to-9am daily averages for FTIR merging\nprint(\"ğŸ“Š Creating 9am-to-9am daily averaged aethalometer data for FTIR merge...\")\n\n# Ensure datetime_local is datetime type and has timezone info\npkl_data_cleaned['datetime_local'] = pd.to_datetime(pkl_data_cleaned['datetime_local'])\n\n# Set datetime_local as index for resampling\ndf_indexed = pkl_data_cleaned.set_index('datetime_local')\n\n# If timezone is not set, localize to Africa/Addis_Ababa\nif df_indexed.index.tz is None:\n    df_indexed.index = df_indexed.index.tz_localize('Africa/Addis_Ababa')\n    print(\"ğŸŒ Localized timezone to Africa/Addis_Ababa\")\nelif df_indexed.index.tz.zone != 'Africa/Addis_Ababa':\n    df_indexed.index = df_indexed.index.tz_convert('Africa/Addis_Ababa')\n    print(f\"ğŸŒ Converted timezone from {df_indexed.index.tz} to Africa/Addis_Ababa\")\n\n# Define the 9am-to-9am resampling function\ndef resample_9am_to_9am(df, min_coverage=0.5):\n    \"\"\"\n    Resample data from 9am to 9am the next day.\n    \n    Args:\n        df (pd.DataFrame): DataFrame with datetime index\n        min_coverage (float): Minimum fraction of valid data required (0.5 = 50%)\n    \n    Returns:\n        pd.DataFrame: Daily averaged data with 9am timestamps\n    \"\"\"\n    # Shift time back by 9 hours so that 9am becomes the start of the day\n    df_shifted = df.copy()\n    df_shifted.index = df_shifted.index - pd.Timedelta(hours=9)\n    \n    # Calculate the number of valid (non-null) data points per day for each column\n    daily_counts = df_shifted.resample('D').count()\n    \n    # Calculate daily means\n    daily_means = df_shifted.resample('D').mean()\n    \n    # Expected number of hourly points per day (24 hours)\n    # Assuming your data is hourly, adjust if different\n    expected_points = 24\n    \n    # For each column, mask days that don't have enough coverage\n    for col in daily_means.columns:\n        if col in daily_counts.columns:\n            coverage = daily_counts[col] / expected_points\n            daily_means.loc[coverage < min_coverage, col] = np.nan\n    \n    # Shift the index forward by 9 hours to get 9am timestamps\n    daily_means.index = daily_means.index + pd.Timedelta(hours=9)\n    \n    return daily_means\n\n# Apply 9am-to-9am resampling\nprint(\"ğŸ• Applying 9am-to-9am resampling...\")\npkl_data_cleaned_daily = resample_9am_to_9am(df_indexed, min_coverage=0.5)\n\n# Ensure the index is named datetime_local\npkl_data_cleaned_daily.index.name = 'datetime_local'\n\nprint(f\"âœ… Daily averaged data: {pkl_data_cleaned_daily.shape}\")\nprint(f\"ğŸ“… Date range: {pkl_data_cleaned_daily.index.min()} to {pkl_data_cleaned_daily.index.max()}\")\nprint(f\"ğŸ“Š Sample of available columns: {list(pkl_data_cleaned_daily.columns[:10])}\")\n\n# Check data coverage\nvalid_days = pkl_data_cleaned_daily['IR BCc_corrected'].notna().sum() if 'IR BCc_corrected' in pkl_data_cleaned_daily.columns else 0\ntotal_days = len(pkl_data_cleaned_daily)\nprint(f\"ğŸ“ˆ Data coverage: {valid_days}/{total_days} days with valid data ({valid_days/total_days*100:.1f}%)\") if total_days > 0 else None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# NEW: Merge 9am-to-9am aethalometer data with FTIR data\nprint(\"ğŸ”— Merging 9am-to-9am aethalometer data with FTIR data...\")\n\n# Store daily data in setup for merging\nsetup.datasets['daily_aethalometer_9am'] = pkl_data_cleaned_daily\n\n# Automatic merge with FTIR data\ntry:\n    merged_data = setup.merge_with_ftir(\n        aethalometer_dataset='daily_aethalometer_9am',\n        site_code='ETAD',  # Will automatically handle site name variations\n        store_as='aethalometer_ftir_merged_9am'\n    )\n    \n    print(f\"\\nğŸ‰ Merge successful! Final dataset: {merged_data.shape}\")\n    print(f\"\\nğŸ“Š Merge statistics:\")\n    print(f\"  ğŸ• Aethalometer daily points (9am-9am): {len(pkl_data_cleaned_daily)}\")\n    print(f\"  ğŸ§ª Merged points with FTIR: {len(merged_data)}\")\n    print(f\"  ğŸ“ˆ Match rate: {len(merged_data)/len(pkl_data_cleaned_daily)*100:.1f}%\")\n    \n    print(f\"\\nğŸ“Š Available columns:\")\n    ftir_cols = [col for col in merged_data.columns if 'ftir' in col.lower()]\n    aeth_cols = [col for col in merged_data.columns if any(x in col for x in ['BCc', 'ATN', 'corrected'])]\n    print(f\"  ğŸ”§ Aethalometer columns: {len(aeth_cols)} (including Ethiopia corrections)\")\n    print(f\"  ğŸ§ª FTIR columns: {len(ftir_cols)} ({ftir_cols})\")\n    \n    # Show date overlap\n    print(f\"\\nğŸ“… Merged data date range:\")\n    print(f\"  From: {merged_data.index.min()}\")\n    print(f\"  To: {merged_data.index.max()}\")\n    print(f\"  Total days: {len(merged_data)}\")\n    \nexcept Exception as e:\n    print(f\"âŒ Error during merge: {e}\")\n    print(f\"\\nğŸ” Debugging information:\")\n    print(f\"  Daily data shape: {pkl_data_cleaned_daily.shape}\")\n    print(f\"  Daily data index type: {type(pkl_data_cleaned_daily.index)}\")\n    print(f\"  Has timezone? {pkl_data_cleaned_daily.index.tz is not None}\")\n    \n    # Try manual exploration\n    print(f\"\\nğŸ” Exploring FTIR data for troubleshooting...\")\n    setup.explore_ftir_data()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# Analysis: Compare Ethiopia-corrected aethalometer with FTIR (9am-to-9am aligned)\nprint(\"ğŸ“Š Analysis: Ethiopia-corrected aethalometer vs FTIR comparison (9am-to-9am)\")\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import stats\n\nif 'merged_data' in locals() and 'EC_ftir' in merged_data.columns and 'IR BCc_corrected' in merged_data.columns:\n    # Compare Ethiopia-corrected BCc with FTIR EC\n    x = merged_data['IR BCc_corrected'].dropna()\n    y = merged_data.loc[x.index, 'EC_ftir'].dropna()\n    \n    # Get common indices\n    common_idx = x.index.intersection(y.index)\n    x_clean = x.loc[common_idx]\n    y_clean = y.loc[common_idx]\n    \n    if len(x_clean) > 5:\n        # Calculate correlation and regression\n        slope, intercept, r_value, p_value, std_err = stats.linregress(x_clean, y_clean)\n        \n        # Graph 1: Scatter plot WITHOUT regression line\n        fig1, ax1 = plt.subplots(1, 1, figsize=(10, 8))\n        ax1.scatter(x_clean, y_clean, alpha=0.7, color='blue', s=50)\n        ax1.set_xlabel('Ethiopia-Corrected IR BCc (ng/mÂ³)', fontsize=12)\n        ax1.set_ylabel('FTIR EC (Âµg/mÂ³)', fontsize=12)\n        ax1.set_title(f'Aethalometer vs FTIR (Raw Data)\\\\nSite: ETAD (9am-9am), n={len(x_clean)}', fontsize=14)\n        ax1.grid(True, alpha=0.3)\n        \n        # Add statistics text without regression line\n        stats_text = f'RÂ² = {r_value**2:.3f}\\\\np-value = {p_value:.3e}'\n        ax1.text(0.05, 0.95, stats_text, transform=ax1.transAxes, \n                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n                verticalalignment='top', fontsize=11)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Graph 2: Scatter plot WITH regression line\n        fig2, ax2 = plt.subplots(1, 1, figsize=(10, 8))\n        ax2.scatter(x_clean, y_clean, alpha=0.7, color='blue', s=50)\n        \n        # Add regression line\n        line_x = np.linspace(x_clean.min(), x_clean.max(), 100)\n        line_y = slope * line_x + intercept\n        ax2.plot(line_x, line_y, 'r--', alpha=0.8, linewidth=2, label=f'y = {slope:.3f}x + {intercept:.3f}')\n        \n        ax2.set_xlabel('Ethiopia-Corrected IR BCc (ng/mÂ³)', fontsize=12)\n        ax2.set_ylabel('FTIR EC (Âµg/mÂ³)', fontsize=12)\n        ax2.set_title(f'Aethalometer vs FTIR (With Regression)\\\\nSite: ETAD (9am-9am), n={len(x_clean)}', fontsize=14)\n        \n        # Add statistics text with regression info\n        stats_text = f'RÂ² = {r_value**2:.3f}\\\\nSlope = {slope:.3f}\\\\nIntercept = {intercept:.3f}\\\\np-value = {p_value:.3e}'\n        ax2.text(0.05, 0.95, stats_text, transform=ax2.transAxes, \n                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n                verticalalignment='top', fontsize=11)\n        \n        ax2.grid(True, alpha=0.3)\n        ax2.legend()\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Graph 3: Time series comparison\n        fig3, ax3 = plt.subplots(1, 1, figsize=(14, 6))\n        ax3.plot(x_clean.index, x_clean.values, 'b-', label='Ethiopia-Corrected IR BCc', alpha=0.7, linewidth=2)\n        ax3.plot(y_clean.index, y_clean.values, 'r-', label='FTIR EC', alpha=0.7, linewidth=2)\n        ax3.set_xlabel('Date', fontsize=12)\n        ax3.set_ylabel('Concentration', fontsize=12)\n        ax3.set_title('Time Series Comparison (9am-9am aligned)', fontsize=14)\n        ax3.legend()\n        ax3.grid(True, alpha=0.3)\n        ax3.tick_params(axis='x', rotation=45)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        print(f\"\\nğŸ“ˆ Correlation Results:\")\n        print(f\"  RÂ² = {r_value**2:.3f}\")\n        print(f\"  Slope = {slope:.3f}\")\n        print(f\"  Intercept = {intercept:.3f}\")\n        print(f\"  p-value = {p_value:.3e}\")\n        print(f\"  Data points = {len(x_clean)}\")\n        \n        # Show if Ethiopia fix improved correlation\n        if r_value**2 > 0.5:\n            print(f\"\\nğŸ‰ Excellent correlation! Ethiopia fix is working well.\")\n        elif r_value**2 > 0.3:\n            print(f\"\\nğŸ‘ Good correlation! Ethiopia fix shows improvement.\")\n        else:\n            print(f\"\\nğŸ“Š Moderate correlation. Consider data quality checks.\")\n            \n        # Compare original BCc vs corrected BCc if available\n        if 'IR BCc' in merged_data.columns:\n            x_orig = merged_data['IR BCc'].dropna()\n            common_orig = x_orig.index.intersection(y.index)\n            if len(common_orig) > 5:\n                x_orig_clean = x_orig.loc[common_orig]\n                y_orig_clean = y.loc[common_orig]\n                _, _, r_orig, _, _ = stats.linregress(x_orig_clean, y_orig_clean)\n                \n                print(f\"\\nğŸ”„ Improvement from Ethiopia Fix:\")\n                print(f\"  Original BCc RÂ² = {r_orig**2:.3f}\")\n                print(f\"  Corrected BCc RÂ² = {r_value**2:.3f}\")\n                print(f\"  Improvement = {(r_value**2 - r_orig**2):.3f} ({((r_value**2 - r_orig**2)/r_orig**2)*100:+.1f}%)\")\n                \n    else:\n        print(f\"âš ï¸ Insufficient overlapping data points ({len(x_clean)}) for analysis\")\nelse:\n    print(f\"âš ï¸ Required data or columns not found for analysis\")\n    if 'merged_data' not in locals():\n        print(\"  merged_data not created - check merge step\")\n    else:\n        print(f\"  Available columns: {list(merged_data.columns)}\")"
  },
  {
   "cell_type": "code",
   "source": "# %%\n# Apply Linear Regression Correction based on FTIR relationship\nprint(\"ğŸ”§ Applying Linear Regression Correction: IR BCc 2 * 0.85 - 0.17\")\n\nif 'merged_data' in locals() and 'IR BCc_corrected' in merged_data.columns:\n    # Convert from ng/mÂ³ to Î¼g/mÂ³ first (divide by 1000)\n    merged_data['IR BCc_corrected_ug'] = merged_data['IR BCc_corrected'] / 1000\n    \n    # Apply linear regression correction: slope * x + intercept\n    # Using your specified values: slope=0.85, intercept=-0.17\n    merged_data['IR BCc_regression_corrected'] = merged_data['IR BCc_corrected_ug'] * 0.85 - 0.17\n    \n    print(\"âœ… Applied corrections:\")\n    print(f\"  1. Unit conversion: ng/mÂ³ â†’ Î¼g/mÂ³ (Ã· 1000)\")\n    print(f\"  2. Linear regression: BCc * 0.85 - 0.17\")\n    \n    # Compare before and after regression correction\n    if 'EC_ftir' in merged_data.columns:\n        # Get clean data for comparison\n        x_before = merged_data['IR BCc_corrected_ug'].dropna()\n        x_after = merged_data['IR BCc_regression_corrected'].dropna()\n        y = merged_data['EC_ftir'].dropna()\n        \n        # Find common indices\n        common_before = x_before.index.intersection(y.index)\n        common_after = x_after.index.intersection(y.index)\n        \n        if len(common_before) > 5 and len(common_after) > 5:\n            # Calculate correlations\n            from scipy import stats\n            \n            # Before regression correction\n            x_before_clean = x_before.loc[common_before]\n            y_before_clean = y.loc[common_before]\n            _, _, r_before, _, _ = stats.linregress(x_before_clean, y_before_clean)\n            \n            # After regression correction\n            x_after_clean = x_after.loc[common_after]\n            y_after_clean = y.loc[common_after]\n            _, _, r_after, _, _ = stats.linregress(x_after_clean, y_after_clean)\n            \n            print(f\"\\nğŸ“Š Regression Correction Impact:\")\n            print(f\"  Before correction RÂ² = {r_before**2:.3f}\")\n            print(f\"  After correction RÂ² = {r_after**2:.3f}\")\n            print(f\"  Improvement = {(r_after**2 - r_before**2):.3f}\")\n            \n            # Graph 4: Comparison plot showing regression correction effect\n            fig4, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n            \n            # Before correction\n            ax1.scatter(x_before_clean, y_before_clean, alpha=0.7, color='blue', s=50)\n            ax1.set_xlabel('Ethiopia-Corrected IR BCc (Î¼g/mÂ³)', fontsize=12)\n            ax1.set_ylabel('FTIR EC (Î¼g/mÂ³)', fontsize=12)\n            ax1.set_title(f'Before Regression Correction\\\\nRÂ² = {r_before**2:.3f}', fontsize=14)\n            ax1.grid(True, alpha=0.3)\n            \n            # After correction\n            ax2.scatter(x_after_clean, y_after_clean, alpha=0.7, color='red', s=50)\n            ax2.set_xlabel('Regression-Corrected IR BCc (Î¼g/mÂ³)', fontsize=12)\n            ax2.set_ylabel('FTIR EC (Î¼g/mÂ³)', fontsize=12)\n            ax2.set_title(f'After Regression Correction\\\\nRÂ² = {r_after**2:.3f}', fontsize=14)\n            ax2.grid(True, alpha=0.3)\n            \n            # Add 1:1 line to after correction plot\n            min_val = min(x_after_clean.min(), y_after_clean.min())\n            max_val = max(x_after_clean.max(), y_after_clean.max())\n            ax2.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='1:1 line')\n            ax2.legend()\n            \n            plt.tight_layout()\n            plt.show()\n            \n            # Graph 5: Time series with regression correction\n            fig5, ax5 = plt.subplots(1, 1, figsize=(14, 6))\n            ax5.plot(x_before_clean.index, x_before_clean.values, 'b-', \n                    label='Ethiopia-Corrected BCc (Î¼g/mÂ³)', alpha=0.7, linewidth=2)\n            ax5.plot(x_after_clean.index, x_after_clean.values, 'g-', \n                    label='Regression-Corrected BCc (Î¼g/mÂ³)', alpha=0.7, linewidth=2)\n            ax5.plot(y_after_clean.index, y_after_clean.values, 'r-', \n                    label='FTIR EC (Î¼g/mÂ³)', alpha=0.7, linewidth=2)\n            ax5.set_xlabel('Date', fontsize=12)\n            ax5.set_ylabel('Concentration (Î¼g/mÂ³)', fontsize=12)\n            ax5.set_title('Time Series: Before vs After Regression Correction', fontsize=14)\n            ax5.legend()\n            ax5.grid(True, alpha=0.3)\n            ax5.tick_params(axis='x', rotation=45)\n            \n            plt.tight_layout()\n            plt.show()\n            \n    print(f\"\\nğŸ’¾ Available corrected columns:\")\n    correction_cols = [col for col in merged_data.columns if 'corrected' in col or 'regression' in col]\n    for col in correction_cols:\n        print(f\"  ğŸ“Š {col}\")\n        \nelse:\n    print(\"âŒ Merged data not available. Run previous cells first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# Summary and save merged data\nprint(\"ğŸ“‹ Complete Pipeline Summary:\")\nprint(\"=\" * 50)\n\n# Pipeline summary\nprint(\"\\nğŸ”„ Processing Steps:\")\nprint(\"1. âœ… Loaded pre-processed Ethiopia aethalometer data\")\nprint(\"2. âœ… Created 9am-to-9am daily averages\")\nprint(\"3. âœ… Loaded FTIR CSV data\")\nprint(\"4. âœ… Merged with time-aligned FTIR data\")\nprint(\"5. âœ… Analyzed correlation between corrected BCc and FTIR EC\")\n\n# Data summary\nprint(f\"\\nğŸ“Š Data Summary:\")\nif 'pkl_data_cleaned' in locals():\n    print(f\"  Original Ethiopia data: {pkl_data_cleaned.shape}\")\nif 'pkl_data_cleaned_daily' in locals():\n    print(f\"  Daily averaged (9am-9am): {pkl_data_cleaned_daily.shape}\")\nif 'merged_data' in locals():\n    print(f\"  Final merged data: {merged_data.shape}\")\n    \n    # Save the merged data\n    output_path = 'aethalometer_ftir_merged_9am_ethiopia.pkl'\n    merged_data.to_pickle(output_path)\n    print(f\"\\nğŸ’¾ Saved merged data to: {output_path}\")\n\n# Show all available datasets\nprint(f\"\\nğŸ’¾ All available datasets in setup:\")\nfor name, data in setup.datasets.items():\n    print(f\"  ğŸ“Š {name}: {data.shape}\")\n\n# FTIR merge summary\nsetup.get_ftir_summary()\n\nprint(f\"\\nğŸ¯ Key Benefits of This Pipeline:\")\nprint(f\"âœ… Ethiopia pneumatic pump fix applied\")\nprint(f\"âœ… Proper 9am-to-9am time alignment\")\nprint(f\"âœ… FTIR data integration from CSV\")\nprint(f\"âœ… Automated site configuration\")\nprint(f\"âœ… Unit conversion (ng/mÂ³ â†’ Âµg/mÂ³)\")\nprint(f\"âœ… Timezone handling\")\nprint(f\"âœ… Validation against independent FTIR measurements\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Summary of the complete pipeline\n",
    "print(\"ğŸ“‹ Complete Pipeline Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "setup.print_enhanced_summary()\n",
    "\n",
    "print(f\"\\nğŸ¯ Pipeline Benefits:\")\n",
    "print(f\"âœ… Ethiopia pneumatic pump fix applied\")\n",
    "print(f\"âœ… FTIR data integration from CSV\")\n",
    "print(f\"âœ… Automated site configuration\")\n",
    "print(f\"âœ… Unit conversion (ng/mÂ³ â†’ Âµg/mÂ³)\")\n",
    "print(f\"âœ… Timezone handling\")\n",
    "print(f\"âœ… Quality control and cleaning\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Available datasets:\")\n",
    "for name, data in setup.datasets.items():\n",
    "    print(f\"  ğŸ“Š {name}: {data.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}