{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# %%\n# Setup and imports\nimport sys\nimport os\nimport pandas as pd\nimport numpy as np\nsys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n\n# Import enhanced setup with FTIR CSV capabilities\nfrom data.qc.enhanced_pkl_processing import process_pkl_data_enhanced\nfrom config.notebook_config import NotebookConfig\nfrom notebook_utils.pkl_cleaning_integration import create_enhanced_setup\n\nprint(\"ğŸš€ Setting up environment...\")\n\n# Your existing configuration\nconfig = NotebookConfig(\n    site_code='ETAD',\n    wavelength='Red',\n    quality_threshold=10,\n    output_format='jpl',\n    min_samples_for_analysis=30,\n    confidence_level=0.95,\n    outlier_threshold=3.0,\n    figure_size=(12, 8),\n    font_size=10,\n    dpi=300\n)\n\n# Set your data paths\nbase_data_path = \"/Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data\"\n\n# FTIR CSV is in the main project directory\nconfig.ftir_csv_path = \"/Users/ahzs645/Github/aethmodular-clean/Four_Sites_FTIR_data.v2.csv\"\n\n# Create enhanced setup with FTIR capabilities\nsetup = create_enhanced_setup(config)\n\nprint(\"âœ… Setup complete!\")\nprint(f\"ğŸ“ FTIR CSV path: {config.ftir_csv_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# Load the already processed Ethiopia data\nimport pandas as pd\n\nprint(\"ğŸ“ Loading pre-processed Ethiopia aethalometer data...\")\n\n# Load the Ethiopia-processed data directly from current notebooks directory\nethiopia_pkl_path = 'pkl_data_cleaned_ethiopia.pkl'  # File is in the same directory as this notebook\n\ntry:\n    pkl_data_cleaned = pd.read_pickle(ethiopia_pkl_path)\n    print(f\"âœ… Loaded Ethiopia-processed data: {pkl_data_cleaned.shape}\")\n    print(f\"ğŸ“… Date range: {pkl_data_cleaned['datetime_local'].min()} to {pkl_data_cleaned['datetime_local'].max()}\")\n    \n    # Check for Ethiopia correction columns\n    ethiopia_cols = [col for col in pkl_data_cleaned.columns if any(x in col for x in ['corrected', 'manual', 'optimized'])]\n    print(f\"ğŸ”§ Ethiopia correction columns found: {len(ethiopia_cols)}\")\n    \n    # Store in setup for easy access\n    setup.datasets['ethiopia_processed'] = pkl_data_cleaned\n    \nexcept FileNotFoundError:\n    print(f\"âŒ File not found: {ethiopia_pkl_path}\")\n    print(\"ğŸ“ Current working directory:\", os.getcwd())\n    print(\"\\nğŸ” Looking for the file in alternative locations...\")\n    \n    # Try alternative paths\n    alternative_paths = [\n        'pkl_data_cleaned_ethiopia.pkl',\n        '../pkl_data_cleaned_ethiopia.pkl',\n        './notebooks/pkl_data_cleaned_ethiopia.pkl',\n        os.path.join(os.getcwd(), 'pkl_data_cleaned_ethiopia.pkl')\n    ]\n    \n    for alt_path in alternative_paths:\n        if os.path.exists(alt_path):\n            print(f\"âœ… Found file at: {alt_path}\")\n            pkl_data_cleaned = pd.read_pickle(alt_path)\n            print(f\"âœ… Loaded Ethiopia-processed data: {pkl_data_cleaned.shape}\")\n            setup.datasets['ethiopia_processed'] = pkl_data_cleaned\n            break\n    else:\n        print(\"âŒ Could not find pkl_data_cleaned_ethiopia.pkl in any expected location\")\n        print(\"\\nğŸ’¡ Please ensure you have run the processing with APPLY_ETHIOPIA_FIX=True first\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# Create 9am-to-9am daily averages for FTIR merging\nprint(\"ğŸ“Š Creating 9am-to-9am daily averaged aethalometer data for FTIR merge...\")\n\n# Ensure datetime_local is datetime type and has timezone info\npkl_data_cleaned['datetime_local'] = pd.to_datetime(pkl_data_cleaned['datetime_local'])\n\n# Set datetime_local as index for resampling\ndf_indexed = pkl_data_cleaned.set_index('datetime_local')\n\n# If timezone is not set, localize to Africa/Addis_Ababa\nif df_indexed.index.tz is None:\n    df_indexed.index = df_indexed.index.tz_localize('Africa/Addis_Ababa')\n    print(\"ğŸŒ Localized timezone to Africa/Addis_Ababa\")\nelif df_indexed.index.tz.zone != 'Africa/Addis_Ababa':\n    df_indexed.index = df_indexed.index.tz_convert('Africa/Addis_Ababa')\n    print(f\"ğŸŒ Converted timezone from {df_indexed.index.tz} to Africa/Addis_Ababa\")\n\n# Define the 9am-to-9am resampling function\ndef resample_9am_to_9am(df, min_coverage=0.5):\n    \"\"\"\n    Resample data from 9am to 9am the next day.\n    \n    Args:\n        df (pd.DataFrame): DataFrame with datetime index\n        min_coverage (float): Minimum fraction of valid data required (0.5 = 50%)\n    \n    Returns:\n        pd.DataFrame: Daily averaged data with 9am timestamps\n    \"\"\"\n    # Shift time back by 9 hours so that 9am becomes the start of the day\n    df_shifted = df.copy()\n    df_shifted.index = df_shifted.index - pd.Timedelta(hours=9)\n    \n    # Calculate the number of valid (non-null) data points per day for each column\n    daily_counts = df_shifted.resample('D').count()\n    \n    # Calculate daily means\n    daily_means = df_shifted.resample('D').mean()\n    \n    # Expected number of hourly points per day (24 hours)\n    # Assuming your data is hourly, adjust if different\n    expected_points = 24\n    \n    # For each column, mask days that don't have enough coverage\n    for col in daily_means.columns:\n        if col in daily_counts.columns:\n            coverage = daily_counts[col] / expected_points\n            daily_means.loc[coverage < min_coverage, col] = np.nan\n    \n    # Shift the index forward by 9 hours to get 9am timestamps\n    daily_means.index = daily_means.index + pd.Timedelta(hours=9)\n    \n    return daily_means\n\n# Apply 9am-to-9am resampling\nprint(\"ğŸ• Applying 9am-to-9am resampling...\")\npkl_data_cleaned_daily = resample_9am_to_9am(df_indexed, min_coverage=0.5)\n\n# Ensure the index is named datetime_local\npkl_data_cleaned_daily.index.name = 'datetime_local'\n\nprint(f\"âœ… Daily averaged data: {pkl_data_cleaned_daily.shape}\")\nprint(f\"ğŸ“… Date range: {pkl_data_cleaned_daily.index.min()} to {pkl_data_cleaned_daily.index.max()}\")\nprint(f\"ğŸ“Š Sample of available columns: {list(pkl_data_cleaned_daily.columns[:10])}\")\n\n# Check data coverage\nvalid_days = pkl_data_cleaned_daily['IR BCc_corrected'].notna().sum() if 'IR BCc_corrected' in pkl_data_cleaned_daily.columns else 0\ntotal_days = len(pkl_data_cleaned_daily)\nprint(f\"ğŸ“ˆ Data coverage: {valid_days}/{total_days} days with valid data ({valid_days/total_days*100:.1f}%)\") if total_days > 0 else None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# NEW: Merge 9am-to-9am aethalometer data with FTIR data\nprint(\"ğŸ”— Merging 9am-to-9am aethalometer data with FTIR data...\")\n\n# Store daily data in setup for merging\nsetup.datasets['daily_aethalometer_9am'] = pkl_data_cleaned_daily\n\n# Automatic merge with FTIR data\ntry:\n    merged_data = setup.merge_with_ftir(\n        aethalometer_dataset='daily_aethalometer_9am',\n        site_code='ETAD',  # Will automatically handle site name variations\n        store_as='aethalometer_ftir_merged_9am'\n    )\n    \n    print(f\"\\nğŸ‰ Merge successful! Final dataset: {merged_data.shape}\")\n    print(f\"\\nğŸ“Š Merge statistics:\")\n    print(f\"  ğŸ• Aethalometer daily points (9am-9am): {len(pkl_data_cleaned_daily)}\")\n    print(f\"  ğŸ§ª Merged points with FTIR: {len(merged_data)}\")\n    print(f\"  ğŸ“ˆ Match rate: {len(merged_data)/len(pkl_data_cleaned_daily)*100:.1f}%\")\n    \n    print(f\"\\nğŸ“Š Available columns:\")\n    ftir_cols = [col for col in merged_data.columns if 'ftir' in col.lower()]\n    aeth_cols = [col for col in merged_data.columns if any(x in col for x in ['BCc', 'ATN', 'corrected'])]\n    print(f\"  ğŸ”§ Aethalometer columns: {len(aeth_cols)} (including Ethiopia corrections)\")\n    print(f\"  ğŸ§ª FTIR columns: {len(ftir_cols)} ({ftir_cols})\")\n    \n    # Show date overlap\n    print(f\"\\nğŸ“… Merged data date range:\")\n    print(f\"  From: {merged_data.index.min()}\")\n    print(f\"  To: {merged_data.index.max()}\")\n    print(f\"  Total days: {len(merged_data)}\")\n    \nexcept Exception as e:\n    print(f\"âŒ Error during merge: {e}\")\n    print(f\"\\nğŸ” Debugging information:\")\n    print(f\"  Daily data shape: {pkl_data_cleaned_daily.shape}\")\n    print(f\"  Daily data index type: {type(pkl_data_cleaned_daily.index)}\")\n    print(f\"  Has timezone? {pkl_data_cleaned_daily.index.tz is not None}\")\n    \n    # Try manual exploration\n    print(f\"\\nğŸ” Exploring FTIR data for troubleshooting...\")\n    setup.explore_ftir_data()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# Analysis: Compare Ethiopia-corrected aethalometer with FTIR (9am-to-9am aligned)\nprint(\"ğŸ“Š Analysis: Ethiopia-corrected aethalometer vs FTIR comparison (9am-to-9am)\")\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import stats\n\nif 'merged_data' in locals() and 'EC_ftir' in merged_data.columns and 'IR BCc_corrected' in merged_data.columns:\n    # Compare Ethiopia-corrected BCc with FTIR EC\n    x = merged_data['IR BCc_corrected'].dropna()\n    y = merged_data.loc[x.index, 'EC_ftir'].dropna()\n    \n    # Get common indices\n    common_idx = x.index.intersection(y.index)\n    x_clean = x.loc[common_idx]\n    y_clean = y.loc[common_idx]\n    \n    if len(x_clean) > 5:\n        # Calculate correlation and regression\n        slope, intercept, r_value, p_value, std_err = stats.linregress(x_clean, y_clean)\n        \n        # Create plot\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n        \n        # Scatter plot with regression\n        ax1.scatter(x_clean, y_clean, alpha=0.7, color='blue', s=50)\n        \n        # Add regression line\n        line_x = np.linspace(x_clean.min(), x_clean.max(), 100)\n        line_y = slope * line_x + intercept\n        ax1.plot(line_x, line_y, 'r--', alpha=0.8, linewidth=2)\n        \n        ax1.set_xlabel('Ethiopia-Corrected IR BCc (ng/mÂ³)', fontsize=12)\n        ax1.set_ylabel('FTIR EC (Âµg/mÂ³)', fontsize=12)\n        ax1.set_title(f'Ethiopia Fix Validation: Aethalometer vs FTIR\\\\nSite: ETAD (9am-9am), n={len(x_clean)}', fontsize=14)\n        \n        # Add statistics text\n        stats_text = f'RÂ² = {r_value**2:.3f}\\\\nSlope = {slope:.3f}\\\\np-value = {p_value:.3e}'\n        ax1.text(0.05, 0.95, stats_text, transform=ax1.transAxes, \n                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n                verticalalignment='top', fontsize=11)\n        \n        ax1.grid(True, alpha=0.3)\n        \n        # Time series comparison\n        ax2.plot(x_clean.index, x_clean.values, 'b-', label='Ethiopia-Corrected IR BCc', alpha=0.7)\n        ax2.plot(y_clean.index, y_clean.values, 'r-', label='FTIR EC', alpha=0.7)\n        ax2.set_xlabel('Date', fontsize=12)\n        ax2.set_ylabel('Concentration', fontsize=12)\n        ax2.set_title('Time Series Comparison (9am-9am aligned)', fontsize=14)\n        ax2.legend()\n        ax2.grid(True, alpha=0.3)\n        ax2.tick_params(axis='x', rotation=45)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        print(f\"\\nğŸ“ˆ Correlation Results:\")\n        print(f\"  RÂ² = {r_value**2:.3f}\")\n        print(f\"  Slope = {slope:.3f}\")\n        print(f\"  Intercept = {intercept:.3f}\")\n        print(f\"  p-value = {p_value:.3e}\")\n        print(f\"  Data points = {len(x_clean)}\")\n        \n        # Show if Ethiopia fix improved correlation\n        if r_value**2 > 0.5:\n            print(f\"\\nğŸ‰ Excellent correlation! Ethiopia fix is working well.\")\n        elif r_value**2 > 0.3:\n            print(f\"\\nğŸ‘ Good correlation! Ethiopia fix shows improvement.\")\n        else:\n            print(f\"\\nğŸ“Š Moderate correlation. Consider data quality checks.\")\n            \n        # Compare original BCc vs corrected BCc if available\n        if 'IR BCc' in merged_data.columns:\n            x_orig = merged_data['IR BCc'].dropna()\n            common_orig = x_orig.index.intersection(y.index)\n            if len(common_orig) > 5:\n                x_orig_clean = x_orig.loc[common_orig]\n                y_orig_clean = y.loc[common_orig]\n                _, _, r_orig, _, _ = stats.linregress(x_orig_clean, y_orig_clean)\n                \n                print(f\"\\nğŸ”„ Improvement from Ethiopia Fix:\")\n                print(f\"  Original BCc RÂ² = {r_orig**2:.3f}\")\n                print(f\"  Corrected BCc RÂ² = {r_value**2:.3f}\")\n                print(f\"  Improvement = {(r_value**2 - r_orig**2):.3f} ({((r_value**2 - r_orig**2)/r_orig**2)*100:+.1f}%)\")\n                \n    else:\n        print(f\"âš ï¸ Insufficient overlapping data points ({len(x_clean)}) for analysis\")\nelse:\n    print(f\"âš ï¸ Required data or columns not found for analysis\")\n    if 'merged_data' not in locals():\n        print(\"  merged_data not created - check merge step\")\n    else:\n        print(f\"  Available columns: {list(merged_data.columns)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# %%\n# Summary and save merged data\nprint(\"ğŸ“‹ Complete Pipeline Summary:\")\nprint(\"=\" * 50)\n\n# Pipeline summary\nprint(\"\\nğŸ”„ Processing Steps:\")\nprint(\"1. âœ… Loaded pre-processed Ethiopia aethalometer data\")\nprint(\"2. âœ… Created 9am-to-9am daily averages\")\nprint(\"3. âœ… Loaded FTIR CSV data\")\nprint(\"4. âœ… Merged with time-aligned FTIR data\")\nprint(\"5. âœ… Analyzed correlation between corrected BCc and FTIR EC\")\n\n# Data summary\nprint(f\"\\nğŸ“Š Data Summary:\")\nif 'pkl_data_cleaned' in locals():\n    print(f\"  Original Ethiopia data: {pkl_data_cleaned.shape}\")\nif 'pkl_data_cleaned_daily' in locals():\n    print(f\"  Daily averaged (9am-9am): {pkl_data_cleaned_daily.shape}\")\nif 'merged_data' in locals():\n    print(f\"  Final merged data: {merged_data.shape}\")\n    \n    # Save the merged data\n    output_path = 'aethalometer_ftir_merged_9am_ethiopia.pkl'\n    merged_data.to_pickle(output_path)\n    print(f\"\\nğŸ’¾ Saved merged data to: {output_path}\")\n\n# Show all available datasets\nprint(f\"\\nğŸ’¾ All available datasets in setup:\")\nfor name, data in setup.datasets.items():\n    print(f\"  ğŸ“Š {name}: {data.shape}\")\n\n# FTIR merge summary\nsetup.get_ftir_summary()\n\nprint(f\"\\nğŸ¯ Key Benefits of This Pipeline:\")\nprint(f\"âœ… Ethiopia pneumatic pump fix applied\")\nprint(f\"âœ… Proper 9am-to-9am time alignment\")\nprint(f\"âœ… FTIR data integration from CSV\")\nprint(f\"âœ… Automated site configuration\")\nprint(f\"âœ… Unit conversion (ng/mÂ³ â†’ Âµg/mÂ³)\")\nprint(f\"âœ… Timezone handling\")\nprint(f\"âœ… Validation against independent FTIR measurements\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Summary of the complete pipeline\n",
    "print(\"ğŸ“‹ Complete Pipeline Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "setup.print_enhanced_summary()\n",
    "\n",
    "print(f\"\\nğŸ¯ Pipeline Benefits:\")\n",
    "print(f\"âœ… Ethiopia pneumatic pump fix applied\")\n",
    "print(f\"âœ… FTIR data integration from CSV\")\n",
    "print(f\"âœ… Automated site configuration\")\n",
    "print(f\"âœ… Unit conversion (ng/mÂ³ â†’ Âµg/mÂ³)\")\n",
    "print(f\"âœ… Timezone handling\")\n",
    "print(f\"âœ… Quality control and cleaning\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Available datasets:\")\n",
    "for name, data in setup.datasets.items():\n",
    "    print(f\"  ğŸ“Š {name}: {data.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}