{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from typing import Optional\n",
    "\n",
    "print(\"🚀 Setting up SPARTAN Speciation Analysis Environment...\")\n",
    "\n",
    "# Set your paths here\n",
    "FTIR_CSV_PATH = \"/Users/ahzs645/Github/aethmodular-clean/Four_Sites_FTIR_data.v2.csv\"\n",
    "SPARTAN_SPECIATION_PATH = \"/Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/EC-HIPS-Aeth Comparison/Data/Downloaded Data/SPARTAN/Addis Ababa/FilterBased_ChemSpecPM25_ETAD.csv\"\n",
    "ETHIOPIA_PKL_PATH = \"pkl_data_cleaned_ethiopia.pkl\"  # Your processed aethalometer data\n",
    "\n",
    "print(\"✅ Setup complete!\")\n",
    "print(f\"📁 FTIR CSV: {Path(FTIR_CSV_PATH).exists()}\")\n",
    "print(f\"🧪 SPARTAN Speciation: {Path(SPARTAN_SPECIATION_PATH).exists()}\")\n",
    "print(f\"🔧 Ethiopia PKL: {Path(ETHIOPIA_PKL_PATH).exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_modules",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Processing Modules\n",
    "class FTIRCSVLoader:\n",
    "    \"\"\"Load and process FTIR data from CSV files\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path: str):\n",
    "        self.csv_path = Path(csv_path)\n",
    "        if not self.csv_path.exists():\n",
    "            raise FileNotFoundError(f\"FTIR CSV file not found: {self.csv_path}\")\n",
    "        \n",
    "    def load_site_data(self, site_code: str, parameters=None) -> pd.DataFrame:\n",
    "        \"\"\"Load FTIR data for a specific site\"\"\"\n",
    "        print(f\"📊 Loading FTIR data for site {site_code}...\")\n",
    "        \n",
    "        # Load the full CSV\n",
    "        df = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Filter by site\n",
    "        site_data = df[df['Site'] == site_code].copy()\n",
    "        \n",
    "        if len(site_data) == 0:\n",
    "            available_sites = df['Site'].unique()\n",
    "            raise ValueError(f\"No data found for site '{site_code}'. Available sites: {list(available_sites)}\")\n",
    "        \n",
    "        # Convert sample date to datetime\n",
    "        site_data['SampleDate'] = pd.to_datetime(site_data['SampleDate'])\n",
    "        \n",
    "        # Filter parameters if specified\n",
    "        if parameters:\n",
    "            site_data = site_data[site_data['Parameter'].isin(parameters)]\n",
    "        \n",
    "        # Pivot to get parameters as columns\n",
    "        pivot_data = site_data.pivot_table(\n",
    "            index='SampleDate',\n",
    "            columns='Parameter',\n",
    "            values='Concentration_ug_m3',\n",
    "            aggfunc='mean'  # Average if multiple measurements per day\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Set datetime index\n",
    "        pivot_data.set_index('SampleDate', inplace=True)\n",
    "        pivot_data.index.name = 'datetime_local'\n",
    "        \n",
    "        print(f\"✅ Loaded {len(pivot_data)} FTIR measurements\")\n",
    "        print(f\"📅 Date range: {pivot_data.index.min()} to {pivot_data.index.max()}\")\n",
    "        print(f\"🧪 Parameters: {list(pivot_data.columns)}\")\n",
    "        \n",
    "        return pivot_data\n",
    "\n",
    "\n",
    "def load_spartan_speciation_data(csv_path: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Load SPARTAN speciation data with proper unit handling\"\"\"\n",
    "    \n",
    "    print(\"🧪 Loading SPARTAN speciation data...\")\n",
    "    \n",
    "    try:\n",
    "        # Load CSV (skip first 3 lines to get to header)\n",
    "        df = pd.read_csv(csv_path, skiprows=3)\n",
    "        print(f\"   Raw data: {len(df)} rows, {len(df.columns)} columns\")\n",
    "        \n",
    "        # Filter for ETAD\n",
    "        df = df[df['Site_Code'] == 'ETAD'].copy()\n",
    "        print(f\"   ETAD data: {len(df)} rows\")\n",
    "        \n",
    "        # Create datetime\n",
    "        def create_timestamp(row):\n",
    "            try:\n",
    "                return pd.Timestamp(\n",
    "                    year=int(row['Start_Year_local']),\n",
    "                    month=int(row['Start_Month_local']),\n",
    "                    day=int(row['Start_Day_local']),\n",
    "                    hour=int(row['Start_hour_local'])\n",
    "                )\n",
    "            except:\n",
    "                return pd.NaT\n",
    "        \n",
    "        df['Start_Date'] = df.apply(create_timestamp, axis=1)\n",
    "        df = df[df['Start_Date'].notna()].copy()\n",
    "        \n",
    "        print(f\"   ✅ Created datetime for {len(df)} rows\")\n",
    "        \n",
    "        # Map parameter codes to clean names with units\n",
    "        parameter_mapping = {\n",
    "            28101: 'PM25_mass',          # μg/m³\n",
    "            28202: 'BC_PM25',            # μg/m³  \n",
    "            28401: 'Sulfate_Ion',        # μg/m³\n",
    "            28402: 'Nitrate_Ion',        # μg/m³\n",
    "            28403: 'Phosphate_Ion',      # μg/m³\n",
    "            28404: 'Nitrite_Ion',        # μg/m³\n",
    "            28801: 'Sodium_Ion',         # μg/m³\n",
    "            28802: 'Ammonium_Ion',       # μg/m³\n",
    "            28803: 'Potassium_Ion',      # μg/m³\n",
    "            28804: 'Magnesium_Ion',      # ng/m³ (note different unit!)\n",
    "            28805: 'Calcium_Ion',        # μg/m³\n",
    "            28902: 'Aluminum',           # ng/m³\n",
    "            28904: 'Titanium',           # ng/m³\n",
    "            28905: 'Vanadium',           # ng/m³\n",
    "            28906: 'Chromium',           # ng/m³\n",
    "            28907: 'Manganese',          # ng/m³\n",
    "            28908: 'Iron',               # ng/m³\n",
    "            28909: 'Cobalt',             # ng/m³\n",
    "            28910: 'Nickel',             # ng/m³\n",
    "            28911: 'Copper',             # ng/m³\n",
    "            28912: 'Zinc',               # ng/m³\n",
    "            28913: 'Arsenic',            # ng/m³\n",
    "            28914: 'Selenium',           # ng/m³\n",
    "            28916: 'Cadmium',            # ng/m³\n",
    "            28917: 'Antimony',           # ng/m³\n",
    "            28919: 'Cerium',             # ng/m³\n",
    "            28920: 'Lead',               # ng/m³\n",
    "            28921: 'Rubidium',           # ng/m³\n",
    "            28922: 'Strontium',          # ng/m³\n",
    "            28923: 'Silicon',            # ng/m³\n",
    "            28924: 'Sulfur',             # ng/m³\n",
    "            28925: 'Chlorine',           # ng/m³\n",
    "            28926: 'Tin'                 # ng/m³\n",
    "        }\n",
    "        \n",
    "        # Unit conversion mapping (ng/m³ to μg/m³ for consistency)\n",
    "        ng_to_ug_species = [\n",
    "            'Magnesium_Ion', 'Aluminum', 'Titanium', 'Vanadium', 'Chromium', \n",
    "            'Manganese', 'Iron', 'Cobalt', 'Nickel', 'Copper', 'Zinc', \n",
    "            'Arsenic', 'Selenium', 'Cadmium', 'Antimony', 'Cerium', 'Lead',\n",
    "            'Rubidium', 'Strontium', 'Silicon', 'Sulfur', 'Chlorine', 'Tin'\n",
    "        ]\n",
    "        \n",
    "        # Map parameter codes\n",
    "        df['Parameter_Name_Clean'] = df['Parameter_Code'].map(parameter_mapping)\n",
    "        mapped_count = df['Parameter_Name_Clean'].notna().sum()\n",
    "        print(f\"   📊 Mapped {mapped_count} parameter measurements\")\n",
    "        \n",
    "        # Keep only mapped parameters\n",
    "        df_mapped = df[df['Parameter_Name_Clean'].notna()].copy()\n",
    "        \n",
    "        # Pivot to wide format\n",
    "        speciation_wide = df_mapped.pivot_table(\n",
    "            index=['Filter_ID', 'Start_Date'],\n",
    "            columns='Parameter_Name_Clean',\n",
    "            values='Value',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        \n",
    "        speciation_wide.columns.name = None\n",
    "        \n",
    "        # Convert ng/m³ to μg/m³ for consistency\n",
    "        for species in ng_to_ug_species:\n",
    "            if species in speciation_wide.columns:\n",
    "                speciation_wide[species] = speciation_wide[species] / 1000  # ng/m³ → μg/m³\n",
    "        \n",
    "        print(f\"   ✅ Created wide format: {len(speciation_wide)} unique samples\")\n",
    "        print(f\"   📏 All species now in μg/m³ units\")\n",
    "        print(f\"   🧪 Available species: {[col for col in speciation_wide.columns if col not in ['Filter_ID', 'Start_Date']]}\")\n",
    "        \n",
    "        return speciation_wide\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading speciation data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def resample_9am_to_9am(df: pd.DataFrame, datetime_col: str = 'datetime_local', \n",
    "                       timezone: str = 'Africa/Addis_Ababa', min_hours: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"Resample data from 9am to 9am next day\"\"\"\n",
    "    df_work = df.copy()\n",
    "    \n",
    "    # Ensure datetime column is datetime type\n",
    "    df_work[datetime_col] = pd.to_datetime(df_work[datetime_col])\n",
    "    \n",
    "    # Set as index\n",
    "    df_work = df_work.set_index(datetime_col)\n",
    "    \n",
    "    # Localize timezone if needed\n",
    "    if df_work.index.tz is None:\n",
    "        df_work.index = df_work.index.tz_localize(timezone)\n",
    "        print(f\"🌍 Localized to {timezone}\")\n",
    "    \n",
    "    # Shift time back by 9 hours so 9am becomes start of day\n",
    "    df_shifted = df_work.copy()\n",
    "    df_shifted.index = df_shifted.index - pd.Timedelta(hours=9)\n",
    "    \n",
    "    # Get numeric columns only\n",
    "    numeric_cols = df_shifted.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Resample to daily, calculating mean and count\n",
    "    daily_means = df_shifted[numeric_cols].resample('D').mean()\n",
    "    daily_counts = df_shifted[numeric_cols].resample('D').count()\n",
    "    \n",
    "    # Filter out days with insufficient data\n",
    "    for col in numeric_cols:\n",
    "        insufficient_data = daily_counts[col] < min_hours\n",
    "        daily_means.loc[insufficient_data, col] = np.nan\n",
    "    \n",
    "    # Shift index forward by 9 hours to get 9am timestamps\n",
    "    daily_means.index = daily_means.index + pd.Timedelta(hours=9)\n",
    "    daily_means.index.name = 'datetime_local'\n",
    "    \n",
    "    return daily_means\n",
    "\n",
    "\n",
    "print(\"✅ Data loading modules ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets with enhanced debugging\n",
    "print(\"📊 Loading all datasets...\")\n",
    "\n",
    "# 1. Load FTIR data\n",
    "ftir_loader = FTIRCSVLoader(FTIR_CSV_PATH)\n",
    "ftir_data = ftir_loader.load_site_data('ETAD')\n",
    "\n",
    "# 2. Load SPARTAN speciation data with detailed debugging\n",
    "print(f\"\\n🔍 Debugging SPARTAN data loading...\")\n",
    "print(f\"📁 File path: {SPARTAN_SPECIATION_PATH}\")\n",
    "print(f\"📋 File exists: {Path(SPARTAN_SPECIATION_PATH).exists()}\")\n",
    "\n",
    "if Path(SPARTAN_SPECIATION_PATH).exists():\n",
    "    # Read first few lines to understand file structure\n",
    "    print(f\\\"\\\\n📖 First 10 lines of the file:\\\")\n",
    "    with open(SPARTAN_SPECIATION_PATH, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i < 10:\n",
    "                print(f\\\"   Line {i}: {line.strip()[:100]}...\\\")\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    # Try to load with different skip settings\n",
    "    try:\n",
    "        # Try skiprows=3 first\n",
    "        df_test = pd.read_csv(SPARTAN_SPECIATION_PATH, skiprows=3, nrows=5)\n",
    "        print(f\\\"\\\\n✅ Successfully read with skiprows=3\\\")\n",
    "        print(f\\\"📊 Columns: {list(df_test.columns)[:10]}...\\\")\n",
    "        print(f\\\"📋 Sample data shape: {df_test.shape}\\\")\n",
    "        \n",
    "        # Check for Site_Code column\n",
    "        if 'Site_Code' in df_test.columns:\n",
    "            print(f\\\"✅ Found Site_Code column\\\")\n",
    "            unique_sites = pd.read_csv(SPARTAN_SPECIATION_PATH, skiprows=3)['Site_Code'].unique()[:10]\n",
    "            print(f\\\"🏢 Available sites: {unique_sites}\\\")\n",
    "        else:\n",
    "            print(f\\\"⚠️ Site_Code column not found. Available columns: {list(df_test.columns)}\\\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\\\"❌ Error with skiprows=3: {e}\\\")\n",
    "        \n",
    "        # Try without skipping rows\n",
    "        try:\n",
    "            df_test = pd.read_csv(SPARTAN_SPECIATION_PATH, nrows=5)\n",
    "            print(f\\\"\\\\n✅ Successfully read without skipping rows\\\")\n",
    "            print(f\\\"📊 Columns: {list(df_test.columns)[:10]}...\\\")\n",
    "        except Exception as e2:\n",
    "            print(f\\\"❌ Error reading file: {e2}\\\")\n",
    "\n",
    "speciation_data = load_spartan_speciation_data(SPARTAN_SPECIATION_PATH)\n",
    "\n",
    "# 3. Load processed Ethiopia aethalometer data\n",
    "print(f\\\"\\\\n📁 Loading processed Ethiopia aethalometer data...\\\")\n",
    "try:\n",
    "    aethalometer_data = pd.read_pickle(ETHIOPIA_PKL_PATH)\n",
    "    print(f\\\"✅ Loaded Ethiopia data: {aethalometer_data.shape}\\\")\n",
    "    \n",
    "    # Apply 9am-to-9am resampling\n",
    "    print(\\\"🕐 Applying 9am-to-9am resampling...\\\")\n",
    "    daily_aethalometer = resample_9am_to_9am(aethalometer_data, timezone='Africa/Addis_Ababa')\n",
    "    print(f\\\"✅ Daily resampling complete: {daily_aethalometer.shape}\\\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\\\"❌ Processed file not found: {ETHIOPIA_PKL_PATH}\\\")\n",
    "    print(\\\"Please ensure you have the processed Ethiopia aethalometer data\\\")\n",
    "    daily_aethalometer = None\n",
    "\n",
    "print(f\\\"\\\\n📋 Data Loading Summary:\\\")\n",
    "print(f\\\"  🧪 FTIR data: {len(ftir_data) if ftir_data is not None else 0} samples\\\")\n",
    "print(f\\\"  🔬 Speciation data: {len(speciation_data) if speciation_data is not None else 0} samples\\\")\n",
    "print(f\\\"  🔧 Daily aethalometer: {len(daily_aethalometer) if daily_aethalometer is not None else 0} days\\\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge_datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "print(\"🔗 Merging datasets...\")\n",
    "\n",
    "if ftir_data is not None and daily_aethalometer is not None:\n",
    "    # Prepare FTIR data for merging\n",
    "    ftir_data_for_merge = ftir_data.copy()\n",
    "    \n",
    "    # Set timestamps to 9am on sample dates with timezone\n",
    "    ftir_timestamps = (pd.to_datetime(ftir_data_for_merge.index.date).normalize() + \n",
    "                      pd.Timedelta(hours=9))\n",
    "    ftir_timestamps = ftir_timestamps.tz_localize('Africa/Addis_Ababa')\n",
    "    \n",
    "    ftir_data_for_merge.index = ftir_timestamps\n",
    "    ftir_data_for_merge.index.name = 'datetime_local'\n",
    "    \n",
    "    # Merge aethalometer with FTIR\n",
    "    merged_aeth_ftir = pd.merge(\n",
    "        daily_aethalometer,\n",
    "        ftir_data_for_merge,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    print(f\"🎉 Aethalometer + FTIR merge: {len(merged_aeth_ftir)} samples\")\n",
    "    \n",
    "    # If we have speciation data, try to merge it too\n",
    "    if speciation_data is not None:\n",
    "        print(\"🧪 Attempting to merge speciation data...\")\n",
    "        \n",
    "        # Prepare speciation data\n",
    "        spec_for_merge = speciation_data.copy()\n",
    "        \n",
    "        # Convert Start_Date to 9am timestamps with timezone\n",
    "        spec_timestamps = (pd.to_datetime(spec_for_merge['Start_Date'].dt.date).normalize() + \n",
    "                          pd.Timedelta(hours=9))\n",
    "        spec_timestamps = spec_timestamps.tz_localize('Africa/Addis_Ababa')\n",
    "        \n",
    "        spec_for_merge.index = spec_timestamps\n",
    "        spec_for_merge.index.name = 'datetime_local'\n",
    "        \n",
    "        # Remove non-numeric columns for merging\n",
    "        spec_numeric = spec_for_merge.select_dtypes(include=[np.number])\n",
    "        \n",
    "        # Merge all three datasets\n",
    "        merged_all = pd.merge(\n",
    "            merged_aeth_ftir,\n",
    "            spec_numeric,\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        print(f\"🎉 Triple merge (Aeth + FTIR + Speciation): {len(merged_all)} samples\")\n",
    "        \n",
    "        # Add Ethiopian seasons\n",
    "        merged_all['month'] = merged_all.index.month\n",
    "        def get_ethiopian_season(month):\n",
    "            if month in [10, 11, 12, 1, 2]:\n",
    "                return 'Dry Season (Bega)'\n",
    "            elif month in [3, 4, 5]:\n",
    "                return 'Belg Rainy Season'\n",
    "            else:\n",
    "                return 'Kiremt Rainy Season'\n",
    "        \n",
    "        merged_all['season'] = merged_all['month'].apply(get_ethiopian_season)\n",
    "        \n",
    "        final_merged = merged_all\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️ No speciation data to merge\")\n",
    "        final_merged = merged_aeth_ftir\n",
    "        \n",
    "    print(f\"\\n📊 Final merged dataset: {final_merged.shape}\")\n",
    "    \n",
    "    # Show available columns by category\n",
    "    all_cols = list(final_merged.columns)\n",
    "    \n",
    "    ftir_cols = [col for col in all_cols if any(x in col.lower() for x in ['ec', 'oc', 'ftir'])]\n",
    "    bc_corrected_cols = [col for col in all_cols if 'BCc' in col and 'corrected' in col]\n",
    "    spec_cols = [col for col in all_cols if any(x in col for x in ['Iron', 'Aluminum', 'Potassium', 'Sulfate'])]\n",
    "    \n",
    "    print(f\"\\n📊 Available data types:\")\n",
    "    print(f\"  🧪 FTIR columns: {ftir_cols}\")\n",
    "    print(f\"  🔧 BC corrected columns: {len(bc_corrected_cols)} (IR, Red, Blue, etc.)\")\n",
    "    print(f\"  🔬 Speciation columns: {len(spec_cols)} - {spec_cols[:5]}...\" if spec_cols else \"  🔬 Speciation columns: None\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Cannot merge - missing required datasets\")\n",
    "    final_merged = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apply_regression_correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply linear regression corrections\n",
    "print(\"🔧 Applying Linear Regression Corrections...\")\n",
    "\n",
    "if final_merged is not None:\n",
    "    # Find BC columns for both IR and Red wavelengths\n",
    "    ir_bc_col = None\n",
    "    red_bc_col = None\n",
    "    \n",
    "    bc_corrected_cols = [col for col in final_merged.columns if 'BCc' in col and 'corrected' in col]\n",
    "    \n",
    "    for col in bc_corrected_cols:\n",
    "        if 'IR' in col:\n",
    "            ir_bc_col = col\n",
    "        elif 'Red' in col:\n",
    "            red_bc_col = col\n",
    "    \n",
    "    print(f\"📊 Found BC columns:\")\n",
    "    print(f\"  🔴 IR BC: {ir_bc_col}\")\n",
    "    print(f\"  🟥 Red BC: {red_bc_col}\")\n",
    "    \n",
    "    # Apply regression corrections for both wavelengths\n",
    "    if ir_bc_col:\n",
    "        # Convert from ng/m³ to μg/m³ and apply regression correction\n",
    "        final_merged['IR_BC_ug'] = final_merged[ir_bc_col] / 1000  # ng/m³ → μg/m³\n",
    "        final_merged['IR_BC_regression_corrected'] = final_merged['IR_BC_ug'] * 0.85 - 0.17\n",
    "        print(f\"✅ Applied IR regression correction: BC × 0.85 - 0.17\")\n",
    "    \n",
    "    if red_bc_col:\n",
    "        # Convert from ng/m³ to μg/m³ and apply regression correction\n",
    "        final_merged['Red_BC_ug'] = final_merged[red_bc_col] / 1000  # ng/m³ → μg/m³\n",
    "        final_merged['Red_BC_regression_corrected'] = final_merged['Red_BC_ug'] * 0.85 - 0.17\n",
    "        print(f\"✅ Applied Red regression correction: BC × 0.85 - 0.17\")\n",
    "    \n",
    "    # Show Iron data availability for color-coding\n",
    "    if 'Iron' in final_merged.columns:\n",
    "        iron_available = final_merged['Iron'].notna().sum()\n",
    "        print(f\"🔬 Iron data available for {iron_available}/{len(final_merged)} samples\")\n",
    "        print(f\"   Iron range: {final_merged['Iron'].min():.3f} - {final_merged['Iron'].max():.3f} μg/m³\")\n",
    "    else:\n",
    "        print(f\"⚠️ No Iron data available for color-coding\")\n",
    "    \n",
    "    print(f\"\\n💾 Regression correction columns added:\")\n",
    "    regression_cols = [col for col in final_merged.columns if 'regression' in col or col.endswith('_ug')]\n",
    "    for col in regression_cols:\n",
    "        print(f\"  📊 {col}\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ No merged data available for regression correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ir_scatter_plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IR Wavelength Scatter Plots with Fe Color-coding\n",
    "print(\"📊 Creating IR Wavelength Scatter Plots with Fe Color-coding\")\n",
    "\n",
    "if final_merged is not None and 'EC_ftir' in final_merged.columns:\n",
    "    \n",
    "    # Get data for IR wavelength\n",
    "    ec_ftir = final_merged['EC_ftir'].dropna()\n",
    "    \n",
    "    # Check if we have Iron data for color-coding\n",
    "    use_fe_coloring = 'Iron' in final_merged.columns and final_merged['Iron'].notna().sum() > 5\n",
    "    \n",
    "    if use_fe_coloring:\n",
    "        print(\"🔬 Using Iron concentration for color-coding\")\n",
    "        colormap = 'viridis'\n",
    "        color_label = 'Iron (μg/m³)'\n",
    "    else:\n",
    "        print(\"⚠️ No Iron data - using default coloring\")\n",
    "        colormap = None\n",
    "        color_label = None\n",
    "    \n",
    "    # Plot 1: Ethiopia-corrected IR BC vs FTIR EC\n",
    "    if 'IR_BC_ug' in final_merged.columns:\n",
    "        ir_bc_ug = final_merged['IR_BC_ug'].dropna()\n",
    "        common_idx = ir_bc_ug.index.intersection(ec_ftir.index)\n",
    "        \n",
    "        if len(common_idx) > 3:\n",
    "            x_data = ir_bc_ug.loc[common_idx]\n",
    "            y_data = ec_ftir.loc[common_idx]\n",
    "            \n",
    "            # Get Iron data for coloring if available\n",
    "            if use_fe_coloring:\n",
    "                color_data = final_merged.loc[common_idx, 'Iron']\n",
    "                # Remove any NaN Iron values\n",
    "                valid_color_idx = color_data.notna()\n",
    "                x_data = x_data[valid_color_idx]\n",
    "                y_data = y_data[valid_color_idx]\n",
    "                color_data = color_data[valid_color_idx]\n",
    "            else:\n",
    "                color_data = None\n",
    "            \n",
    "            # Calculate regression\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            if use_fe_coloring and color_data is not None:\n",
    "                scatter = ax.scatter(x_data, y_data, c=color_data, cmap=colormap, \n",
    "                                   alpha=0.7, s=60, edgecolor='black', linewidth=0.5)\n",
    "                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                cbar.set_label(color_label, fontsize=12)\n",
    "            else:\n",
    "                ax.scatter(x_data, y_data, alpha=0.7, color='blue', s=60, \n",
    "                          edgecolor='black', linewidth=0.5)\n",
    "            \n",
    "            # Add regression line\n",
    "            line_x = np.linspace(x_data.min(), x_data.max(), 100)\n",
    "            line_y = slope * line_x + intercept\n",
    "            ax.plot(line_x, line_y, 'r--', alpha=0.8, linewidth=2, \n",
    "                   label=f'y = {slope:.3f}x + {intercept:.3f}')\n",
    "            \n",
    "            # Add 1:1 line\n",
    "            max_val = max(x_data.max(), y_data.max())\n",
    "            min_val = min(x_data.min(), y_data.min())\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], 'k:', alpha=0.5, label='1:1 line')\n",
    "            \n",
    "            ax.set_xlabel('Ethiopia-Corrected IR BC (μg/m³)', fontsize=12)\n",
    "            ax.set_ylabel('FTIR EC (μg/m³)', fontsize=12)\n",
    "            ax.set_title(f'IR Wavelength: Aethalometer vs FTIR-EC\\n(Ethiopia-corrected, n={len(x_data)})', fontsize=14)\n",
    "            \n",
    "            # Statistics text\n",
    "            stats_text = (f'R² = {r_value**2:.3f}\\n'\n",
    "                         f'Slope = {slope:.3f}\\n'\n",
    "                         f'Intercept = {intercept:.3f}\\n'\n",
    "                         f'p-value = {p_value:.2e}')\n",
    "            ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                   verticalalignment='top', fontsize=10)\n",
    "            \n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # Plot 2: Regression-corrected IR BC vs FTIR EC\n",
    "    if 'IR_BC_regression_corrected' in final_merged.columns:\n",
    "        ir_bc_regress = final_merged['IR_BC_regression_corrected'].dropna()\n",
    "        common_idx = ir_bc_regress.index.intersection(ec_ftir.index)\n",
    "        \n",
    "        if len(common_idx) > 3:\n",
    "            x_data = ir_bc_regress.loc[common_idx]\n",
    "            y_data = ec_ftir.loc[common_idx]\n",
    "            \n",
    "            # Get Iron data for coloring if available\n",
    "            if use_fe_coloring:\n",
    "                color_data = final_merged.loc[common_idx, 'Iron']\n",
    "                # Remove any NaN Iron values\n",
    "                valid_color_idx = color_data.notna()\n",
    "                x_data = x_data[valid_color_idx]\n",
    "                y_data = y_data[valid_color_idx]\n",
    "                color_data = color_data[valid_color_idx]\n",
    "            else:\n",
    "                color_data = None\n",
    "            \n",
    "            # Calculate regression\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            if use_fe_coloring and color_data is not None:\n",
    "                scatter = ax.scatter(x_data, y_data, c=color_data, cmap=colormap, \n",
    "                                   alpha=0.7, s=60, edgecolor='black', linewidth=0.5)\n",
    "                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                cbar.set_label(color_label, fontsize=12)\n",
    "            else:\n",
    "                ax.scatter(x_data, y_data, alpha=0.7, color='red', s=60, \n",
    "                          edgecolor='black', linewidth=0.5)\n",
    "            \n",
    "            # Add regression line\n",
    "            line_x = np.linspace(x_data.min(), x_data.max(), 100)\n",
    "            line_y = slope * line_x + intercept\n",
    "            ax.plot(line_x, line_y, 'r--', alpha=0.8, linewidth=2, \n",
    "                   label=f'y = {slope:.3f}x + {intercept:.3f}')\n",
    "            \n",
    "            # Add 1:1 line\n",
    "            max_val = max(x_data.max(), y_data.max())\n",
    "            min_val = min(x_data.min(), y_data.min())\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], 'k:', alpha=0.5, label='1:1 line')\n",
    "            \n",
    "            ax.set_xlabel('Regression-Corrected IR BC (μg/m³)', fontsize=12)\n",
    "            ax.set_ylabel('FTIR EC (μg/m³)', fontsize=12)\n",
    "            ax.set_title(f'IR Wavelength: Aethalometer vs FTIR-EC\\n(Regression-corrected: BC × 0.85 - 0.17, n={len(x_data)})', fontsize=14)\n",
    "            \n",
    "            # Statistics text\n",
    "            stats_text = (f'R² = {r_value**2:.3f}\\n'\n",
    "                         f'Slope = {slope:.3f}\\n'\n",
    "                         f'Intercept = {intercept:.3f}\\n'\n",
    "                         f'p-value = {p_value:.2e}')\n",
    "            ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                   verticalalignment='top', fontsize=10)\n",
    "            \n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "else:\n",
    "    print(\"❌ Cannot create IR plots - missing required data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "red_scatter_plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red Wavelength Scatter Plots with Fe Color-coding\n",
    "print(\"📊 Creating Red Wavelength Scatter Plots with Fe Color-coding\")\n",
    "\n",
    "if final_merged is not None and 'EC_ftir' in final_merged.columns:\n",
    "    \n",
    "    # Get data for Red wavelength\n",
    "    ec_ftir = final_merged['EC_ftir'].dropna()\n",
    "    \n",
    "    # Check if we have Iron data for color-coding\n",
    "    use_fe_coloring = 'Iron' in final_merged.columns and final_merged['Iron'].notna().sum() > 5\n",
    "    \n",
    "    if use_fe_coloring:\n",
    "        print(\"🔬 Using Iron concentration for color-coding\")\n",
    "        colormap = 'plasma'\n",
    "        color_label = 'Iron (μg/m³)'\n",
    "    else:\n",
    "        print(\"⚠️ No Iron data - using default coloring\")\n",
    "        colormap = None\n",
    "        color_label = None\n",
    "    \n",
    "    # Plot 1: Ethiopia-corrected Red BC vs FTIR EC\n",
    "    if 'Red_BC_ug' in final_merged.columns:\n",
    "        red_bc_ug = final_merged['Red_BC_ug'].dropna()\n",
    "        common_idx = red_bc_ug.index.intersection(ec_ftir.index)\n",
    "        \n",
    "        if len(common_idx) > 3:\n",
    "            x_data = red_bc_ug.loc[common_idx]\n",
    "            y_data = ec_ftir.loc[common_idx]\n",
    "            \n",
    "            # Get Iron data for coloring if available\n",
    "            if use_fe_coloring:\n",
    "                color_data = final_merged.loc[common_idx, 'Iron']\n",
    "                # Remove any NaN Iron values\n",
    "                valid_color_idx = color_data.notna()\n",
    "                x_data = x_data[valid_color_idx]\n",
    "                y_data = y_data[valid_color_idx]\n",
    "                color_data = color_data[valid_color_idx]\n",
    "            else:\n",
    "                color_data = None\n",
    "            \n",
    "            # Calculate regression\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            if use_fe_coloring and color_data is not None:\n",
    "                scatter = ax.scatter(x_data, y_data, c=color_data, cmap=colormap, \n",
    "                                   alpha=0.7, s=60, edgecolor='black', linewidth=0.5)\n",
    "                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                cbar.set_label(color_label, fontsize=12)\n",
    "            else:\n",
    "                ax.scatter(x_data, y_data, alpha=0.7, color='red', s=60, \n",
    "                          edgecolor='black', linewidth=0.5)\n",
    "            \n",
    "            # Add regression line\n",
    "            line_x = np.linspace(x_data.min(), x_data.max(), 100)\n",
    "            line_y = slope * line_x + intercept\n",
    "            ax.plot(line_x, line_y, 'r--', alpha=0.8, linewidth=2, \n",
    "                   label=f'y = {slope:.3f}x + {intercept:.3f}')\n",
    "            \n",
    "            # Add 1:1 line\n",
    "            max_val = max(x_data.max(), y_data.max())\n",
    "            min_val = min(x_data.min(), y_data.min())\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], 'k:', alpha=0.5, label='1:1 line')\n",
    "            \n",
    "            ax.set_xlabel('Ethiopia-Corrected Red BC (μg/m³)', fontsize=12)\n",
    "            ax.set_ylabel('FTIR EC (μg/m³)', fontsize=12)\n",
    "            ax.set_title(f'Red Wavelength: Aethalometer vs FTIR-EC\\n(Ethiopia-corrected, n={len(x_data)})', fontsize=14)\n",
    "            \n",
    "            # Statistics text\n",
    "            stats_text = (f'R² = {r_value**2:.3f}\\n'\n",
    "                         f'Slope = {slope:.3f}\\n'\n",
    "                         f'Intercept = {intercept:.3f}\\n'\n",
    "                         f'p-value = {p_value:.2e}')\n",
    "            ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                   verticalalignment='top', fontsize=10)\n",
    "            \n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # Plot 2: Regression-corrected Red BC vs FTIR EC\n",
    "    if 'Red_BC_regression_corrected' in final_merged.columns:\n",
    "        red_bc_regress = final_merged['Red_BC_regression_corrected'].dropna()\n",
    "        common_idx = red_bc_regress.index.intersection(ec_ftir.index)\n",
    "        \n",
    "        if len(common_idx) > 3:\n",
    "            x_data = red_bc_regress.loc[common_idx]\n",
    "            y_data = ec_ftir.loc[common_idx]\n",
    "            \n",
    "            # Get Iron data for coloring if available\n",
    "            if use_fe_coloring:\n",
    "                color_data = final_merged.loc[common_idx, 'Iron']\n",
    "                # Remove any NaN Iron values\n",
    "                valid_color_idx = color_data.notna()\n",
    "                x_data = x_data[valid_color_idx]\n",
    "                y_data = y_data[valid_color_idx]\n",
    "                color_data = color_data[valid_color_idx]\n",
    "            else:\n",
    "                color_data = None\n",
    "            \n",
    "            # Calculate regression\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            if use_fe_coloring and color_data is not None:\n",
    "                scatter = ax.scatter(x_data, y_data, c=color_data, cmap=colormap, \n",
    "                                   alpha=0.7, s=60, edgecolor='black', linewidth=0.5)\n",
    "                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                cbar.set_label(color_label, fontsize=12)\n",
    "            else:\n",
    "                ax.scatter(x_data, y_data, alpha=0.7, color='darkred', s=60, \n",
    "                          edgecolor='black', linewidth=0.5)\n",
    "            \n",
    "            # Add regression line\n",
    "            line_x = np.linspace(x_data.min(), x_data.max(), 100)\n",
    "            line_y = slope * line_x + intercept\n",
    "            ax.plot(line_x, line_y, 'r--', alpha=0.8, linewidth=2, \n",
    "                   label=f'y = {slope:.3f}x + {intercept:.3f}')\n",
    "            \n",
    "            # Add 1:1 line\n",
    "            max_val = max(x_data.max(), y_data.max())\n",
    "            min_val = min(x_data.min(), y_data.min())\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], 'k:', alpha=0.5, label='1:1 line')\n",
    "            \n",
    "            ax.set_xlabel('Regression-Corrected Red BC (μg/m³)', fontsize=12)\n",
    "            ax.set_ylabel('FTIR EC (μg/m³)', fontsize=12)\n",
    "            ax.set_title(f'Red Wavelength: Aethalometer vs FTIR-EC\\n(Regression-corrected: BC × 0.85 - 0.17, n={len(x_data)})', fontsize=14)\n",
    "            \n",
    "            # Statistics text\n",
    "            stats_text = (f'R² = {r_value**2:.3f}\\n'\n",
    "                         f'Slope = {slope:.3f}\\n'\n",
    "                         f'Intercept = {intercept:.3f}\\n'\n",
    "                         f'p-value = {p_value:.2e}')\n",
    "            ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                   verticalalignment='top', fontsize=10)\n",
    "            \n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "else:\n",
    "    print(\"❌ Cannot create Red plots - missing required data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hips_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aethalometer vs HIPS Comparison Plots\n",
    "print(\"📊 Creating Aethalometer vs HIPS Comparison Plots\")\n",
    "\n",
    "# Note: HIPS data would typically be BC_PM25 from speciation data\n",
    "if final_merged is not None and 'BC_PM25' in final_merged.columns:\n",
    "    \n",
    "    hips_bc = final_merged['BC_PM25'].dropna()\n",
    "    print(f\"🔬 HIPS BC data available: {len(hips_bc)} samples\")\n",
    "    \n",
    "    # Check if we have Iron data for color-coding\n",
    "    use_fe_coloring = 'Iron' in final_merged.columns and final_merged['Iron'].notna().sum() > 5\n",
    "    \n",
    "    if use_fe_coloring:\n",
    "        print(\"🔬 Using Iron concentration for color-coding\")\n",
    "        colormap = 'coolwarm'\n",
    "        color_label = 'Iron (μg/m³)'\n",
    "    else:\n",
    "        print(\"⚠️ No Iron data - using default coloring\")\n",
    "        colormap = None\n",
    "        color_label = None\n",
    "    \n",
    "    # Plot 1: Ethiopia-corrected IR BC vs HIPS BC\n",
    "    if 'IR_BC_ug' in final_merged.columns:\n",
    "        ir_bc_ug = final_merged['IR_BC_ug'].dropna()\n",
    "        common_idx = ir_bc_ug.index.intersection(hips_bc.index)\n",
    "        \n",
    "        if len(common_idx) > 3:\n",
    "            x_data = ir_bc_ug.loc[common_idx]\n",
    "            y_data = hips_bc.loc[common_idx]\n",
    "            \n",
    "            # Get Iron data for coloring if available\n",
    "            if use_fe_coloring:\n",
    "                color_data = final_merged.loc[common_idx, 'Iron']\n",
    "                # Remove any NaN Iron values\n",
    "                valid_color_idx = color_data.notna()\n",
    "                x_data = x_data[valid_color_idx]\n",
    "                y_data = y_data[valid_color_idx]\n",
    "                color_data = color_data[valid_color_idx]\n",
    "            else:\n",
    "                color_data = None\n",
    "            \n",
    "            # Calculate regression\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            if use_fe_coloring and color_data is not None:\n",
    "                scatter = ax.scatter(x_data, y_data, c=color_data, cmap=colormap, \n",
    "                                   alpha=0.7, s=60, edgecolor='black', linewidth=0.5)\n",
    "                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                cbar.set_label(color_label, fontsize=12)\n",
    "            else:\n",
    "                ax.scatter(x_data, y_data, alpha=0.7, color='green', s=60, \n",
    "                          edgecolor='black', linewidth=0.5)\n",
    "            \n",
    "            # Add regression line\n",
    "            line_x = np.linspace(x_data.min(), x_data.max(), 100)\n",
    "            line_y = slope * line_x + intercept\n",
    "            ax.plot(line_x, line_y, 'r--', alpha=0.8, linewidth=2, \n",
    "                   label=f'y = {slope:.3f}x + {intercept:.3f}')\n",
    "            \n",
    "            # Add 1:1 line\n",
    "            max_val = max(x_data.max(), y_data.max())\n",
    "            min_val = min(x_data.min(), y_data.min())\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], 'k:', alpha=0.5, label='1:1 line')\n",
    "            \n",
    "            ax.set_xlabel('Ethiopia-Corrected IR BC (μg/m³)', fontsize=12)\n",
    "            ax.set_ylabel('HIPS BC (μg/m³)', fontsize=12)\n",
    "            ax.set_title(f'Aethalometer vs HIPS BC Comparison\\n(Ethiopia-corrected, n={len(x_data)})', fontsize=14)\n",
    "            \n",
    "            # Statistics text\n",
    "            stats_text = (f'R² = {r_value**2:.3f}\\n'\n",
    "                         f'Slope = {slope:.3f}\\n'\n",
    "                         f'Intercept = {intercept:.3f}\\n'\n",
    "                         f'p-value = {p_value:.2e}')\n",
    "            ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                   verticalalignment='top', fontsize=10)\n",
    "            \n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # Plot 2: Regression-corrected IR BC vs HIPS BC\n",
    "    if 'IR_BC_regression_corrected' in final_merged.columns:\n",
    "        ir_bc_regress = final_merged['IR_BC_regression_corrected'].dropna()\n",
    "        common_idx = ir_bc_regress.index.intersection(hips_bc.index)\n",
    "        \n",
    "        if len(common_idx) > 3:\n",
    "            x_data = ir_bc_regress.loc[common_idx]\n",
    "            y_data = hips_bc.loc[common_idx]\n",
    "            \n",
    "            # Get Iron data for coloring if available\n",
    "            if use_fe_coloring:\n",
    "                color_data = final_merged.loc[common_idx, 'Iron']\n",
    "                # Remove any NaN Iron values\n",
    "                valid_color_idx = color_data.notna()\n",
    "                x_data = x_data[valid_color_idx]\n",
    "                y_data = y_data[valid_color_idx]\n",
    "                color_data = color_data[valid_color_idx]\n",
    "            else:\n",
    "                color_data = None\n",
    "            \n",
    "            # Calculate regression\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "            \n",
    "            # Create plot\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            if use_fe_coloring and color_data is not None:\n",
    "                scatter = ax.scatter(x_data, y_data, c=color_data, cmap=colormap, \n",
    "                                   alpha=0.7, s=60, edgecolor='black', linewidth=0.5)\n",
    "                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                cbar.set_label(color_label, fontsize=12)\n",
    "            else:\n",
    "                ax.scatter(x_data, y_data, alpha=0.7, color='darkgreen', s=60, \n",
    "                          edgecolor='black', linewidth=0.5)\n",
    "            \n",
    "            # Add regression line\n",
    "            line_x = np.linspace(x_data.min(), x_data.max(), 100)\n",
    "            line_y = slope * line_x + intercept\n",
    "            ax.plot(line_x, line_y, 'r--', alpha=0.8, linewidth=2, \n",
    "                   label=f'y = {slope:.3f}x + {intercept:.3f}')\n",
    "            \n",
    "            # Add 1:1 line\n",
    "            max_val = max(x_data.max(), y_data.max())\n",
    "            min_val = min(x_data.min(), y_data.min())\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], 'k:', alpha=0.5, label='1:1 line')\n",
    "            \n",
    "            ax.set_xlabel('Regression-Corrected IR BC (μg/m³)', fontsize=12)\n",
    "            ax.set_ylabel('HIPS BC (μg/m³)', fontsize=12)\n",
    "            ax.set_title(f'Aethalometer vs HIPS BC Comparison\\n(Regression-corrected: BC × 0.85 - 0.17, n={len(x_data)})', fontsize=14)\n",
    "            \n",
    "            # Statistics text\n",
    "            stats_text = (f'R² = {r_value**2:.3f}\\n'\n",
    "                         f'Slope = {slope:.3f}\\n'\n",
    "                         f'Intercept = {intercept:.3f}\\n'\n",
    "                         f'p-value = {p_value:.2e}')\n",
    "            ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                   verticalalignment='top', fontsize=10)\n",
    "            \n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "else:\n",
    "    print(\"❌ Cannot create HIPS comparison plots - BC_PM25 data not available\")\n",
    "    if final_merged is not None:\n",
    "        available_bc_cols = [col for col in final_merged.columns if 'BC' in col]\n",
    "        print(f\"Available BC columns: {available_bc_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_and_save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and save results\n",
    "print(\"📋 SPARTAN SPECIATION ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if final_merged is not None:\n",
    "    print(f\"🎉 Analysis completed successfully!\")\n",
    "    print(f\"\")\n",
    "    print(f\"📊 Final dataset: {final_merged.shape}\")\n",
    "    print(f\"📅 Date range: {final_merged.index.min()} to {final_merged.index.max()}\")\n",
    "    \n",
    "    # Count data availability\n",
    "    ftir_count = final_merged['EC_ftir'].notna().sum() if 'EC_ftir' in final_merged.columns else 0\n",
    "    speciation_count = final_merged['Iron'].notna().sum() if 'Iron' in final_merged.columns else 0\n",
    "    bc_pm25_count = final_merged['BC_PM25'].notna().sum() if 'BC_PM25' in final_merged.columns else 0\n",
    "    \n",
    "    print(f\"\")\n",
    "    print(f\"📈 Data Availability:\")\n",
    "    print(f\"  🧪 FTIR EC: {ftir_count} samples\")\n",
    "    print(f\"  🔬 Iron (for color-coding): {speciation_count} samples\")\n",
    "    print(f\"  🧬 HIPS BC_PM25: {bc_pm25_count} samples\")\n",
    "    \n",
    "    # Show seasonal distribution if available\n",
    "    if 'season' in final_merged.columns:\n",
    "        season_counts = final_merged['season'].value_counts()\n",
    "        print(f\"\")\n",
    "        print(f\"🌍 Ethiopian Seasonal Distribution:\")\n",
    "        for season, count in season_counts.items():\n",
    "            print(f\"  {season}: {count} samples\")\n",
    "    \n",
    "    # Save the final dataset\n",
    "    output_file = \"SPARTAN_Speciation_Merged_Analysis.pkl\"\n",
    "    final_merged.to_pickle(output_file)\n",
    "    print(f\"\\n💾 Saved final dataset to: {output_file}\")\n",
    "    \n",
    "    # Save as CSV for easy viewing\n",
    "    csv_file = \"SPARTAN_Speciation_Merged_Analysis.csv\"\n",
    "    final_merged.to_csv(csv_file)\n",
    "    print(f\"💾 Saved CSV version to: {csv_file}\")\n",
    "    \n",
    "    print(f\"\")\n",
    "    print(f\"🎯 Analysis Features Completed:\")\n",
    "    print(f\"  ✅ SPARTAN speciation data integration\")\n",
    "    print(f\"  ✅ 9AM-to-9AM daily averaging\")\n",
    "    print(f\"  ✅ Ethiopia loading effect corrections\")\n",
    "    print(f\"  ✅ Linear regression corrections (BC × 0.85 - 0.17)\")\n",
    "    print(f\"  ✅ Iron-concentration color-coding\")\n",
    "    print(f\"  ✅ IR wavelength scatter plots\")\n",
    "    print(f\"  ✅ Red wavelength scatter plots\")\n",
    "    print(f\"  ✅ HIPS comparison plots\")\n",
    "    print(f\"  ✅ Ethiopian seasonal classification\")\n",
    "    \n",
    "    print(f\"\")\n",
    "    print(f\"📚 Available Chemical Species:\")\n",
    "    spec_cols = [col for col in final_merged.columns if any(x in col for x in \n",
    "                ['Ion', 'Iron', 'Aluminum', 'Potassium', 'Sulfate', 'Nitrate'])]\n",
    "    print(f\"  🧪 {len(spec_cols)} species: {spec_cols[:8]}...\" if len(spec_cols) > 8 else f\"  🧪 {spec_cols}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ Analysis could not be completed - check data loading steps\")\n",
    "\n",
    "print(f\"\\n🏁 SPARTAN Speciation Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
