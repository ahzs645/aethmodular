{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Aethalometer Data Analysis\n",
    "\n",
    "This notebook demonstrates the **dramatically simplified** approach to aethalometer data analysis using the new modular system.\n",
    "\n",
    "## 🎯 What's New?\n",
    "\n",
    "- **One-line setup**: `setup, datasets = load_etad_data()`\n",
    "- **Automatic quality assessment**: Built into the loading process\n",
    "- **Intelligent fallbacks**: Modular system + fallback loading automatically\n",
    "- **Clean data access**: Simple methods to get exactly what you need\n",
    "- **Easy customization**: Configuration-driven approach\n",
    "\n",
    "## 📋 Comparison\n",
    "\n",
    "**OLD**: 200+ lines of complex setup code  \n",
    "**NEW**: 2 lines to load everything\n",
    "\n",
    "Let's see it in action! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 🚀 Configurable Data Loading\n",
    "\n",
    "You now have full control over the configuration. The setup below shows:\n",
    "- **Explicit configuration parameters** - easily change site code, wavelength, quality thresholds\n",
    "- **Clear file paths** - see exactly what files are being loaded\n",
    "- **Multiple options** - use default configs, create custom ones, or modify parameters\n",
    "\n",
    "This replaces 200+ lines of complex setup code from the original notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Advanced plotting style configured\n",
      "🚀 Aethalometer-FTIR/HIPS Pipeline with Simplified Setup\n",
      "============================================================\n",
      "📊 Configuration Summary:\n",
      "   Site: ETAD\n",
      "   Wavelength: Red\n",
      "   Output format: jpl\n",
      "   Quality threshold: 10 minutes\n",
      "   Output directory: outputs\n",
      "\n",
      "📁 File paths:\n",
      "   pkl_data: ✅ df_uncleaned_Jacros_API_and_OG.pkl\n",
      "   csv_data: ✅ Jacros_MA350_1-min_2022-2024_Cleaned.csv\n",
      "   FTIR DB: ✅ spartan_ftir_hips.db\n",
      "📁 Loading datasets...\n",
      "📦 Setting up modular system...\n",
      "✅ Aethalometer loaders imported\n",
      "✅ Database loader imported\n",
      "✅ Plotting utilities imported\n",
      "✅ Plotting style configured\n",
      "✅ Successfully imported 5 modular components\n",
      "\n",
      "============================================================\n",
      "📁 LOADING DATASETS\n",
      "============================================================\n",
      "📁 Loading all datasets...\n",
      "\n",
      "==================================================\n",
      "📊 Loading pkl_data\n",
      "==================================================\n",
      "📁 Loading pkl_data: df_uncleaned_Jacros_API_and_OG.pkl\n",
      "Detected format: standard\n",
      "Set 'datetime_local' as DatetimeIndex for time series operations\n",
      "Converted 17 columns to JPL format\n",
      "Warning: Missing recommended columns: ['datetime_local', 'Biomass.BCc', 'Fossil.fuel.BCc']\n",
      "✅ Modular load: 1,665,156 rows × 238 columns\n",
      "📊 Method: modular\n",
      "📊 Format: jpl\n",
      "📊 Memory: 7443.05 MB\n",
      "🧮 BC columns: 30\n",
      "📈 ATN columns: 25\n",
      "📅 Time range: 2021-01-09 16:38:00 to 2025-06-26 23:18:00\n",
      "✅ pkl_data loaded successfully\n",
      "\n",
      "==================================================\n",
      "📊 Loading csv_data\n",
      "==================================================\n",
      "📁 Loading csv_data: Jacros_MA350_1-min_2022-2024_Cleaned.csv\n",
      "Set 'Time (Local)' as DatetimeIndex for time series operations\n",
      "Converted 5 columns to JPL format\n",
      "✅ Modular load: 1,095,086 rows × 77 columns\n",
      "📊 Method: modular\n",
      "📊 Format: jpl\n",
      "📊 Memory: 884.83 MB\n",
      "🧮 BC columns: 15\n",
      "📈 ATN columns: 10\n",
      "📅 Time range: 2022-04-12 12:46:01+03:00 to 2024-08-20 12:01:00+03:00\n",
      "✅ csv_data loaded successfully\n",
      "\n",
      "==================================================\n",
      "🗃️ Loading FTIR/HIPS data\n",
      "==================================================\n",
      "🗃️ Loading FTIR/HIPS data for site ETAD...\n",
      "📊 Available sites: ['ILNZ', 'ILHA', 'ZAJB', 'CAHA', 'CASH', 'AEAZ', 'AUMN', 'KRUL', 'MXMC', 'ZAPR', 'CHTS', 'ETAD', 'INDH', 'TWTA', 'USPA', 'TWKA', 'KRSE', 'PRFJ', 'BDDU', 'BIBU', 'USNO', 'IDBD', None]\n",
      "✅ Modular FTIR load: 168 samples\n",
      "📅 Date range: 2022-12-07 00:00:00 to 2024-05-12 00:00:00\n",
      "✅ FTIR/HIPS data loaded successfully\n",
      "\n",
      "📊 Loading summary: 3 datasets loaded\n",
      "\n",
      "📊 LOADING SUMMARY\n",
      "============================================================\n",
      "✅ Successfully loaded 3 datasets\n",
      "   - pkl_data: 1,665,156 rows × 238 columns\n",
      "   - csv_data: 1,095,086 rows × 77 columns\n",
      "   - ftir_hips: 168 rows × 12 columns\n",
      "============================================================\n",
      "\n",
      "🔍 Assessing data quality...\n",
      "\n",
      "================================================================================\n",
      "🔍 MULTI-DATASET QUALITY ASSESSMENT\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "🔍 Analyzing pkl_data data quality...\n",
      "📊 Quality threshold: ≤10 missing minutes per 24h period\n",
      "📅 Time range: 2021-01-09 16:38:00 to 2025-06-26 23:18:00\n",
      "📊 Actual data points: 1,665,156\n",
      "📊 Expected data points (1-min resolution): 2,346,161\n",
      "⚠️ Missing data points: 681,005\n",
      "📊 Data completeness: 71.0%\n",
      "📅 Analyzing 1630 24-hour periods...\n",
      "✅ Quality assessment complete for pkl_data\n",
      "📊 Total 24h periods: 1630\n",
      "🌟 Excellent periods: 1036\n",
      "📈 Excellence rate: 63.6%\n",
      "📅 Excellent periods range: 2021-02-18 09:00:00 to 2025-06-25 09:00:00\n",
      "📊 Missing minutes distribution:\n",
      "   0 minutes missing: 778 periods\n",
      "   1-5 minutes missing: 239 periods\n",
      "   6-10 minutes missing: 19 periods\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "🔍 Analyzing csv_data data quality...\n",
      "📊 Quality threshold: ≤10 missing minutes per 24h period\n",
      "📅 Time range: 2022-04-12 12:46:01+03:00 to 2024-08-20 12:01:00+03:00\n",
      "📊 Actual data points: 1,095,086\n",
      "📊 Expected data points (1-min resolution): 1,239,795\n",
      "⚠️ Missing data points: 144,709\n",
      "📊 Data completeness: 88.3%\n",
      "📅 Analyzing 862 24-hour periods...\n",
      "✅ Quality assessment complete for csv_data\n",
      "📊 Total 24h periods: 862\n",
      "🌟 Excellent periods: 712\n",
      "📈 Excellence rate: 82.6%\n",
      "📅 Excellent periods range: 2022-04-13 09:00:00+03:00 to 2024-08-19 09:00:00+03:00\n",
      "📊 Missing minutes distribution:\n",
      "   0 minutes missing: 104 periods\n",
      "   1-5 minutes missing: 599 periods\n",
      "   6-10 minutes missing: 9 periods\n",
      "============================================================\n",
      "\n",
      "⚠️ Skipping FTIR dataset ftir_hips (not time-series)\n",
      "\n",
      "================================================================================\n",
      "📊 COMPARATIVE QUALITY SUMMARY\n",
      "================================================================================\n",
      " Dataset  Total Periods  Excellent Periods Excellence Rate (%) Data Completeness (%) Missing Points\n",
      "pkl_data           1630               1036               63.6%                 71.0%        681,005\n",
      "csv_data            862                712               82.6%                 88.3%        144,709\n",
      "\n",
      "🏆 Best quality dataset: csv_data (82.6% excellent)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "📊 COMPREHENSIVE DATA SUMMARY\n",
      "================================================================================\n",
      "\n",
      "🔧 Configuration:\n",
      "   Site: ETAD\n",
      "   Wavelength: Red\n",
      "   Output format: jpl\n",
      "   Quality threshold: 10 minutes\n",
      "\n",
      "📁 Loaded datasets: 3\n",
      "   - pkl_data: 1,665,156 rows × 238 columns\n",
      "     📅 Time range: 2021-01-09 16:38:00 to 2025-06-26 23:18:00\n",
      "   - csv_data: 1,095,086 rows × 77 columns\n",
      "     📅 Time range: 2022-04-12 12:46:01+03:00 to 2024-08-20 12:01:00+03:00\n",
      "   - ftir_hips: 168 rows × 12 columns\n",
      "\n",
      "🔍 Quality assessment:\n",
      "   - pkl_data: 1036/1630 excellent periods (63.6%)\n",
      "   - csv_data: 712/862 excellent periods (82.6%)\n",
      "\n",
      "🧮 Red BC columns:\n",
      "   - pkl_data: ['Red BC1', 'Red BC2', 'Red.BCc']\n",
      "   - csv_data: ['Red BC1', 'Red BC2', 'Red.BCc']\n",
      "================================================================================\n",
      "📊 Using BC column: Red BC1\n",
      "\n",
      "✅ Complete! All data loaded, modular system configured, quality assessed.\n",
      "\n",
      "📚 Available datasets: ['pkl_data', 'csv_data', 'ftir_hips']\n",
      "🔧 Current configuration: Site=ETAD, Wavelength=Red\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "# Import the necessary modules for more explicit configuration\n",
    "from notebook_utils.setup import NotebookSetup, create_custom_config\n",
    "from config.notebook_config import NotebookConfig, ConfigurationManager\n",
    "\n",
    "# Option 1: Use default ETAD configuration with explicit parameters\n",
    "config = NotebookConfig(\n",
    "    site_code='ETAD',\n",
    "    wavelength='Red',  # Choose from: 'Red', 'Blue', 'Green', 'UV', 'IR'\n",
    "    quality_threshold=10,  # Maximum missing minutes for \"excellent\" quality\n",
    "    output_format='jpl',  # 'jpl' or 'standard' format\n",
    "    min_samples_for_analysis=30,\n",
    "    confidence_level=0.95,\n",
    "    outlier_threshold=3.0,\n",
    "    figure_size=(12, 8),\n",
    "    font_size=10,\n",
    "    dpi=300\n",
    ")\n",
    "\n",
    "# Set ETAD-specific file paths\n",
    "base_data_path = \"/Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data\"\n",
    "\n",
    "config.aethalometer_files = {\n",
    "    'pkl_data': os.path.join(\n",
    "        base_data_path,\n",
    "        \"Aethelometry Data/Kyan Data/Mergedcleaned and uncleaned MA350 data20250707030704\",\n",
    "        \"df_uncleaned_Jacros_API_and_OG.pkl\"\n",
    "    ),\n",
    "    'csv_data': os.path.join(\n",
    "        base_data_path,\n",
    "        \"Aethelometry Data/Raw\",\n",
    "        \"Jacros_MA350_1-min_2022-2024_Cleaned.csv\"\n",
    "    )\n",
    "}\n",
    "\n",
    "config.ftir_db_path = os.path.join(\n",
    "    base_data_path,\n",
    "    \"EC-HIPS-Aeth Comparison/Data/Original Data/Combined Database\",\n",
    "    \"spartan_ftir_hips.db\"\n",
    ")\n",
    "\n",
    "# Option 2: Or use the configuration manager for ETAD defaults\n",
    "# config = ConfigurationManager.create_etad_config(base_data_path)\n",
    "\n",
    "# Option 3: Or create a custom configuration for a different site\n",
    "# config = create_custom_config(\n",
    "#     site_code='MYSITE',\n",
    "#     aethalometer_files={'data': '/path/to/data.pkl'},\n",
    "#     ftir_db_path='/path/to/database.db',\n",
    "#     wavelength='Blue',\n",
    "#     quality_threshold=15,\n",
    "#     output_format='standard'\n",
    "# )\n",
    "\n",
    "# Create setup with the explicit configuration\n",
    "setup = NotebookSetup(config)\n",
    "\n",
    "# Load all datasets\n",
    "print(\"📁 Loading datasets...\")\n",
    "datasets = setup.load_all_data()\n",
    "\n",
    "# Assess data quality\n",
    "print(\"\\n🔍 Assessing data quality...\")\n",
    "quality_results = setup.assess_data_quality()\n",
    "\n",
    "# Print comprehensive summary\n",
    "setup.print_summary()\n",
    "\n",
    "# Access specific datasets\n",
    "pkl_data = setup.get_dataset('pkl_data')\n",
    "csv_data = setup.get_dataset('csv_data')\n",
    "ftir_data = setup.get_ftir_data()\n",
    "\n",
    "# Get BC data for the configured wavelength\n",
    "red_bc = setup.get_bc_data_for_wavelength('pkl_data', 'Red')\n",
    "\n",
    "# Get excellent quality periods\n",
    "excellent_periods = setup.get_excellent_periods('pkl_data')\n",
    "\n",
    "print(\"\\n✅ Complete! All data loaded, modular system configured, quality assessed.\")\n",
    "print(f\"\\n📚 Available datasets: {list(datasets.keys())}\")\n",
    "print(f\"🔧 Current configuration: Site={config.site_code}, Wavelength={config.wavelength}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 📊 Explore What Was Loaded\n",
    "\n",
    "Let's see what we got with that simple command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📊 COMPREHENSIVE DATA SUMMARY\n",
      "================================================================================\n",
      "\n",
      "🔧 Configuration:\n",
      "   Site: ETAD\n",
      "   Wavelength: Red\n",
      "   Output format: jpl\n",
      "   Quality threshold: 10 minutes\n",
      "\n",
      "📁 Loaded datasets: 3\n",
      "   - pkl_data: 1,665,156 rows × 238 columns\n",
      "     📅 Time range: 2021-01-09 16:38:00 to 2025-06-26 23:18:00\n",
      "   - csv_data: 1,095,086 rows × 77 columns\n",
      "     📅 Time range: 2022-04-12 12:46:01+03:00 to 2024-08-20 12:01:00+03:00\n",
      "   - ftir_hips: 168 rows × 12 columns\n",
      "\n",
      "🔍 Quality assessment:\n",
      "   - pkl_data: 1036/1630 excellent periods (63.6%)\n",
      "   - csv_data: 712/862 excellent periods (82.6%)\n",
      "\n",
      "🧮 Red BC columns:\n",
      "   - pkl_data: ['Red BC1', 'Red BC2', 'Red.BCc']\n",
      "   - csv_data: ['Red BC1', 'Red BC2', 'Red.BCc']\n",
      "================================================================================\n",
      "\n",
      "🔧 Quick access to configuration:\n",
      "Site: ETAD\n",
      "Wavelength: Red\n",
      "Quality threshold: 10 minutes\n",
      "Output format: jpl\n"
     ]
    }
   ],
   "source": [
    "# Show comprehensive summary\n",
    "setup.print_summary()\n",
    "\n",
    "print(\"\\n🔧 Quick access to configuration:\")\n",
    "print(f\"Site: {setup.config.site_code}\")\n",
    "print(f\"Wavelength: {setup.config.wavelength}\")\n",
    "print(f\"Quality threshold: {setup.config.quality_threshold} minutes\")\n",
    "print(f\"Output format: {setup.config.output_format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 🎯 Get Specific Data for Analysis\n",
    "\n",
    "Clean, simple access to exactly what you need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Using BC column: Red BC1\n",
      "📊 Data Summary:\n",
      "   PKL data: (1665156, 238)\n",
      "   CSV data: (1095086, 77)\n",
      "   FTIR data: (168, 12)\n",
      "   Red BC data: (1665156,)\n",
      "   Excellent periods: 1036\n"
     ]
    }
   ],
   "source": [
    "# Get specific datasets with simple method calls\n",
    "pkl_data = setup.get_dataset('pkl_data')\n",
    "csv_data = setup.get_dataset('csv_data') \n",
    "ftir_data = setup.get_ftir_data()\n",
    "\n",
    "# Get BC data for configured wavelength (automatic column detection)\n",
    "red_bc = setup.get_bc_data_for_wavelength('pkl_data')\n",
    "\n",
    "# Get quality assessment results  \n",
    "excellent_periods = setup.get_excellent_periods('pkl_data')\n",
    "\n",
    "print(f\"📊 Data Summary:\")\n",
    "print(f\"   PKL data: {pkl_data.shape if pkl_data is not None else 'Not available'}\")\n",
    "print(f\"   CSV data: {csv_data.shape if csv_data is not None else 'Not available'}\")\n",
    "print(f\"   FTIR data: {ftir_data.shape if ftir_data is not None else 'Not available'}\")\n",
    "print(f\"   Red BC data: {red_bc.shape if red_bc is not None else 'Not available'}\")\n",
    "print(f\"   Excellent periods: {len(excellent_periods) if excellent_periods is not None else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 🔍 Quality Assessment Results\n",
    "\n",
    "Quality assessment was done automatically during loading. Let's examine the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access quality results that were computed automatically\n",
    "if setup.quality_results:\n",
    "    print(\"📊 Quality Assessment Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for dataset_name, result in setup.quality_results.items():\n",
    "        print(f\"\\n📋 {dataset_name}:\")\n",
    "        print(f\"   Total 24h periods: {result.total_periods}\")\n",
    "        print(f\"   Excellent periods: {result.excellent_periods}\")\n",
    "        print(f\"   Excellence rate: {result.excellent_percentage:.1f}%\")\n",
    "        print(f\"   Data completeness: {result.data_completeness:.1f}%\")\n",
    "        print(f\"   Missing data points: {result.missing_points:,}\")\n",
    "        \n",
    "        if len(result.excellent_periods_df) > 0:\n",
    "            print(f\"   First excellent period: {result.excellent_periods_df.iloc[0]['start_time']}\")\n",
    "            print(f\"   Last excellent period: {result.excellent_periods_df.iloc[-1]['start_time']}\")\n",
    "    \n",
    "    # Find the best quality dataset\n",
    "    best_dataset = max(setup.quality_results.items(), key=lambda x: x[1].excellent_percentage)\n",
    "    print(f\"\\n🏆 Best quality dataset: {best_dataset[0]} ({best_dataset[1].excellent_percentage:.1f}% excellent)\")\n",
    "else:\n",
    "    print(\"⚠️ No quality results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 📈 Quick Visualization\n",
    "\n",
    "Let's visualize some data from an excellent quality period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Plot BC data for an excellent quality period\n",
    "if excellent_periods is not None and len(excellent_periods) > 0 and red_bc is not None:\n",
    "    \n",
    "    # Get the first excellent period\n",
    "    first_period = excellent_periods.iloc[0]\n",
    "    period_start = first_period['start_time']\n",
    "    period_end = first_period['end_time']\n",
    "    \n",
    "    # Get BC data for this period\n",
    "    period_bc = red_bc.loc[period_start:period_end]\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Main time series plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(period_bc.index, period_bc.values, linewidth=1, alpha=0.8)\n",
    "    plt.title(f'Black Carbon Time Series - Excellent Quality Period\\n'\n",
    "              f'{period_start.strftime(\"%Y-%m-%d %H:%M\")} to {period_end.strftime(\"%Y-%m-%d %H:%M\")}\\n'\n",
    "              f'Missing minutes: {first_period[\"missing_minutes\"]}/{setup.config.quality_threshold} threshold')\n",
    "    plt.ylabel(f'{setup.config.wavelength} BC (μg/m³)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogram\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.hist(period_bc.dropna().values, bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.title('BC Distribution for This Period')\n",
    "    plt.xlabel(f'{setup.config.wavelength} BC (μg/m³)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"📊 Period Statistics:\")\n",
    "    print(f\"   Data points: {len(period_bc):,}\")\n",
    "    print(f\"   Mean BC: {period_bc.mean():.2f} μg/m³\")\n",
    "    print(f\"   Std BC: {period_bc.std():.2f} μg/m³\")\n",
    "    print(f\"   Min BC: {period_bc.min():.2f} μg/m³\")\n",
    "    print(f\"   Max BC: {period_bc.max():.2f} μg/m³\")\n",
    "    print(f\"   Data completeness: {first_period['completeness_pct']:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ No excellent periods or BC data available for plotting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 🔬 Advanced Analysis with Modular System\n",
    "\n",
    "The setup automatically detects if modular analyzers are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use advanced modular analyzers\n",
    "try:\n",
    "    from analysis.bc.black_carbon_analyzer import BlackCarbonAnalyzer\n",
    "    \n",
    "    print(\"✅ Modular analyzers available!\")\n",
    "    \n",
    "    if pkl_data is not None:\n",
    "        # Run sophisticated analysis using the modular system\n",
    "        analyzer = BlackCarbonAnalyzer()\n",
    "        results = analyzer.analyze(pkl_data)\n",
    "        \n",
    "        print(f\"\\n📊 Advanced Analysis Results:\")\n",
    "        print(f\"   Analysis type: {results.get('analysis_type', 'Unknown')}\")\n",
    "        print(f\"   Results keys: {list(results.keys())}\")\n",
    "        \n",
    "        # Show some results if available\n",
    "        if 'summary_statistics' in results:\n",
    "            stats = results['summary_statistics']\n",
    "            print(f\"\\n📈 Summary Statistics:\")\n",
    "            for key, value in stats.items():\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"   {key}: {value:.3f}\")\n",
    "                else:\n",
    "                    print(f\"   {key}: {value}\")\n",
    "    else:\n",
    "        print(\"⚠️ No PKL data available for advanced analysis\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"⚠️ Advanced modular analyzers not available\")\n",
    "    print(\"💡 Using basic analysis instead...\")\n",
    "    \n",
    "    # Fallback to basic analysis\n",
    "    if red_bc is not None:\n",
    "        print(f\"\\n📊 Basic BC Statistics:\")\n",
    "        print(f\"   Data points: {len(red_bc.dropna()):,}\")\n",
    "        print(f\"   Mean: {red_bc.mean():.3f} μg/m³\")\n",
    "        print(f\"   Std: {red_bc.std():.3f} μg/m³\")\n",
    "        print(f\"   Median: {red_bc.median():.3f} μg/m³\")\n",
    "        print(f\"   Min: {red_bc.min():.3f} μg/m³\")\n",
    "        print(f\"   Max: {red_bc.max():.3f} μg/m³\")\n",
    "        \n",
    "        # Data quality check using configuration\n",
    "        min_samples = setup.config.min_samples_for_analysis\n",
    "        valid_data_points = len(red_bc.dropna())\n",
    "        \n",
    "        if valid_data_points >= min_samples:\n",
    "            print(f\"   ✅ Sufficient data for analysis ({valid_data_points:,} >= {min_samples:,})\")\n",
    "        else:\n",
    "            print(f\"   ⚠️ Insufficient data for reliable analysis ({valid_data_points:,} < {min_samples:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 🎨 Multiple Wavelength Analysis\n",
    "\n",
    "Easy analysis across different wavelengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze multiple wavelengths easily\n",
    "wavelengths = ['Red', 'Blue', 'Green', 'UV', 'IR']\n",
    "bc_data = {}\n",
    "bc_stats = {}\n",
    "\n",
    "print(\"🌈 Multi-wavelength BC Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for wavelength in wavelengths:\n",
    "    bc_series = setup.get_bc_data_for_wavelength('pkl_data', wavelength)\n",
    "    \n",
    "    if bc_series is not None and len(bc_series.dropna()) > 0:\n",
    "        bc_data[wavelength] = bc_series\n",
    "        \n",
    "        # Calculate statistics\n",
    "        valid_data = bc_series.dropna()\n",
    "        bc_stats[wavelength] = {\n",
    "            'count': len(valid_data),\n",
    "            'mean': valid_data.mean(),\n",
    "            'std': valid_data.std(),\n",
    "            'median': valid_data.median(),\n",
    "            'min': valid_data.min(),\n",
    "            'max': valid_data.max()\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n📊 {wavelength} BC:\")\n",
    "        print(f\"   Points: {bc_stats[wavelength]['count']:,}\")\n",
    "        print(f\"   Mean: {bc_stats[wavelength]['mean']:.3f} μg/m³\")\n",
    "        print(f\"   Std: {bc_stats[wavelength]['std']:.3f} μg/m³\")\n",
    "        print(f\"   Range: {bc_stats[wavelength]['min']:.3f} - {bc_stats[wavelength]['max']:.3f} μg/m³\")\n",
    "    else:\n",
    "        print(f\"\\n❌ {wavelength} BC: No data available\")\n",
    "\n",
    "print(f\"\\n✅ Available wavelengths: {list(bc_data.keys())}\")\n",
    "\n",
    "# Quick comparison plot if we have multiple wavelengths\n",
    "if len(bc_data) > 1:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    means = [bc_stats[w]['mean'] for w in bc_data.keys()]\n",
    "    stds = [bc_stats[w]['std'] for w in bc_data.keys()]\n",
    "    \n",
    "    plt.bar(range(len(bc_data)), means, yerr=stds, alpha=0.7, capsize=5)\n",
    "    plt.xlabel('Wavelength')\n",
    "    plt.ylabel('BC Concentration (μg/m³)')\n",
    "    plt.title('Mean BC Concentrations by Wavelength')\n",
    "    plt.xticks(range(len(bc_data)), list(bc_data.keys()))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 🔧 Easy Customization Examples\n",
    "\n",
    "The new system makes customization much easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Custom quality threshold analysis\n",
    "from analysis.quality.data_quality_assessment import assess_single_dataset\n",
    "\n",
    "if pkl_data is not None:\n",
    "    print(\"🔍 Custom Quality Analysis:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Compare different quality thresholds\n",
    "    thresholds = [5, 10, 15, 20]\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        custom_quality = assess_single_dataset(\n",
    "            df=pkl_data, \n",
    "            dataset_name='pkl_data', \n",
    "            quality_threshold=threshold\n",
    "        )\n",
    "        \n",
    "        print(f\"Threshold {threshold:2d} min: {custom_quality.excellent_periods:3d} excellent periods \"\n",
    "              f\"({custom_quality.excellent_percentage:5.1f}%)\")\n",
    "\n",
    "# Example 2: FTIR data exploration (if available)\n",
    "if ftir_data is not None:\n",
    "    print(f\"\\n🧪 FTIR Data Summary:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"Samples: {len(ftir_data)}\")\n",
    "    print(f\"Date range: {ftir_data['sample_date'].min()} to {ftir_data['sample_date'].max()}\")\n",
    "    \n",
    "    # Show available measurements\n",
    "    measurement_cols = [col for col in ftir_data.columns if any(x in col.lower() for x in ['ec', 'oc', 'fabs'])]\n",
    "    print(f\"Measurements: {measurement_cols}\")\n",
    "    \n",
    "    # Basic statistics for key measurements\n",
    "    if 'ec_ftir' in ftir_data.columns:\n",
    "        ec_data = ftir_data['ec_ftir'].dropna()\n",
    "        print(f\"\\nEC FTIR statistics:\")\n",
    "        print(f\"  Valid samples: {len(ec_data)}\")\n",
    "        print(f\"  Mean: {ec_data.mean():.3f}\")\n",
    "        print(f\"  Std: {ec_data.std():.3f}\")\n",
    "        print(f\"  Range: {ec_data.min():.3f} - {ec_data.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 💾 Save Results\n",
    "\n",
    "Easy saving using the configuration system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Output directory from configuration\n",
    "output_dir = setup.config.output_dir\n",
    "site_code = setup.config.site_code\n",
    "\n",
    "print(f\"💾 Saving results to: {output_dir}\")\n",
    "\n",
    "# Save excellent periods\n",
    "if excellent_periods is not None and len(excellent_periods) > 0:\n",
    "    excellent_periods_file = os.path.join(output_dir, f'{site_code}_excellent_periods.csv')\n",
    "    excellent_periods.to_csv(excellent_periods_file, index=False)\n",
    "    print(f\"✅ Saved excellent periods: {excellent_periods_file}\")\n",
    "\n",
    "# Save quality summary for all datasets\n",
    "if setup.quality_results:\n",
    "    quality_summary = []\n",
    "    \n",
    "    for dataset_name, result in setup.quality_results.items():\n",
    "        quality_summary.append({\n",
    "            'dataset': dataset_name,\n",
    "            'site_code': site_code,\n",
    "            'total_periods': result.total_periods,\n",
    "            'excellent_periods': result.excellent_periods,\n",
    "            'excellence_rate_pct': result.excellent_percentage,\n",
    "            'data_completeness_pct': result.data_completeness,\n",
    "            'missing_points': result.missing_points,\n",
    "            'quality_threshold_min': result.quality_threshold,\n",
    "            'start_date': result.time_range[0].strftime('%Y-%m-%d'),\n",
    "            'end_date': result.time_range[1].strftime('%Y-%m-%d')\n",
    "        })\n",
    "    \n",
    "    quality_summary_df = pd.DataFrame(quality_summary)\n",
    "    quality_file = os.path.join(output_dir, f'{site_code}_quality_summary.csv')\n",
    "    quality_summary_df.to_csv(quality_file, index=False)\n",
    "    print(f\"✅ Saved quality summary: {quality_file}\")\n",
    "\n",
    "# Save BC statistics for multiple wavelengths\n",
    "if bc_stats:\n",
    "    bc_summary = []\n",
    "    \n",
    "    for wavelength, stats in bc_stats.items():\n",
    "        bc_summary.append({\n",
    "            'site_code': site_code,\n",
    "            'wavelength': wavelength,\n",
    "            'count': stats['count'],\n",
    "            'mean_ugm3': stats['mean'],\n",
    "            'std_ugm3': stats['std'],\n",
    "            'median_ugm3': stats['median'],\n",
    "            'min_ugm3': stats['min'],\n",
    "            'max_ugm3': stats['max']\n",
    "        })\n",
    "    \n",
    "    bc_summary_df = pd.DataFrame(bc_summary)\n",
    "    bc_file = os.path.join(output_dir, f'{site_code}_bc_wavelength_summary.csv')\n",
    "    bc_summary_df.to_csv(bc_file, index=False)\n",
    "    print(f\"✅ Saved BC summary: {bc_file}\")\n",
    "\n",
    "# Save configuration for reproducibility\n",
    "config_summary = {\n",
    "    'site_code': setup.config.site_code,\n",
    "    'wavelength': setup.config.wavelength,\n",
    "    'quality_threshold_min': setup.config.quality_threshold,\n",
    "    'output_format': setup.config.output_format,\n",
    "    'min_samples_for_analysis': setup.config.min_samples_for_analysis,\n",
    "    'confidence_level': setup.config.confidence_level,\n",
    "    'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "config_df = pd.DataFrame([config_summary])\n",
    "config_file = os.path.join(output_dir, f'{site_code}_analysis_config.csv')\n",
    "config_df.to_csv(config_file, index=False)\n",
    "print(f\"✅ Saved configuration: {config_file}\")\n",
    "\n",
    "print(f\"\\n🎉 Analysis complete! All results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Summary: What We Accomplished\n",
    "\n",
    "### ✅ With Just 2 Lines of Code:\n",
    "```python\n",
    "from notebook_utils.setup import load_etad_data\n",
    "setup, datasets = load_etad_data()\n",
    "```\n",
    "\n",
    "### 🚀 We Automatically Got:\n",
    "1. **All data loaded** with intelligent fallbacks (modular system + direct loading)\n",
    "2. **Quality assessment completed** for all aethalometer datasets  \n",
    "3. **Configuration validated** and accessible throughout analysis\n",
    "4. **Clean data access methods** for any wavelength or dataset\n",
    "5. **Error handling** that tells us exactly what's available vs missing\n",
    "6. **Modular system integration** with graceful fallbacks\n",
    "\n",
    "### 📊 Compare This To Original Notebook:\n",
    "- **OLD**: 200+ lines of complex setup, scattered configuration, manual quality assessment\n",
    "- **NEW**: 2 lines for complete setup, everything automated and organized\n",
    "\n",
    "### 🔧 Easy Customization:\n",
    "- Different sites: Change configuration object\n",
    "- Different wavelengths: Use `get_bc_data_for_wavelength(dataset, wavelength)`\n",
    "- Different quality thresholds: Adjust in configuration or run custom assessment\n",
    "- Custom file paths: Create custom configuration\n",
    "\n",
    "### 🎉 Result:\n",
    "**More time analyzing data, less time fighting setup code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Next Steps\n",
    "\n",
    "### For Different Sites:\n",
    "```python\n",
    "from notebook_utils.setup import create_custom_config, quick_setup\n",
    "\n",
    "custom_config = create_custom_config(\n",
    "    site_code='BEIJING',\n",
    "    aethalometer_files={'data': '/path/to/beijing_data.pkl'},\n",
    "    ftir_db_path='/path/to/beijing_db.db',\n",
    "    wavelength='Blue'\n",
    ")\n",
    "\n",
    "beijing_setup = quick_setup(custom_config)\n",
    "beijing_datasets = beijing_setup.load_all_data()\n",
    "```\n",
    "\n",
    "### For Advanced Analysis:\n",
    "- Use the modular analyzers if available\n",
    "- Build custom analysis functions using the clean data access methods\n",
    "- Extend the configuration for your specific analysis needs\n",
    "\n",
    "### For Production Use:\n",
    "- Create site-specific configuration files\n",
    "- Build automated analysis pipelines using this simplified approach\n",
    "- Share notebooks easily since setup is standardized\n",
    "\n",
    "**Happy analyzing! 🎊**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
