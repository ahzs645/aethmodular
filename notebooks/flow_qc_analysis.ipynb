{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Data Quality Control Analysis\n",
    "\n",
    "This notebook performs quality control analysis on MA350 flow measurement data from two locations: Jacros and Pasadena.\n",
    "\n",
    "## Key Metrics:\n",
    "- **R** = Flow1 / Flow2 (target: 3.0)\n",
    "- **f1** = Flow1 / Flow_total (target: 0.75)\n",
    "- **f2** = Flow2 / Flow_total (target: 0.25)\n",
    "- **S** = (Flow1 + Flow2) / Flow_total (target: 1.00)\n",
    "- **T** = Flow_total / Flow_setpoint (target: 1.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Portable raw-data paths (override with AETHMODULAR_DATA_ROOT)\n",
    "_cwd = Path.cwd().resolve()\n",
    "_repo_root = next((p for p in [_cwd, *_cwd.parents] if (p / \"pyproject.toml\").exists()), _cwd)\n",
    "_data_root = Path(os.environ.get(\"AETHMODULAR_DATA_ROOT\", _repo_root / \"research\" / \"ftir_hips_chem\")).expanduser()\n",
    "def _resolve_raw_file(filename):\n",
    "    candidates = [\n",
    "        _data_root / \"Raw\" / filename,\n",
    "        _data_root / \"Aethelometry Data\" / \"Raw\" / filename,\n",
    "    ]\n",
    "    return next((p for p in candidates if p.exists()), candidates[0])\n",
    "jacros_path = _resolve_raw_file(\"Jacros_MA350_1-min_2022-2024_Cleaned.csv\")\n",
    "pasadena_path = _resolve_raw_file(\"Pasadena_MA350_1-min_2023-2024_Cleaned.csv\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Figure settings\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from both locations (fallback to synthetic sample data when CSVs are unavailable)\n",
    "def _synthetic_flow_df(location_name, periods):\n",
    "    rng = np.random.default_rng(42 if location_name == 'Jacros' else 84)\n",
    "    ts = pd.date_range('2023-01-01', periods=periods, freq='min', tz='UTC')\n",
    "    flow_setpoint = np.full(periods, 150.0)\n",
    "    flow_total = flow_setpoint * rng.normal(1.0, 0.03, periods)\n",
    "    flow1 = flow_total * rng.normal(0.75, 0.03, periods)\n",
    "    flow2 = np.maximum(flow_total - flow1, 1.0)\n",
    "    return pd.DataFrame({\n",
    "        'Time (UTC)': ts.astype(str),\n",
    "        'Flow setpoint (mL/min)': flow_setpoint,\n",
    "        'Flow total (mL/min)': flow_total,\n",
    "        'Flow1 (mL/min)': flow1,\n",
    "        'Flow2 (mL/min)': flow2,\n",
    "    })\n",
    "\n",
    "if jacros_path.exists():\n",
    "    jacros_df = pd.read_csv(jacros_path)\n",
    "else:\n",
    "    print(f\"⚠️ Missing {jacros_path}; using synthetic Jacros sample data.\")\n",
    "    jacros_df = _synthetic_flow_df('Jacros', periods=24 * 14)\n",
    "\n",
    "if pasadena_path.exists():\n",
    "    pasadena_df = pd.read_csv(pasadena_path)\n",
    "else:\n",
    "    print(f\"⚠️ Missing {pasadena_path}; using synthetic Pasadena sample data.\")\n",
    "    pasadena_df = _synthetic_flow_df('Pasadena', periods=24 * 10)\n",
    "\n",
    "# Add location identifier\n",
    "jacros_df['Location'] = 'Jacros'\n",
    "pasadena_df['Location'] = 'Pasadena'\n",
    "\n",
    "print(f\"Jacros data: {len(jacros_df)} records\")\n",
    "print(f\"Pasadena data: {len(pasadena_df)} records\")\n",
    "print(\"\\nColumn names:\")\n",
    "print(jacros_df.columns.tolist()[:30])  # Show first 30 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each dataset\n",
    "def process_flow_data(df, location_name):\n",
    "    \"\"\"\n",
    "    Process flow data and compute QC metrics\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original\n",
    "    df_proc = df.copy()\n",
    "    \n",
    "    # Parse datetime\n",
    "    df_proc['Timestamp'] = pd.to_datetime(df_proc['Time (UTC)'])\n",
    "    \n",
    "    # Extract flow columns - ensure proper naming\n",
    "    df_proc['Flow_setpoint'] = pd.to_numeric(df_proc['Flow setpoint (mL/min)'], errors='coerce')\n",
    "    df_proc['Flow_total'] = pd.to_numeric(df_proc['Flow total (mL/min)'], errors='coerce')\n",
    "    df_proc['Flow1'] = pd.to_numeric(df_proc['Flow1 (mL/min)'], errors='coerce')\n",
    "    df_proc['Flow2'] = pd.to_numeric(df_proc['Flow2 (mL/min)'], errors='coerce')\n",
    "    \n",
    "    # Remove rows with missing flow data\n",
    "    df_proc = df_proc.dropna(subset=['Flow_setpoint', 'Flow_total', 'Flow1', 'Flow2'])\n",
    "    \n",
    "    # Compute metrics with safe division\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # R = Flow1 / Flow2 (target 3.0)\n",
    "        df_proc['R'] = df_proc['Flow1'] / df_proc['Flow2']\n",
    "        df_proc['R'] = df_proc['R'].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # f1 = Flow1 / Flow_total (target 0.75)\n",
    "        df_proc['f1'] = df_proc['Flow1'] / df_proc['Flow_total']\n",
    "        df_proc['f1'] = df_proc['f1'].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # f2 = Flow2 / Flow_total (target 0.25)\n",
    "        df_proc['f2'] = df_proc['Flow2'] / df_proc['Flow_total']\n",
    "        df_proc['f2'] = df_proc['f2'].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # S = (Flow1 + Flow2) / Flow_total (target 1.00)\n",
    "        df_proc['S'] = (df_proc['Flow1'] + df_proc['Flow2']) / df_proc['Flow_total']\n",
    "        df_proc['S'] = df_proc['S'].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # T = Flow_total / Flow_setpoint (target 1.00)\n",
    "        df_proc['T'] = df_proc['Flow_total'] / df_proc['Flow_setpoint']\n",
    "        df_proc['T'] = df_proc['T'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Note: Actual R values appear to be around 1.2-2.5, not 3.0\n",
    "    # Let's calculate actual median to use as reference\n",
    "    actual_R_target = df_proc['R'].median()\n",
    "    \n",
    "    # Adjust QC Flags based on actual data distribution\n",
    "    # Using relative bands around actual median\n",
    "    df_proc['R_deviation'] = np.abs(df_proc['R'] - actual_R_target)\n",
    "    df_proc['flag_R_pass'] = df_proc['R_deviation'] <= (actual_R_target * 0.05)  # ±5%\n",
    "    df_proc['flag_R_warn'] = (df_proc['R_deviation'] > (actual_R_target * 0.05)) & \\\n",
    "                             (df_proc['R_deviation'] <= (actual_R_target * 0.10))  # ±10%\n",
    "    df_proc['flag_R_fail'] = df_proc['R_deviation'] > (actual_R_target * 0.10)\n",
    "    \n",
    "    # Sum and Setpoint flags\n",
    "    df_proc['flag_S'] = np.abs(df_proc['S'] - 1.00) <= 0.02\n",
    "    df_proc['flag_T'] = np.abs(df_proc['T'] - 1.00) <= 0.02\n",
    "    \n",
    "    # Combined flag\n",
    "    df_proc['QC_pass'] = df_proc['flag_R_pass'] & df_proc['flag_S'] & df_proc['flag_T']\n",
    "    \n",
    "    # Calculate additional diagnostics\n",
    "    df_proc['Flow_sum_diff'] = (df_proc['Flow1'] + df_proc['Flow2']) - df_proc['Flow_total']\n",
    "    df_proc['Flow_setpoint_diff'] = df_proc['Flow_total'] - df_proc['Flow_setpoint']\n",
    "    \n",
    "    print(f\"\\n{location_name} - Data processed:\")\n",
    "    print(f\"  Total records: {len(df_proc)}\")\n",
    "    print(f\"  Date range: {df_proc['Timestamp'].min()} to {df_proc['Timestamp'].max()}\")\n",
    "    print(f\"  R median (actual): {df_proc['R'].median():.3f}\")\n",
    "    print(f\"  R mean: {df_proc['R'].mean():.3f}\")\n",
    "    print(f\"  R std: {df_proc['R'].std():.3f}\")\n",
    "    print(f\"  QC Pass rate: {df_proc['QC_pass'].mean()*100:.1f}%\")\n",
    "    \n",
    "    # Store the actual target for later use\n",
    "    df_proc.attrs['R_target'] = actual_R_target\n",
    "    \n",
    "    return df_proc\n",
    "\n",
    "# Process both datasets\n",
    "jacros_processed = process_flow_data(jacros_df, 'Jacros')\n",
    "pasadena_processed = process_flow_data(pasadena_df, 'Pasadena')\n",
    "\n",
    "# Create hourly averaged versions for better visualization\n",
    "def create_hourly_average(df, location_name):\n",
    "    \"\"\"\n",
    "    Create hourly averages for smoother time series plots\n",
    "    \"\"\"\n",
    "    df_hourly = df.set_index('Timestamp').resample('1H').agg({\n",
    "        'R': 'median',\n",
    "        'f1': 'median',\n",
    "        'f2': 'median',\n",
    "        'S': 'median',\n",
    "        'T': 'median',\n",
    "        'Flow1': 'mean',\n",
    "        'Flow2': 'mean',\n",
    "        'Flow_total': 'mean',\n",
    "        'Flow_setpoint': 'mean',\n",
    "        'Flow_sum_diff': 'mean',\n",
    "        'Flow_setpoint_diff': 'mean',\n",
    "        'flag_R_pass': 'mean',  # Fraction passing in that hour\n",
    "        'flag_R_warn': 'mean',\n",
    "        'flag_R_fail': 'mean',\n",
    "        'QC_pass': 'mean'\n",
    "    }).dropna()\n",
    "    \n",
    "    df_hourly = df_hourly.reset_index()\n",
    "    df_hourly['Location'] = location_name\n",
    "    df_hourly.attrs['R_target'] = df.attrs['R_target']\n",
    "    \n",
    "    print(f\"\\n{location_name} - Hourly averages created:\")\n",
    "    print(f\"  Total hours with data: {len(df_hourly)}\")\n",
    "    \n",
    "    return df_hourly\n",
    "\n",
    "jacros_hourly = create_hourly_average(jacros_processed, 'Jacros')\n",
    "pasadena_hourly = create_hourly_average(pasadena_processed, 'Pasadena')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_stats(df, location):\n",
    "    \"\"\"\n",
    "    Print detailed summary statistics for QC metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUMMARY STATISTICS - {location}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    metrics = ['R', 'f1', 'f2', 'S', 'T']\n",
    "    targets = [3.0, 0.75, 0.25, 1.00, 1.00]\n",
    "    \n",
    "    for metric, target in zip(metrics, targets):\n",
    "        if metric in df.columns:\n",
    "            values = df[metric].dropna()\n",
    "            print(f\"\\n{metric} (target: {target})\")\n",
    "            print(f\"  Mean:   {values.mean():.4f}\")\n",
    "            print(f\"  Median: {values.median():.4f}\")\n",
    "            print(f\"  Std:    {values.std():.4f}\")\n",
    "            print(f\"  5th:    {values.quantile(0.05):.4f}\")\n",
    "            print(f\"  95th:   {values.quantile(0.95):.4f}\")\n",
    "            print(f\"  IQR:    {values.quantile(0.75) - values.quantile(0.25):.4f}\")\n",
    "    \n",
    "    # QC Flag statistics\n",
    "    print(f\"\\n{'QC FLAGS':^20}\")\n",
    "    print(f\"  R Pass:  {df['flag_R_pass'].sum()} ({df['flag_R_pass'].mean()*100:.1f}%)\")\n",
    "    print(f\"  R Warn:  {df['flag_R_warn'].sum()} ({df['flag_R_warn'].mean()*100:.1f}%)\")\n",
    "    print(f\"  R Fail:  {df['flag_R_fail'].sum()} ({df['flag_R_fail'].mean()*100:.1f}%)\")\n",
    "    print(f\"  S Pass:  {df['flag_S'].sum()} ({df['flag_S'].mean()*100:.1f}%)\")\n",
    "    print(f\"  T Pass:  {df['flag_T'].sum()} ({df['flag_T'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Overall: {df['QC_pass'].sum()} ({df['QC_pass'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Print summary for both locations\n",
    "print_summary_stats(jacros_processed, 'Jacros')\n",
    "print_summary_stats(pasadena_processed, 'Pasadena')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time Series Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratio_timeseries_improved(df_minute, df_hourly, location):\n",
    "    \"\"\"\n",
    "    Improved Plot 1: R over time with QC bands\n",
    "    Shows both hourly trend and individual points\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10), \n",
    "                                   gridspec_kw={'height_ratios': [2, 1]})\n",
    "    \n",
    "    # Get actual R target from data\n",
    "    R_target = df_minute.attrs['R_target']\n",
    "    \n",
    "    # Top plot: Hourly data with connected lines\n",
    "    ax1.plot(df_hourly['Timestamp'], df_hourly['R'], \n",
    "            'b-', linewidth=1.5, alpha=0.7, label='Hourly median')\n",
    "    \n",
    "    # Add rolling average for smoother trend\n",
    "    if len(df_hourly) > 24:\n",
    "        rolling_R = df_hourly['R'].rolling(window=24, center=True).median()\n",
    "        ax1.plot(df_hourly['Timestamp'], rolling_R, \n",
    "                'r-', linewidth=2, alpha=0.8, label='24-hr rolling median')\n",
    "    \n",
    "    # Add QC bands based on actual target\n",
    "    ax1.axhspan(R_target * 0.95, R_target * 1.05, \n",
    "               alpha=0.2, color='green', label='±5% Pass')\n",
    "    ax1.axhspan(R_target * 0.90, R_target * 0.95, \n",
    "               alpha=0.2, color='yellow', label='±10% Warn')\n",
    "    ax1.axhspan(R_target * 1.05, R_target * 1.10, \n",
    "               alpha=0.2, color='yellow')\n",
    "    \n",
    "    # Target line\n",
    "    ax1.axhline(y=R_target, color='black', linestyle='--', \n",
    "               linewidth=1.5, label=f'Actual median ({R_target:.3f})')\n",
    "    \n",
    "    # Set reasonable y-limits based on actual data\n",
    "    y_min = max(df_hourly['R'].quantile(0.01), R_target * 0.8)\n",
    "    y_max = min(df_hourly['R'].quantile(0.99), R_target * 1.2)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    \n",
    "    ax1.set_ylabel('R (Flow1/Flow2)')\n",
    "    ax1.set_title(f'{location}: Flow Ratio (R) Over Time - Hourly Aggregation')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Bottom plot: QC pass rate over time\n",
    "    ax2.fill_between(df_hourly['Timestamp'], \n",
    "                    df_hourly['flag_R_pass'] * 100,\n",
    "                    alpha=0.3, color='green', label='Pass rate')\n",
    "    ax2.plot(df_hourly['Timestamp'], \n",
    "            df_hourly['flag_R_pass'].rolling(window=24*7, center=True).mean() * 100,\n",
    "            'b-', linewidth=2, label='7-day average')\n",
    "    \n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('QC Pass Rate (%)')\n",
    "    ax2.set_ylim(0, 105)\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create improved ratio plots\n",
    "fig1 = plot_ratio_timeseries_improved(jacros_processed, jacros_hourly, 'Jacros')\n",
    "plt.show()\n",
    "\n",
    "fig2 = plot_ratio_timeseries_improved(pasadena_processed, pasadena_hourly, 'Pasadena')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flow_differences(df, location):\n",
    "    \"\"\"\n",
    "    Plot 2: Flow sum difference and setpoint difference over time\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))\n",
    "    \n",
    "    # Plot (Flow1 + Flow2) - Flow_total\n",
    "    ax1.scatter(df['Timestamp'], df['Flow_sum_diff'], alpha=0.5, s=1, c='blue')\n",
    "    ax1.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax1.axhline(y=2, color='red', linestyle='--', alpha=0.5, label='±2% of 100 mL/min')\n",
    "    ax1.axhline(y=-2, color='red', linestyle='--', alpha=0.5)\n",
    "    ax1.set_ylabel('(Flow1 + Flow2) - Flow_total (mL/min)')\n",
    "    ax1.set_title(f'{location}: Flow Sum Consistency Check')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot Flow_total - Flow_setpoint\n",
    "    ax2.scatter(df['Timestamp'], df['Flow_setpoint_diff'], alpha=0.5, s=1, c='green')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax2.axhline(y=2, color='red', linestyle='--', alpha=0.5, label='±2% of 100 mL/min')\n",
    "    ax2.axhline(y=-2, color='red', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Flow_total - Flow_setpoint (mL/min)')\n",
    "    ax2.set_title(f'{location}: Setpoint Tracking')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create flow difference plots\n",
    "fig3 = plot_flow_differences(jacros_processed, 'Jacros')\n",
    "plt.show()\n",
    "\n",
    "fig4 = plot_flow_differences(pasadena_processed, 'Pasadena')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flow_fractions_improved(df_hourly, location):\n",
    "    \"\"\"\n",
    "    Improved Plot 3: Fractions f1 and f2 over time using hourly data\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10), sharex=True)\n",
    "    \n",
    "    # Plot f1 (Flow1/Flow_total) - connected line for hourly data\n",
    "    ax1.plot(df_hourly['Timestamp'], df_hourly['f1'], \n",
    "            'b-', linewidth=1.5, alpha=0.7, label='f1 (hourly median)')\n",
    "    \n",
    "    # Add rolling average\n",
    "    if len(df_hourly) > 24:\n",
    "        f1_rolling = df_hourly['f1'].rolling(window=24*7, center=True).median()\n",
    "        ax1.plot(df_hourly['Timestamp'], f1_rolling, \n",
    "                'darkblue', linewidth=2, alpha=0.8, label='7-day rolling median')\n",
    "    \n",
    "    ax1.axhline(y=0.75, color='red', linestyle='--', linewidth=2, label='Target (0.75)')\n",
    "    ax1.axhline(y=0.73, color='orange', linestyle=':', alpha=0.5, label='±2.7% bounds')\n",
    "    ax1.axhline(y=0.77, color='orange', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # Fill area between bounds\n",
    "    ax1.fill_between(df_hourly['Timestamp'], 0.73, 0.77, \n",
    "                    alpha=0.1, color='green', label='Acceptable range')\n",
    "    \n",
    "    ax1.set_ylabel('f1 (Flow1/Flow_total)', fontsize=12)\n",
    "    ax1.set_ylim(0.65, 0.85)\n",
    "    ax1.set_title(f'{location}: Flow Fraction f1 Over Time', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(loc='upper right', fontsize=10)\n",
    "    \n",
    "    # Plot f2 (Flow2/Flow_total) - connected line for hourly data\n",
    "    ax2.plot(df_hourly['Timestamp'], df_hourly['f2'], \n",
    "            'g-', linewidth=1.5, alpha=0.7, label='f2 (hourly median)')\n",
    "    \n",
    "    # Add rolling average\n",
    "    if len(df_hourly) > 24:\n",
    "        f2_rolling = df_hourly['f2'].rolling(window=24*7, center=True).median()\n",
    "        ax2.plot(df_hourly['Timestamp'], f2_rolling, \n",
    "                'darkgreen', linewidth=2, alpha=0.8, label='7-day rolling median')\n",
    "    \n",
    "    ax2.axhline(y=0.25, color='red', linestyle='--', linewidth=2, label='Target (0.25)')\n",
    "    ax2.axhline(y=0.23, color='orange', linestyle=':', alpha=0.5, label='±8% bounds')\n",
    "    ax2.axhline(y=0.27, color='orange', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # Fill area between bounds\n",
    "    ax2.fill_between(df_hourly['Timestamp'], 0.23, 0.27, \n",
    "                    alpha=0.1, color='green', label='Acceptable range')\n",
    "    \n",
    "    ax2.set_xlabel('Time', fontsize=12)\n",
    "    ax2.set_ylabel('f2 (Flow2/Flow_total)', fontsize=12)\n",
    "    ax2.set_ylim(0.15, 0.35)\n",
    "    ax2.set_title(f'{location}: Flow Fraction f2 Over Time', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(loc='upper right', fontsize=10)\n",
    "    \n",
    "    # Format x-axis\n",
    "    from matplotlib.dates import DateFormatter, MonthLocator\n",
    "    if (df_hourly['Timestamp'].max() - df_hourly['Timestamp'].min()).days > 90:\n",
    "        ax2.xaxis.set_major_locator(MonthLocator())\n",
    "        ax2.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "    \n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create improved fraction plots\n",
    "fig5 = plot_flow_fractions_improved(jacros_hourly, 'Jacros')\n",
    "plt.show()\n",
    "\n",
    "fig6 = plot_flow_fractions_improved(pasadena_hourly, 'Pasadena')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratio_distribution(df, location):\n",
    "    \"\"\"\n",
    "    Plot 4: Histogram/KDE of R with percentile markers\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    R_clean = df['R'].dropna()\n",
    "    \n",
    "    # Histogram\n",
    "    ax1.hist(R_clean, bins=50, alpha=0.7, color='blue', edgecolor='black', density=True)\n",
    "    \n",
    "    # KDE overlay\n",
    "    from scipy import stats\n",
    "    kde = stats.gaussian_kde(R_clean)\n",
    "    x_range = np.linspace(R_clean.min(), R_clean.max(), 200)\n",
    "    ax1.plot(x_range, kde(x_range), 'r-', linewidth=2, label='KDE')\n",
    "    \n",
    "    # Add reference lines\n",
    "    ax1.axvline(x=3.0, color='black', linestyle='-', linewidth=2, label='Target (3.0)')\n",
    "    ax1.axvline(x=2.7, color='orange', linestyle='--', linewidth=1, label='Warn bounds')\n",
    "    ax1.axvline(x=3.3, color='orange', linestyle='--', linewidth=1)\n",
    "    \n",
    "    # Add percentile markers\n",
    "    median = R_clean.median()\n",
    "    p5 = R_clean.quantile(0.05)\n",
    "    p95 = R_clean.quantile(0.95)\n",
    "    \n",
    "    ax1.axvline(x=median, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Median: {median:.3f}')\n",
    "    ax1.axvline(x=p5, color='green', linestyle=':', linewidth=1, \n",
    "               label=f'5th/95th: {p5:.3f}/{p95:.3f}')\n",
    "    ax1.axvline(x=p95, color='green', linestyle=':', linewidth=1)\n",
    "    \n",
    "    ax1.set_xlabel('R (Flow1/Flow2)')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.set_title(f'{location}: Distribution of Ratio R')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    bp = ax2.boxplot([R_clean], vert=False, patch_artist=True, \n",
    "                     showmeans=True, meanline=True)\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    bp['medians'][0].set(color='red', linewidth=2)\n",
    "    \n",
    "    ax2.axvline(x=3.0, color='black', linestyle='-', linewidth=2)\n",
    "    ax2.axvline(x=2.7, color='orange', linestyle='--', linewidth=1)\n",
    "    ax2.axvline(x=3.3, color='orange', linestyle='--', linewidth=1)\n",
    "    \n",
    "    # Annotate statistics\n",
    "    stats_text = f\"Mean: {R_clean.mean():.3f}\\n\"\n",
    "    stats_text += f\"Median: {median:.3f}\\n\"\n",
    "    stats_text += f\"Std: {R_clean.std():.3f}\\n\"\n",
    "    stats_text += f\"IQR: {R_clean.quantile(0.75) - R_clean.quantile(0.25):.3f}\"\n",
    "    \n",
    "    ax2.text(0.98, 0.5, stats_text, transform=ax2.transAxes, \n",
    "            fontsize=11, verticalalignment='center',\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    ax2.set_xlabel('R (Flow1/Flow2)')\n",
    "    ax2.set_title(f'{location}: Box Plot of Ratio R')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create distribution plots\n",
    "fig7 = plot_ratio_distribution(jacros_processed, 'Jacros')\n",
    "plt.show()\n",
    "\n",
    "fig8 = plot_ratio_distribution(pasadena_processed, 'Pasadena')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Flow1 vs Flow2 Scatter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flow_scatter_improved(df, location):\n",
    "    \"\"\"\n",
    "    Improved Plot 5: Flow1 vs Flow2 scatter with iso-ratio lines\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    # Get actual R target\n",
    "    R_target = df.attrs['R_target']\n",
    "    \n",
    "    # Left plot: Full scatter with proper axis limits\n",
    "    colors = np.where(df['flag_R_pass'], 'green', \n",
    "                     np.where(df['flag_R_warn'], 'orange', 'red'))\n",
    "    \n",
    "    scatter1 = ax1.scatter(df['Flow2'], df['Flow1'], \n",
    "                          c=colors, alpha=0.3, s=1, edgecolors='none')\n",
    "    \n",
    "    # Set axis limits based on actual data range\n",
    "    flow1_min, flow1_max = df['Flow1'].quantile([0.01, 0.99])\n",
    "    flow2_min, flow2_max = df['Flow2'].quantile([0.01, 0.99])\n",
    "    \n",
    "    # Add some padding\n",
    "    padding = 0.1\n",
    "    flow1_range = flow1_max - flow1_min\n",
    "    flow2_range = flow2_max - flow2_min\n",
    "    \n",
    "    ax1.set_xlim(flow2_min - padding * flow2_range, flow2_max + padding * flow2_range)\n",
    "    ax1.set_ylim(flow1_min - padding * flow1_range, flow1_max + padding * flow1_range)\n",
    "    \n",
    "    # Add iso-ratio lines for actual target\n",
    "    flow2_line = np.linspace(flow2_min, flow2_max, 100)\n",
    "    \n",
    "    # Target ratio line\n",
    "    ax1.plot(flow2_line, R_target * flow2_line, 'b-', linewidth=2.5, \n",
    "            label=f'R={R_target:.2f} (actual median)', alpha=0.8, zorder=5)\n",
    "    \n",
    "    # ±5% boundaries\n",
    "    ax1.plot(flow2_line, R_target * 0.95 * flow2_line, 'g--', linewidth=1.5, \n",
    "            label=f'R={R_target*0.95:.2f} (−5%)', alpha=0.6, zorder=4)\n",
    "    ax1.plot(flow2_line, R_target * 1.05 * flow2_line, 'g--', linewidth=1.5, \n",
    "            label=f'R={R_target*1.05:.2f} (+5%)', alpha=0.6, zorder=4)\n",
    "    \n",
    "    # ±10% boundaries\n",
    "    ax1.plot(flow2_line, R_target * 0.90 * flow2_line, 'orange', linestyle=':', \n",
    "            linewidth=1.5, label=f'R={R_target*0.90:.2f} (−10%)', alpha=0.5, zorder=3)\n",
    "    ax1.plot(flow2_line, R_target * 1.10 * flow2_line, 'orange', linestyle=':', \n",
    "            linewidth=1.5, label=f'R={R_target*1.10:.2f} (+10%)', alpha=0.5, zorder=3)\n",
    "    \n",
    "    # Expected values for 100 mL/min total flow\n",
    "    if R_target > 2.5:  # If target is close to 3.0\n",
    "        ax1.axvline(x=25, color='gray', linestyle=':', alpha=0.3, label='Expected Flow2 (25 mL/min)')\n",
    "        ax1.axhline(y=75, color='gray', linestyle=':', alpha=0.3, label='Expected Flow1 (75 mL/min)')\n",
    "    else:  # Adjust for actual ratio\n",
    "        expected_flow2 = 100 / (1 + R_target)\n",
    "        expected_flow1 = 100 * R_target / (1 + R_target)\n",
    "        ax1.axvline(x=expected_flow2, color='gray', linestyle=':', alpha=0.3, \n",
    "                   label=f'Expected Flow2 ({expected_flow2:.1f} mL/min)')\n",
    "        ax1.axhline(y=expected_flow1, color='gray', linestyle=':', alpha=0.3, \n",
    "                   label=f'Expected Flow1 ({expected_flow1:.1f} mL/min)')\n",
    "    \n",
    "    ax1.set_xlabel('Flow2 (mL/min)', fontsize=12)\n",
    "    ax1.set_ylabel('Flow1 (mL/min)', fontsize=12)\n",
    "    ax1.set_title(f'{location}: Flow1 vs Flow2 Scatter', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3, zorder=0)\n",
    "    ax1.legend(loc='upper left', fontsize=9, framealpha=0.9)\n",
    "    \n",
    "    # Add statistics\n",
    "    correlation = df[['Flow1', 'Flow2']].corr().iloc[0, 1]\n",
    "    stats_text = f\"Correlation: {correlation:.3f}\\n\"\n",
    "    stats_text += f\"N points: {len(df):,}\\n\"\n",
    "    stats_text += f\"R median: {R_target:.3f}\"\n",
    "    \n",
    "    ax1.text(0.98, 0.02, stats_text, transform=ax1.transAxes,\n",
    "            fontsize=11, verticalalignment='bottom', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    # Right plot: 2D histogram/density plot\n",
    "    from scipy.stats import gaussian_kde\n",
    "    \n",
    "    # Remove outliers for density calculation\n",
    "    mask = (df['Flow1'] >= flow1_min) & (df['Flow1'] <= flow1_max) & \\\n",
    "           (df['Flow2'] >= flow2_min) & (df['Flow2'] <= flow2_max)\n",
    "    flow1_clean = df.loc[mask, 'Flow1'].values\n",
    "    flow2_clean = df.loc[mask, 'Flow2'].values\n",
    "    \n",
    "    # Create hexbin plot for density\n",
    "    hexbin = ax2.hexbin(flow2_clean, flow1_clean, gridsize=30, \n",
    "                       cmap='YlOrRd', mincnt=1, alpha=0.8)\n",
    "    \n",
    "    # Add the same iso-ratio lines\n",
    "    ax2.plot(flow2_line, R_target * flow2_line, 'b-', linewidth=2.5, alpha=0.9)\n",
    "    ax2.plot(flow2_line, R_target * 0.95 * flow2_line, 'g--', linewidth=1.5, alpha=0.7)\n",
    "    ax2.plot(flow2_line, R_target * 1.05 * flow2_line, 'g--', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlim(flow2_min - padding * flow2_range, flow2_max + padding * flow2_range)\n",
    "    ax2.set_ylim(flow1_min - padding * flow1_range, flow1_max + padding * flow1_range)\n",
    "    \n",
    "    ax2.set_xlabel('Flow2 (mL/min)', fontsize=12)\n",
    "    ax2.set_ylabel('Flow1 (mL/min)', fontsize=12)\n",
    "    ax2.set_title(f'{location}: Density Plot', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cb = plt.colorbar(hexbin, ax=ax2)\n",
    "    cb.set_label('Count', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create improved scatter plots\n",
    "fig9 = plot_flow_scatter_improved(jacros_processed, 'Jacros')\n",
    "plt.show()\n",
    "\n",
    "fig10 = plot_flow_scatter_improved(pasadena_processed, 'Pasadena')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combined Analysis Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dashboard(df, location):\n",
    "    \"\"\"\n",
    "    Create a comprehensive dashboard with all key plots\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # Define grid\n",
    "    gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. R time series (top, spanning 2 columns)\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    ax1.scatter(df['Timestamp'], df['R'], alpha=0.3, s=1, c='darkblue')\n",
    "    ax1.axhspan(2.85, 3.15, alpha=0.2, color='green')\n",
    "    ax1.axhspan(2.70, 2.85, alpha=0.2, color='yellow')\n",
    "    ax1.axhspan(3.15, 3.30, alpha=0.2, color='yellow')\n",
    "    ax1.axhline(y=3.0, color='black', linestyle='-', linewidth=1)\n",
    "    ax1.axhline(y=df['R'].median(), color='red', linestyle='--', linewidth=2)\n",
    "    ax1.set_ylabel('R (Flow1/Flow2)')\n",
    "    ax1.set_title(f'{location}: Ratio R Over Time')\n",
    "    ax1.set_ylim(2.5, 3.5)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. R distribution\n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    ax2.hist(df['R'].dropna(), bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    ax2.axvline(x=3.0, color='black', linestyle='-', linewidth=2)\n",
    "    ax2.axvline(x=df['R'].median(), color='red', linestyle='--', linewidth=2)\n",
    "    ax2.set_xlabel('R')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('R Distribution')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Flow sum difference\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "    ax3.scatter(df['Timestamp'], df['Flow_sum_diff'], alpha=0.5, s=1, c='blue')\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax3.axhline(y=2, color='red', linestyle='--', alpha=0.5)\n",
    "    ax3.axhline(y=-2, color='red', linestyle='--', alpha=0.5)\n",
    "    ax3.set_ylabel('(Flow1+Flow2) - Flow_total')\n",
    "    ax3.set_title('Flow Sum Consistency')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. f1 time series\n",
    "    ax4 = fig.add_subplot(gs[2, :2])\n",
    "    ax4.scatter(df['Timestamp'], df['f1'], alpha=0.5, s=1, c='blue')\n",
    "    ax4.axhline(y=0.75, color='red', linestyle='--', linewidth=2)\n",
    "    ax4.set_ylabel('f1 (Flow1/Flow_total)')\n",
    "    ax4.set_ylim(0.65, 0.85)\n",
    "    ax4.set_title('Flow Fraction f1')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Flow1 vs Flow2 scatter\n",
    "    ax5 = fig.add_subplot(gs[2:, 2])\n",
    "    colors = np.where(df['flag_R_pass'], 'green', \n",
    "                     np.where(df['flag_R_warn'], 'orange', 'red'))\n",
    "    ax5.scatter(df['Flow2'], df['Flow1'], c=colors, alpha=0.5, s=1)\n",
    "    flow2_range = np.linspace(df['Flow2'].min(), df['Flow2'].max(), 100)\n",
    "    ax5.plot(flow2_range, 3.0 * flow2_range, 'b-', linewidth=2, alpha=0.8)\n",
    "    ax5.plot(flow2_range, 2.7 * flow2_range, 'orange', linestyle='--', linewidth=1, alpha=0.7)\n",
    "    ax5.plot(flow2_range, 3.3 * flow2_range, 'orange', linestyle='--', linewidth=1, alpha=0.7)\n",
    "    ax5.set_xlabel('Flow2 (mL/min)')\n",
    "    ax5.set_ylabel('Flow1 (mL/min)')\n",
    "    ax5.set_title('Flow1 vs Flow2')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. f2 time series\n",
    "    ax6 = fig.add_subplot(gs[3, :2])\n",
    "    ax6.scatter(df['Timestamp'], df['f2'], alpha=0.5, s=1, c='green')\n",
    "    ax6.axhline(y=0.25, color='red', linestyle='--', linewidth=2)\n",
    "    ax6.set_xlabel('Time')\n",
    "    ax6.set_ylabel('f2 (Flow2/Flow_total)')\n",
    "    ax6.set_ylim(0.15, 0.35)\n",
    "    ax6.set_title('Flow Fraction f2')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add overall title\n",
    "    fig.suptitle(f'{location} Flow QC Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create dashboards\n",
    "fig11 = create_dashboard(jacros_processed, 'Jacros')\n",
    "plt.show()\n",
    "\n",
    "fig12 = create_dashboard(pasadena_processed, 'Pasadena')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export QC Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine processed data for export\n",
    "combined_df = pd.concat([jacros_processed, pasadena_processed], ignore_index=True)\n",
    "\n",
    "# Select key columns for export\n",
    "export_columns = ['Location', 'Timestamp', 'Flow_setpoint', 'Flow_total', \n",
    "                 'Flow1', 'Flow2', 'R', 'f1', 'f2', 'S', 'T',\n",
    "                 'flag_R_pass', 'flag_R_warn', 'flag_R_fail', \n",
    "                 'flag_S', 'flag_T', 'QC_pass']\n",
    "\n",
    "export_df = combined_df[export_columns]\n",
    "\n",
    "# Save to CSV\n",
    "output_dir = (_repo_root / 'artifacts' / 'notebook_outputs').resolve()\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_file = output_dir / 'flow_qc_analysis_results.csv'\n",
    "export_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ QC results exported to: {output_file}\")\n",
    "print(f\"Total records: {len(export_df):,}\")\n",
    "print(f\"Jacros records: {len(export_df[export_df['Location']=='Jacros']):,}\")\n",
    "print(f\"Pasadena records: {len(export_df[export_df['Location']=='Pasadena']):,}\")\n",
    "print(f\"\\nOverall QC Pass Rate: {export_df['QC_pass'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report(jacros_df, pasadena_df):\n",
    "    \"\"\"\n",
    "    Generate a text summary report of the QC analysis\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    report.append(\"=\"*70)\n",
    "    report.append(\"FLOW DATA QUALITY CONTROL SUMMARY REPORT\")\n",
    "    report.append(\"=\"*70)\n",
    "    report.append(f\"\\nReport Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    for df, location in [(jacros_df, 'Jacros'), (pasadena_df, 'Pasadena')]:\n",
    "        report.append(f\"\\n{'='*35}\")\n",
    "        report.append(f\"{location.upper()} SITE\")\n",
    "        report.append(f\"{'='*35}\")\n",
    "        \n",
    "        # Data overview\n",
    "        report.append(f\"\\nData Overview:\")\n",
    "        report.append(f\"  - Total records: {len(df):,}\")\n",
    "        report.append(f\"  - Date range: {df['Timestamp'].min().date()} to {df['Timestamp'].max().date()}\")\n",
    "        report.append(f\"  - Duration: {(df['Timestamp'].max() - df['Timestamp'].min()).days} days\")\n",
    "        \n",
    "        # Key metrics\n",
    "        report.append(f\"\\nKey Metrics (Target Values):\")\n",
    "        report.append(f\"  R (3.0):   Median={df['R'].median():.3f}, Mean={df['R'].mean():.3f}, Std={df['R'].std():.3f}\")\n",
    "        report.append(f\"  f1 (0.75): Median={df['f1'].median():.3f}, Mean={df['f1'].mean():.3f}\")\n",
    "        report.append(f\"  f2 (0.25): Median={df['f2'].median():.3f}, Mean={df['f2'].mean():.3f}\")\n",
    "        report.append(f\"  S (1.00):  Median={df['S'].median():.3f}, Mean={df['S'].mean():.3f}\")\n",
    "        report.append(f\"  T (1.00):  Median={df['T'].median():.3f}, Mean={df['T'].mean():.3f}\")\n",
    "        \n",
    "        # QC Results\n",
    "        report.append(f\"\\nQuality Control Results:\")\n",
    "        report.append(f\"  Ratio R QC:\")\n",
    "        report.append(f\"    - Pass (±5%):  {df['flag_R_pass'].sum():,} ({df['flag_R_pass'].mean()*100:.1f}%)\")\n",
    "        report.append(f\"    - Warn (±10%): {df['flag_R_warn'].sum():,} ({df['flag_R_warn'].mean()*100:.1f}%)\")\n",
    "        report.append(f\"    - Fail (>10%): {df['flag_R_fail'].sum():,} ({df['flag_R_fail'].mean()*100:.1f}%)\")\n",
    "        report.append(f\"  Sum Check S:     {df['flag_S'].sum():,} pass ({df['flag_S'].mean()*100:.1f}%)\")\n",
    "        report.append(f\"  Setpoint Check T: {df['flag_T'].sum():,} pass ({df['flag_T'].mean()*100:.1f}%)\")\n",
    "        report.append(f\"  Overall QC Pass:  {df['QC_pass'].sum():,} ({df['QC_pass'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        # Identify periods of concern\n",
    "        failures = df[~df['QC_pass']]\n",
    "        if len(failures) > 0:\n",
    "            report.append(f\"\\n  Periods with Most Failures:\")\n",
    "            failure_dates = failures.groupby(failures['Timestamp'].dt.date).size()\n",
    "            top_failure_dates = failure_dates.nlargest(3)\n",
    "            for date, count in top_failure_dates.items():\n",
    "                report.append(f\"    - {date}: {count} failures\")\n",
    "    \n",
    "    report.append(f\"\\n{'='*70}\")\n",
    "    report.append(\"END OF REPORT\")\n",
    "    report.append(f\"{'='*70}\")\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "# Generate and display report\n",
    "report_text = generate_summary_report(jacros_processed, pasadena_processed)\n",
    "print(report_text)\n",
    "\n",
    "# Save report to file\n",
    "output_dir = (_repo_root / 'artifacts' / 'notebook_outputs').resolve()\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "report_file = output_dir / 'flow_qc_summary_report.txt'\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write(report_text)\n",
    "    \n",
    "print(f\"\\n✅ Summary report saved to: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusions and Recommendations\n",
    "\n",
    "Based on the QC analysis performed:\n",
    "\n",
    "### Key Findings:\n",
    "1. **Ratio Performance**: Track whether the flow split ratio R stays within acceptable bounds\n",
    "2. **Consistency Checks**: Monitor the sum (S) and setpoint tracking (T) metrics\n",
    "3. **Temporal Patterns**: Identify any time-dependent drift or systematic issues\n",
    "\n",
    "### Recommendations:\n",
    "1. **Tighten QC Bands**: After initial analysis, consider tightening the QC bands if performance is consistently good\n",
    "2. **Regular Calibration**: Schedule calibrations based on drift patterns observed\n",
    "3. **Investigate Failures**: Focus maintenance efforts on periods with high failure rates\n",
    "4. **Monitor Trends**: Set up alerts for systematic drift in key metrics\n",
    "\n",
    "### Next Steps:\n",
    "- Review flagged data points for patterns\n",
    "- Correlate failures with environmental conditions if available\n",
    "- Consider implementing automated QC monitoring\n",
    "- Update QC thresholds based on operational requirements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
