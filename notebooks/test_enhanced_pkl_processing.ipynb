{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced PKL Processing Test Notebook\n",
    "\n",
    "This notebook tests the integrated enhanced PKL processing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahzs645/Github/aethmodular/src/data/qc/../../external/calibration.py:2855: SyntaxWarning: invalid escape sequence '\\['\n",
      "  status_vals_desc = sub(\"'|\\[|\\]\",'',str(status_vals_desc_list))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced plotting style configured\n",
      "üöÄ Aethalometer-FTIR/HIPS Pipeline with Simplified Setup\n",
      "============================================================\n",
      "üìä Configuration Summary:\n",
      "   Site: ETAD\n",
      "   Wavelength: Red\n",
      "   Output format: jpl\n",
      "   Quality threshold: 10 minutes\n",
      "   Output directory: outputs\n",
      "\n",
      "üìÅ File paths:\n",
      "   pkl_data: ‚úÖ df_uncleaned_Jacros_API_and_OG.pkl\n",
      "   csv_data: ‚úÖ Jacros_MA350_1-min_2022-2024_Cleaned.csv\n",
      "   FTIR DB: ‚úÖ spartan_ftir_hips.db\n",
      "üßπ Enhanced setup with PKL cleaning capabilities loaded\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "# Import the new enhanced PKL processing module\n",
    "from data.qc.enhanced_pkl_processing import process_pkl_data_enhanced, EnhancedPKLProcessor\n",
    "from config.notebook_config import NotebookConfig\n",
    "from notebook_utils.pkl_cleaning_integration import create_enhanced_setup\n",
    "\n",
    "# Your existing configuration\n",
    "config = NotebookConfig(\n",
    "    site_code='ETAD',\n",
    "    wavelength='Red',\n",
    "    quality_threshold=10,\n",
    "    output_format='jpl',\n",
    "    min_samples_for_analysis=30,\n",
    "    confidence_level=0.95,\n",
    "    outlier_threshold=3.0,\n",
    "    figure_size=(12, 8),\n",
    "    font_size=10,\n",
    "    dpi=300\n",
    ")\n",
    "\n",
    "# Set your data paths (same as before)\n",
    "base_data_path = \"/Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data\"\n",
    "\n",
    "config.aethalometer_files = {\n",
    "    'pkl_data': os.path.join(\n",
    "        base_data_path,\n",
    "        \"Aethelometry Data/Kyan Data/Mergedcleaned and uncleaned MA350 data20250707030704\",\n",
    "        \"df_uncleaned_Jacros_API_and_OG.pkl\"\n",
    "    ),\n",
    "    'csv_data': os.path.join(\n",
    "        base_data_path,\n",
    "        \"Aethelometry Data/Raw\",\n",
    "        \"Jacros_MA350_1-min_2022-2024_Cleaned.csv\"\n",
    "    )\n",
    "}\n",
    "\n",
    "config.ftir_db_path = os.path.join(\n",
    "    base_data_path,\n",
    "    \"EC-HIPS-Aeth Comparison/Data/Original Data/Combined Database\",\n",
    "    \"spartan_ftir_hips.db\"\n",
    ")\n",
    "\n",
    "# Create enhanced setup\n",
    "setup = create_enhanced_setup(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading datasets...\n",
      "üì¶ Setting up modular system...\n",
      "‚úÖ Aethalometer loaders imported\n",
      "‚úÖ Database loader imported\n",
      "‚úÖ Plotting utilities imported\n",
      "‚úÖ Plotting style configured\n",
      "‚úÖ Successfully imported 5 modular components\n",
      "\n",
      "============================================================\n",
      "üìÅ LOADING DATASETS\n",
      "============================================================\n",
      "üìÅ Loading all datasets...\n",
      "\n",
      "==================================================\n",
      "üìä Loading pkl_data\n",
      "==================================================\n",
      "üìÅ Loading pkl_data: df_uncleaned_Jacros_API_and_OG.pkl\n",
      "Detected format: standard\n",
      "Set 'datetime_local' as DatetimeIndex for time series operations\n",
      "Converted 17 columns to JPL format\n",
      "Warning: Missing recommended columns: ['datetime_local', 'Biomass.BCc', 'Fossil.fuel.BCc']\n",
      "‚úÖ Modular load: 1,665,156 rows √ó 238 columns\n",
      "üìä Method: modular\n",
      "üìä Format: jpl\n",
      "üìä Memory: 7443.05 MB\n",
      "üßÆ BC columns: 30\n",
      "üìà ATN columns: 25\n",
      "üìÖ Time range: 2021-01-09 16:38:00 to 2025-06-26 23:18:00\n",
      "‚úÖ pkl_data loaded successfully\n",
      "\n",
      "==================================================\n",
      "üìä Loading csv_data\n",
      "==================================================\n",
      "üìÅ Loading csv_data: Jacros_MA350_1-min_2022-2024_Cleaned.csv\n",
      "Set 'Time (Local)' as DatetimeIndex for time series operations\n",
      "Converted 5 columns to JPL format\n",
      "‚úÖ Modular load: 1,095,086 rows √ó 77 columns\n",
      "üìä Method: modular\n",
      "üìä Format: jpl\n",
      "üìä Memory: 884.83 MB\n",
      "üßÆ BC columns: 15\n",
      "üìà ATN columns: 10\n",
      "üìÖ Time range: 2022-04-12 12:46:01+03:00 to 2024-08-20 12:01:00+03:00\n",
      "‚úÖ csv_data loaded successfully\n",
      "\n",
      "==================================================\n",
      "üóÉÔ∏è Loading FTIR/HIPS data\n",
      "==================================================\n",
      "üóÉÔ∏è Loading FTIR/HIPS data for site ETAD...\n",
      "üìä Available sites: ['ILNZ', 'ILHA', 'ZAJB', 'CAHA', 'CASH', 'AEAZ', 'AUMN', 'KRUL', 'MXMC', 'ZAPR', 'CHTS', 'ETAD', 'INDH', 'TWTA', 'USPA', 'TWKA', 'KRSE', 'PRFJ', 'BDDU', 'BIBU', 'USNO', 'IDBD', None]\n",
      "‚úÖ Modular FTIR load: 168 samples\n",
      "üìÖ Date range: 2022-12-07 00:00:00 to 2024-05-12 00:00:00\n",
      "‚úÖ FTIR/HIPS data loaded successfully\n",
      "\n",
      "üìä Loading summary: 3 datasets loaded\n",
      "\n",
      "üìä LOADING SUMMARY\n",
      "============================================================\n",
      "‚úÖ Successfully loaded 3 datasets\n",
      "   - pkl_data: 1,665,156 rows √ó 238 columns\n",
      "   - csv_data: 1,095,086 rows √ó 77 columns\n",
      "   - ftir_hips: 168 rows √ó 12 columns\n",
      "============================================================\n",
      "‚úÖ Converting datetime_local from index to column...\n",
      "üìä PKL data ready: (1665156, 239)\n",
      "üìÖ Date range: 2021-01-09 16:38:00 to 2025-06-26 23:18:00\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"üìÅ Loading datasets...\")\n",
    "datasets = setup.load_all_data()\n",
    "\n",
    "# Get PKL data\n",
    "pkl_data_original = setup.get_dataset('pkl_data')\n",
    "\n",
    "# Quick fix for datetime_local issue (same as before)\n",
    "if 'datetime_local' not in pkl_data_original.columns:\n",
    "    if pkl_data_original.index.name == 'datetime_local':\n",
    "        print(\"‚úÖ Converting datetime_local from index to column...\")\n",
    "        pkl_data_original = pkl_data_original.reset_index()\n",
    "    elif hasattr(pkl_data_original.index, 'tz'):\n",
    "        print(\"‚úÖ Creating datetime_local column from datetime index...\")\n",
    "        pkl_data_original['datetime_local'] = pkl_data_original.index\n",
    "        pkl_data_original = pkl_data_original.reset_index(drop=True)\n",
    "\n",
    "print(f\"üìä PKL data ready: {pkl_data_original.shape}\")\n",
    "print(f\"üìÖ Date range: {pkl_data_original['datetime_local'].min()} to {pkl_data_original['datetime_local'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Enhanced PKL Data Processing Pipeline\n",
      "============================================================\n",
      "üîß Comprehensive Preprocessing Pipeline\n",
      "============================================================\n",
      "Step 1: Processing datetime...\n",
      "\n",
      "Step 2: Fixing column names...\n",
      "‚úÖ Renamed 16 columns\n",
      "\n",
      "Step 3: Converting data types...\n",
      "Converted IR ATN1 to float.\n",
      "Converted UV ATN1 to float.\n",
      "Converted Blue ATN1 to float.\n",
      "Converted Green ATN1 to float.\n",
      "Converted Red ATN1 to float.\n",
      "‚úÖ Applied calibration.convert_to_float()\n",
      "\n",
      "Step 4: Adding Session ID...\n",
      "\n",
      "Step 5: Adding delta calculations...\n",
      "‚úÖ Applied calibration.add_deltas()\n",
      "\n",
      "Step 6: Final adjustments...\n",
      "‚úÖ Filtered to 2022+: 1,665,156 -> 1,627,058 rows\n",
      "üîÑ Applying DEMA Smoothing...\n",
      "========================================\n",
      "\n",
      "Processing IR wavelength...\n",
      "  Available BC columns: ['IR BC1', 'IR BC2', 'IR BCc']\n",
      "  ‚úÖ Created IR BC1 smoothed\n",
      "  ‚úÖ Created IR BC2 smoothed\n",
      "  ‚úÖ Created IR BCc smoothed\n",
      "\n",
      "Processing Blue wavelength...\n",
      "  Available BC columns: ['Blue BC1', 'Blue BC2', 'Blue BCc']\n",
      "  ‚úÖ Created Blue BC1 smoothed\n",
      "  ‚úÖ Created Blue BC2 smoothed\n",
      "  ‚úÖ Created Blue BCc smoothed\n",
      "\n",
      "üßπ Final Cleaning Pipeline\n",
      "============================================================\n",
      "Starting PKL data cleaning pipeline...\n",
      "==================================================\n",
      "üîç Data Structure Diagnosis:\n",
      "------------------------------\n",
      "DataFrame shape: (1627058, 284)\n",
      "Date range: 2022-04-12 09:12:00 to 2025-06-26 23:18:00\n",
      "BC columns: 15 (e.g., ['Blue BC1', 'Blue BC2', 'Blue BCc'])\n",
      "BC smoothed columns: 6 (e.g., ['IR BC1 smoothed', 'IR BC2 smoothed', 'IR BCc smoothed'])\n",
      "ATN columns: 40 (e.g., ['Blue ATN1', 'Blue ATN2', 'Green ATN1'])\n",
      "Flow columns: 4 (e.g., ['Flow setpoint (mL/min)', 'Flow total (mL/min)', 'Flow1 (mL/min)'])\n",
      "\n",
      "Targeted wavelengths: ['IR', 'Blue']\n",
      "  IR: ‚úÖ BC | ‚úÖ BC smoothed | ‚úÖ ATN\n",
      "  Blue: ‚úÖ BC | ‚úÖ BC smoothed | ‚úÖ ATN\n",
      "------------------------------\n",
      "\n",
      "üßπ Starting cleaning steps...\n",
      "1919 datapoints removed due to Start up or Tape advance status\n",
      "Statuses of concern, count by device and status:\n",
      "\n",
      "MA350-0238 Flow unstable 750\n",
      "MA350-0238 Optical saturation 0\n",
      "MA350-0238 Sample timing error 0\n",
      "Number of datapoints with invalid optics values\n",
      "AFTER dropping data with 'Optical saturation' status values: 802\n",
      "Removed 56128 datapoints for optics\n",
      "Status cleaning: Removed 58797 rows (3.61%)\n",
      "Extreme BCc cleaning: Removed 13900 rows (0.89%)\n",
      "Flow range cleaning: Removed 0 rows (0.00%)\n",
      "Abnormal flow ratio: Removed 29362 rows (1.89%)\n",
      "Leak ratio cleaning: Removed 507 rows (0.03%)\n",
      "BCc denominator cleaning: Removed 25537 rows (1.68%)\n",
      "Sharp change 605\n",
      "noise 1425\n",
      "Temperature change cleaning: Removed 2030 rows (0.14%)\n",
      "IR ATN1_roughness: threshold=0.1147, high periods flagged: 17945 rows so far\n",
      "IR ATN2_roughness: threshold=0.1008, high periods flagged: 18439 rows so far\n",
      "Blue ATN1_roughness: threshold=0.1859, high periods flagged: 19114 rows so far\n",
      "Blue ATN2_roughness: threshold=0.1664, high periods flagged: 19142 rows so far\n",
      "==================================================\n",
      "Cleaning complete! Final data shape: (1477783, 293)\n",
      "\n",
      "üìä Processing Results Summary:\n",
      "============================================================\n",
      "Original data points: 1,665,156\n",
      "After preprocessing: 1,627,058\n",
      "After smoothing: 1,627,058\n",
      "Final cleaned: 1,477,783\n",
      "Total removed: 187,373 (11.25%)\n",
      "\n",
      "‚úÖ PKL data processing completed successfully!\n",
      "\n",
      "üìä Final data verification:\n",
      "Shape: (1477783, 293)\n",
      "Date range: 2022-04-12 09:54:00 to 2025-06-26 23:18:00\n",
      "  ‚úÖ IR ATN1\n",
      "  ‚úÖ IR BCc\n",
      "  ‚úÖ Blue ATN1\n",
      "  ‚úÖ Blue BCc\n",
      "  ‚úÖ Flow total (mL/min)\n",
      "  ‚úÖ Smoothed columns: 6\n",
      "\n",
      "üíæ Cleaned data exported:\n",
      "  üìÑ CSV: pkl_data_cleaned_enhanced.csv\n",
      "  üì¶ Pickle: pkl_data_cleaned_enhanced.pkl\n",
      "\n",
      "üéâ Processing Complete!\n",
      "üìä Final shape: (1477783, 293)\n",
      "üöÄ Ready for further analysis!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# SIMPLIFIED PROCESSING: Replace all the complex pipeline with one function call!\n",
    "\n",
    "# Option 1: Simple one-liner (with export)\n",
    "pkl_data_cleaned = process_pkl_data_enhanced(\n",
    "    pkl_data_original,\n",
    "    wavelengths_to_filter=['IR', 'Blue'],  # Focus on IR and Blue\n",
    "    export_path='pkl_data_cleaned_enhanced',  # Will create .csv and .pkl files\n",
    "    verbose=True  # Show detailed progress\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Processing Complete!\")\n",
    "print(f\"üìä Final shape: {pkl_data_cleaned.shape}\")\n",
    "print(\"üöÄ Ready for further analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Option 2: More control with the class (if you need to customize further)\n",
    "\n",
    "# Create processor with custom settings\n",
    "processor = EnhancedPKLProcessor(\n",
    "    wavelengths_to_filter=['IR', 'Blue'],\n",
    "    verbose=True,\n",
    "    # You can pass additional PKLDataCleaner arguments here\n",
    "    quality_threshold=10  # Example custom parameter\n",
    ")\n",
    "\n",
    "# Run the full pipeline\n",
    "pkl_data_cleaned_v2 = processor.process_pkl_data(\n",
    "    pkl_data_original,\n",
    "    export_path='pkl_data_cleaned_v2'\n",
    ")\n",
    "\n",
    "# Or run individual steps if needed\n",
    "# df_preprocessed = processor.comprehensive_preprocessing(pkl_data_original)\n",
    "# df_smoothed = processor.apply_dema_smoothing(df_preprocessed)\n",
    "# df_cleaned = processor.cleaner.clean_pipeline(df_smoothed, skip_preprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Final Verification:\n",
      "==================================================\n",
      "‚úÖ datetime_local\n",
      "‚úÖ IR ATN1\n",
      "‚úÖ IR BCc\n",
      "‚úÖ Blue ATN1\n",
      "‚úÖ Blue BCc\n",
      "‚úÖ Flow total (mL/min)\n",
      "\n",
      "üìà Smoothed columns (6):\n",
      "  ‚Ä¢ IR BC1 smoothed\n",
      "  ‚Ä¢ IR BC2 smoothed\n",
      "  ‚Ä¢ IR BCc smoothed\n",
      "  ‚Ä¢ Blue BC1 smoothed\n",
      "  ‚Ä¢ Blue BC2 smoothed\n",
      "  ‚Ä¢ Blue BCc smoothed\n",
      "\n",
      "üìä Summary Statistics:\n",
      "Original rows: 1,665,156\n",
      "Final rows: 1,477,783\n",
      "Columns: 293\n",
      "Date range: 2022-04-12 09:54:00 to 2025-06-26 23:18:00\n",
      "Memory usage: 7090.1 MB\n",
      "\n",
      "‚úÖ Enhanced PKL processing complete and verified!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Verification and comparison\n",
    "print(\"\\nüìä Final Verification:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check that we have all the key columns\n",
    "key_columns = ['datetime_local', 'IR ATN1', 'IR BCc', 'Blue ATN1', 'Blue BCc', 'Flow total (mL/min)']\n",
    "for col in key_columns:\n",
    "    if col in pkl_data_cleaned.columns:\n",
    "        print(f\"‚úÖ {col}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {col}\")\n",
    "\n",
    "# Check smoothed columns\n",
    "smoothed_cols = [col for col in pkl_data_cleaned.columns if 'smoothed' in col]\n",
    "print(f\"\\nüìà Smoothed columns ({len(smoothed_cols)}):\")\n",
    "for col in smoothed_cols[:10]:  # Show first 10\n",
    "    print(f\"  ‚Ä¢ {col}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä Summary Statistics:\")\n",
    "print(f\"Original rows: {len(pkl_data_original):,}\")\n",
    "print(f\"Final rows: {len(pkl_data_cleaned):,}\")\n",
    "print(f\"Columns: {pkl_data_cleaned.shape[1]}\")\n",
    "print(f\"Date range: {pkl_data_cleaned['datetime_local'].min()} to {pkl_data_cleaned['datetime_local'].max()}\")\n",
    "\n",
    "# Memory usage\n",
    "memory_mb = pkl_data_cleaned.memory_usage(deep=True).sum() / 1024 / 1024\n",
    "print(f\"Memory usage: {memory_mb:.1f} MB\")\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced PKL processing complete and verified!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Quick Quality Check\n",
      "Time range: 2022-04-12 09:54:00 to 2025-06-26 23:18:00 (1172 days)\n",
      "Expected points: 1,687,045\n",
      "Actual points: 1,477,783\n",
      "Missing: 209,262 (12.40%)\n",
      "Full missing days: 69\n",
      "Partial missing days: 1100\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Optional: Quick quality check using the modular QC tools\n",
    "from data.qc import quick_quality_check\n",
    "\n",
    "# Set datetime as index for quality check\n",
    "pkl_for_qc = pkl_data_cleaned.set_index('datetime_local')\n",
    "quick_quality_check(pkl_for_qc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
