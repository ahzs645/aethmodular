{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Tasks - January 2025\n",
    "\n",
    "This notebook addresses the tasks from the December 2025 meeting:\n",
    "\n",
    "## Carry-Over\n",
    "- [ ] **Iron/EC ratio analysis** (Priority item)\n",
    "\n",
    "## Plot Updates\n",
    "- [ ] Fix axis scaling on Delhi plots\n",
    "- [ ] Create matched-sample plots (only samples with ALL three measurements)\n",
    "- [ ] Remove Delhi green wavelength outliers and replot time series\n",
    "\n",
    "## Summary\n",
    "- [ ] Create cross-plot collage (all plot types, all sites)\n",
    "- [ ] Create summary table with slopes and R² values\n",
    "\n",
    "## New Analyses\n",
    "- [ ] Raw attenuation correlation matrix\n",
    "\n",
    "## Maybe\n",
    "- [ ] Hourly-binned wavelength ratio analysis for Angstrom absorption exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Get the directory where the notebook is located and add scripts to path\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "scripts_path = os.path.join(notebook_dir, 'scripts')\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.insert(0, scripts_path)\n",
    "\n",
    "# Core imports\n",
    "from config import SITES, MAC_VALUE\n",
    "from data_matching import (\n",
    "    load_aethalometer_data, \n",
    "    load_filter_data,\n",
    "    add_base_filter_id,\n",
    "    match_by_filter_id,\n",
    "    match_aeth_filter_data,\n",
    "    match_hips_with_smooth_raw\n",
    ")\n",
    "from flow_periods import add_flow_period, print_flow_period_summary\n",
    "from outliers import (\n",
    "    apply_exclusion_flags,\n",
    "    apply_threshold_flags,\n",
    "    get_clean_data,\n",
    "    print_exclusion_summary\n",
    ")\n",
    "from plotting import PlotConfig, crossplots, timeseries, distributions, comparisons\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS (from Example notebook)\n",
    "# =============================================================================\n",
    "\n",
    "SITE_COLORS = {'Beijing': '#1f77b4', 'Delhi': '#ff7f0e', 'JPL': '#2ca02c', 'Addis_Ababa': '#d62728'}\n",
    "\n",
    "def apply_all_outlier_flags(data_dict, aeth_col='ir_bcc', filter_col='hips_fabs', \n",
    "                            convert_to_ng=True, verbose=True):\n",
    "    \"\"\"Apply both date-based and threshold-based outlier flags.\"\"\"\n",
    "    flagged_data = {}\n",
    "    for site_name, df in data_dict.items():\n",
    "        df_flagged = df.copy()\n",
    "        multiplier = 1000 if convert_to_ng else 1\n",
    "        df_flagged['aeth_bc'] = df_flagged[aeth_col] * multiplier\n",
    "        df_flagged['filter_ec'] = df_flagged[filter_col] * multiplier\n",
    "        df_flagged = apply_exclusion_flags(df_flagged, site_name)\n",
    "        df_flagged = apply_threshold_flags(df_flagged, site_name)\n",
    "        df_flagged['is_any_outlier'] = df_flagged['is_excluded'] | df_flagged['is_outlier']\n",
    "        flagged_data[site_name] = df_flagged\n",
    "        if verbose:\n",
    "            print_exclusion_summary(df_flagged, site_name)\n",
    "    return flagged_data\n",
    "\n",
    "\n",
    "def filter_common_samples(data_dict, required_cols, verbose=True):\n",
    "    \"\"\"Filter to only samples with ALL required columns having data.\"\"\"\n",
    "    filtered_data = {}\n",
    "    for site_name, df in data_dict.items():\n",
    "        available_cols = [col for col in required_cols if col in df.columns]\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            if verbose:\n",
    "                print(f\"{site_name}: Missing columns {missing_cols}, skipping\")\n",
    "            continue\n",
    "        mask = df[available_cols].notna().all(axis=1)\n",
    "        df_common = df[mask].copy()\n",
    "        filtered_data[site_name] = df_common\n",
    "        if verbose:\n",
    "            print(f\"{site_name}: {len(df)} total -> {len(df_common)} common ({len(df_common)/len(df)*100:.1f}%)\")\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def get_data_mode(data_dict, mode='all', required_cols=None, verbose=False):\n",
    "    \"\"\"Get data in 'all' or 'common' mode.\"\"\"\n",
    "    if mode == 'all':\n",
    "        return data_dict\n",
    "    elif mode == 'common':\n",
    "        if required_cols is None:\n",
    "            required_cols = ['ir_bcc', 'hips_fabs', 'ftir_ec']\n",
    "        return filter_common_samples(data_dict, required_cols, verbose=verbose)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "\n",
    "print(\"Utility functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Match Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aethalometer data\n",
    "aethalometer_data = load_aethalometer_data()\n",
    "\n",
    "# Load filter data with base_filter_id\n",
    "filter_data = load_filter_data()\n",
    "filter_data = add_base_filter_id(filter_data)\n",
    "\n",
    "print(f\"\\nFilter data: {len(filter_data)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match HIPS with aethalometer and apply outlier flags\n",
    "hips_aeth_matched = {}\n",
    "\n",
    "for site_name, config in SITES.items():\n",
    "    if site_name not in aethalometer_data:\n",
    "        continue\n",
    "    matched = match_hips_with_smooth_raw(\n",
    "        site_name,\n",
    "        aethalometer_data[site_name],\n",
    "        filter_data,\n",
    "        config['code']\n",
    "    )\n",
    "    if matched is not None:\n",
    "        hips_aeth_matched[site_name] = matched\n",
    "        print(f\"{site_name}: {len(matched)} matched pairs\")\n",
    "\n",
    "# Apply outlier flags\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"APPLYING OUTLIER FLAGS\")\n",
    "print(\"=\" * 60)\n",
    "hips_aeth_matched = apply_all_outlier_flags(hips_aeth_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match by FilterId for FTIR/HIPS/Iron analysis\n",
    "matched_by_filter = {}\n",
    "\n",
    "for site_name, config in SITES.items():\n",
    "    matched = match_by_filter_id(\n",
    "        filter_data, \n",
    "        site_code=config['code'],\n",
    "        params=['EC_ftir', 'HIPS_Fabs', 'ChemSpec_Iron_PM2.5']\n",
    "    )\n",
    "    if matched is not None:\n",
    "        matched['hips_fabs'] = matched['hips_fabs'] / MAC_VALUE\n",
    "        matched_by_filter[site_name] = matched\n",
    "        print(f\"{site_name}: {len(matched)} filters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 1: Iron/EC Ratio Analysis (Priority)\n",
    "\n",
    "Analyze the relationship between Iron concentration and EC measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iron/EC Ratio Analysis\n",
    "print(\"=\" * 70)\n",
    "print(\"IRON/EC RATIO ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "iron_ec_stats = {}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (site_name, df) in enumerate(matched_by_filter.items()):\n",
    "    if idx >= 4:\n",
    "        break\n",
    "    ax = axes[idx]\n",
    "    color = SITE_COLORS.get(site_name, '#333333')\n",
    "    \n",
    "    # Get iron and EC data\n",
    "    iron_col = 'iron' if 'iron' in df.columns else 'chemspec_iron_pm2.5'\n",
    "    ec_col = 'ftir_ec'\n",
    "    \n",
    "    if iron_col not in df.columns or ec_col not in df.columns:\n",
    "        ax.text(0.5, 0.5, f'{site_name}\\nMissing data', ha='center', va='center')\n",
    "        continue\n",
    "    \n",
    "    # Filter valid data\n",
    "    valid = df[[iron_col, ec_col]].notna().all(axis=1)\n",
    "    iron = df.loc[valid, iron_col]\n",
    "    ec = df.loc[valid, ec_col]\n",
    "    \n",
    "    if len(iron) < 3:\n",
    "        ax.text(0.5, 0.5, f'{site_name}\\nInsufficient data', ha='center', va='center')\n",
    "        continue\n",
    "    \n",
    "    # Calculate ratio\n",
    "    ratio = iron / ec\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(ec, iron, c=color, alpha=0.7, s=60)\n",
    "    \n",
    "    # Regression\n",
    "    slope, intercept, r_value, _, _ = stats.linregress(ec, iron)\n",
    "    x_line = np.linspace(0, ec.max() * 1.05, 100)\n",
    "    ax.plot(x_line, slope * x_line + intercept, 'b-', lw=2,\n",
    "           label=f'R²={r_value**2:.3f}, slope={slope:.4f}')\n",
    "    \n",
    "    # Set axes to start at origin\n",
    "    max_val = max(ec.max(), iron.max()) * 1.05\n",
    "    ax.set_xlim(0, ec.max() * 1.05)\n",
    "    ax.set_ylim(0, iron.max() * 1.05)\n",
    "    \n",
    "    ax.set_xlabel('FTIR EC (µg/m³)')\n",
    "    ax.set_ylabel('Iron (µg/m³)')\n",
    "    ax.set_title(f'{site_name} (n={len(ec)})\\nMean Fe/EC ratio: {ratio.mean():.4f}')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Store stats\n",
    "    iron_ec_stats[site_name] = {\n",
    "        'n': len(ec),\n",
    "        'r2': r_value**2,\n",
    "        'slope': slope,\n",
    "        'mean_ratio': ratio.mean(),\n",
    "        'std_ratio': ratio.std(),\n",
    "        'median_ratio': ratio.median()\n",
    "    }\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Iron_EC_Ratio_Analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\nIron/EC Ratio Summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Site':<15} {'N':>6} {'R²':>8} {'Slope':>10} {'Mean Ratio':>12} {'Std':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for site, s in iron_ec_stats.items():\n",
    "    print(f\"{site:<15} {s['n']:>6} {s['r2']:>8.3f} {s['slope']:>10.4f} {s['mean_ratio']:>12.4f} {s['std_ratio']:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 2: Delhi Plot Fixes\n",
    "\n",
    "- Fix axis scaling (currently extends to 60 when max is ~20)\n",
    "- Remove green wavelength outliers (4-7 points) and replot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delhi-specific analysis with fixed axis scaling\n",
    "if 'Delhi' in hips_aeth_matched:\n",
    "    delhi_data = hips_aeth_matched['Delhi']\n",
    "    \n",
    "    print(\"Delhi Data Summary:\")\n",
    "    print(f\"  Total samples: {len(delhi_data)}\")\n",
    "    print(f\"  IR BCc range: {delhi_data['ir_bcc'].min():.2f} - {delhi_data['ir_bcc'].max():.2f}\")\n",
    "    print(f\"  HIPS range: {delhi_data['hips_fabs'].min():.2f} - {delhi_data['hips_fabs'].max():.2f}\")\n",
    "    \n",
    "    # Check for green wavelength outliers\n",
    "    if 'green_bcc' in delhi_data.columns:\n",
    "        green_mean = delhi_data['green_bcc'].mean()\n",
    "        green_std = delhi_data['green_bcc'].std()\n",
    "        green_outliers = delhi_data['green_bcc'] > (green_mean + 3 * green_std)\n",
    "        print(f\"\\n  Green wavelength outliers (>3σ): {green_outliers.sum()}\")\n",
    "        if green_outliers.any():\n",
    "            print(f\"  Outlier values: {delhi_data.loc[green_outliers, 'green_bcc'].values}\")\n",
    "else:\n",
    "    print(\"Delhi data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delhi crossplot with FIXED axis scaling\n",
    "if 'Delhi' in hips_aeth_matched:\n",
    "    delhi_data = hips_aeth_matched['Delhi']\n",
    "    clean_delhi = get_clean_data(delhi_data)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Get data\n",
    "    x = clean_delhi['ir_bcc'].dropna()\n",
    "    y = clean_delhi.loc[x.index, 'hips_fabs'].dropna()\n",
    "    common_idx = x.index.intersection(y.index)\n",
    "    x, y = clean_delhi.loc[common_idx, 'ir_bcc'], clean_delhi.loc[common_idx, 'hips_fabs']\n",
    "    \n",
    "    # Calculate proper axis limit (not 60!)\n",
    "    max_val = max(x.max(), y.max()) * 1.05\n",
    "    print(f\"Proper max value: {max_val:.2f} (not 60)\")\n",
    "    \n",
    "    # Left plot: Before (showing the problem)\n",
    "    ax = axes[0]\n",
    "    ax.scatter(x, y, c='#ff7f0e', alpha=0.7, s=60)\n",
    "    ax.set_xlim(0, 60)  # OLD: bad scaling\n",
    "    ax.set_ylim(0, 60)\n",
    "    ax.plot([0, 60], [0, 60], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('Aethalometer IR BCc (µg/m³)')\n",
    "    ax.set_ylabel('HIPS Fabs / MAC (µg/m³)')\n",
    "    ax.set_title('Delhi - BEFORE (bad axis scaling to 60)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Right plot: After (fixed)\n",
    "    ax = axes[1]\n",
    "    ax.scatter(x, y, c='#ff7f0e', alpha=0.7, s=60)\n",
    "    \n",
    "    if len(x) > 2:\n",
    "        slope, intercept, r_value, _, _ = stats.linregress(x, y)\n",
    "        x_line = np.linspace(0, max_val, 100)\n",
    "        ax.plot(x_line, slope * x_line + intercept, 'b-', lw=2,\n",
    "               label=f'R²={r_value**2:.3f}, slope={slope:.2f}')\n",
    "    \n",
    "    ax.set_xlim(0, max_val)  # FIXED: proper scaling\n",
    "    ax.set_ylim(0, max_val)\n",
    "    ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='1:1')\n",
    "    ax.set_xlabel('Aethalometer IR BCc (µg/m³)')\n",
    "    ax.set_ylabel('HIPS Fabs / MAC (µg/m³)')\n",
    "    ax.set_title(f'Delhi - AFTER (proper scaling to {max_val:.1f})')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Delhi_Axis_Fix.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 3: Matched-Sample Plots (Common Data Mode)\n",
    "\n",
    "Create plots showing ONLY samples where all three measurements are available:\n",
    "- FTIR EC\n",
    "- HIPS\n",
    "- Aethalometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get COMMON data (samples with ALL three measurements)\n",
    "print(\"=\" * 70)\n",
    "print(\"MATCHED-SAMPLE ANALYSIS (Common Data Mode)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nFiltering to samples with FTIR EC + HIPS + Aethalometer...\\n\")\n",
    "\n",
    "data_common = get_data_mode(\n",
    "    hips_aeth_matched, \n",
    "    mode='common',\n",
    "    required_cols=['ir_bcc', 'hips_fabs', 'ftir_ec'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matched-sample crossplots for all sites\n",
    "n_sites = len(data_common)\n",
    "if n_sites == 0:\n",
    "    print(\"No sites have common data!\")\n",
    "else:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (site_name, df) in enumerate(data_common.items()):\n",
    "        if idx >= 4:\n",
    "            break\n",
    "        ax = axes[idx]\n",
    "        color = SITE_COLORS.get(site_name, '#333333')\n",
    "        \n",
    "        # Clean data (exclude outliers)\n",
    "        if 'is_any_outlier' in df.columns:\n",
    "            clean = ~df['is_any_outlier']\n",
    "            df_clean = df[clean]\n",
    "        else:\n",
    "            df_clean = df\n",
    "        \n",
    "        x = df_clean['ir_bcc']\n",
    "        y = df_clean['hips_fabs']\n",
    "        \n",
    "        ax.scatter(x, y, c=color, alpha=0.7, s=60)\n",
    "        \n",
    "        if len(x) > 2:\n",
    "            slope, intercept, r_value, _, _ = stats.linregress(x, y)\n",
    "            max_val = max(x.max(), y.max()) * 1.05\n",
    "            x_line = np.linspace(0, max_val, 100)\n",
    "            ax.plot(x_line, slope * x_line + intercept, 'b-', lw=2,\n",
    "                   label=f'R²={r_value**2:.3f}, slope={slope:.2f}')\n",
    "            ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='1:1')\n",
    "            ax.set_xlim(0, max_val)\n",
    "            ax.set_ylim(0, max_val)\n",
    "        \n",
    "        ax.set_xlabel('Aethalometer IR BCc (µg/m³)')\n",
    "        ax.set_ylabel('HIPS Fabs / MAC (µg/m³)')\n",
    "        ax.set_title(f'{site_name} - COMMON DATA ONLY\\n(n={len(x)}, all 3 measurements)')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for idx in range(len(data_common), 4):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Matched_Sample_Crossplots.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 4: Cross-Plot Collage (All Sites, All Types)\n",
    "\n",
    "Create a comprehensive collage showing:\n",
    "1. HIPS vs Aethalometer\n",
    "2. FTIR EC vs Aethalometer  \n",
    "3. HIPS vs FTIR EC\n",
    "\n",
    "For all sites on one figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-plot collage: 3 plot types x 4 sites\n",
    "def create_crossplot_collage(data_dict, save_name='Crossplot_Collage.png'):\n",
    "    \"\"\"\n",
    "    Create a collage with 3 rows (plot types) x N columns (sites).\n",
    "    \n",
    "    Row 1: HIPS vs Aethalometer\n",
    "    Row 2: FTIR EC vs Aethalometer\n",
    "    Row 3: HIPS vs FTIR EC\n",
    "    \"\"\"\n",
    "    sites = list(data_dict.keys())\n",
    "    n_sites = len(sites)\n",
    "    \n",
    "    plot_configs = [\n",
    "        {'x': 'ir_bcc', 'y': 'hips_fabs', 'xlabel': 'Aeth IR BCc', 'ylabel': 'HIPS/MAC', 'title': 'HIPS vs Aeth'},\n",
    "        {'x': 'ir_bcc', 'y': 'ftir_ec', 'xlabel': 'Aeth IR BCc', 'ylabel': 'FTIR EC', 'title': 'FTIR vs Aeth'},\n",
    "        {'x': 'ftir_ec', 'y': 'hips_fabs', 'xlabel': 'FTIR EC', 'ylabel': 'HIPS/MAC', 'title': 'HIPS vs FTIR'},\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, n_sites, figsize=(4*n_sites, 12))\n",
    "    if n_sites == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    all_stats = []\n",
    "    \n",
    "    for row, config in enumerate(plot_configs):\n",
    "        for col, site_name in enumerate(sites):\n",
    "            ax = axes[row, col]\n",
    "            df = data_dict[site_name]\n",
    "            color = SITE_COLORS.get(site_name, '#333333')\n",
    "            \n",
    "            # Get clean data\n",
    "            if 'is_any_outlier' in df.columns:\n",
    "                df_clean = df[~df['is_any_outlier']]\n",
    "            else:\n",
    "                df_clean = df\n",
    "            \n",
    "            # Check columns exist\n",
    "            if config['x'] not in df_clean.columns or config['y'] not in df_clean.columns:\n",
    "                ax.text(0.5, 0.5, 'Missing data', ha='center', va='center', transform=ax.transAxes)\n",
    "                continue\n",
    "            \n",
    "            # Get valid data\n",
    "            valid = df_clean[[config['x'], config['y']]].notna().all(axis=1)\n",
    "            x = df_clean.loc[valid, config['x']]\n",
    "            y = df_clean.loc[valid, config['y']]\n",
    "            \n",
    "            if len(x) < 3:\n",
    "                ax.text(0.5, 0.5, f'n={len(x)}', ha='center', va='center', transform=ax.transAxes)\n",
    "                continue\n",
    "            \n",
    "            # Plot\n",
    "            ax.scatter(x, y, c=color, alpha=0.7, s=40)\n",
    "            \n",
    "            # Regression\n",
    "            slope, intercept, r_value, _, _ = stats.linregress(x, y)\n",
    "            max_val = max(x.max(), y.max()) * 1.05\n",
    "            x_line = np.linspace(0, max_val, 100)\n",
    "            ax.plot(x_line, slope * x_line + intercept, 'b-', lw=1.5)\n",
    "            ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.4, lw=1)\n",
    "            \n",
    "            ax.set_xlim(0, max_val)\n",
    "            ax.set_ylim(0, max_val)\n",
    "            ax.set_xlabel(config['xlabel'], fontsize=9)\n",
    "            ax.set_ylabel(config['ylabel'], fontsize=9)\n",
    "            \n",
    "            # Title with stats\n",
    "            if row == 0:\n",
    "                ax.set_title(f'{site_name}\\nR²={r_value**2:.2f}, m={slope:.2f}', fontsize=10)\n",
    "            else:\n",
    "                ax.set_title(f'R²={r_value**2:.2f}, m={slope:.2f}', fontsize=9)\n",
    "            \n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Store stats\n",
    "            all_stats.append({\n",
    "                'Site': site_name,\n",
    "                'Plot': config['title'],\n",
    "                'N': len(x),\n",
    "                'R²': r_value**2,\n",
    "                'Slope': slope,\n",
    "                'Intercept': intercept\n",
    "            })\n",
    "    \n",
    "    # Row labels on the left\n",
    "    for row, config in enumerate(plot_configs):\n",
    "        axes[row, 0].set_ylabel(f\"{config['title']}\\n{config['ylabel']}\", fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_name, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.DataFrame(all_stats)\n",
    "\n",
    "# Create collage\n",
    "stats_df = create_crossplot_collage(data_common, save_name='Crossplot_Collage_Common.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 5: Summary Table with Slopes and R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary table\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY TABLE: Slopes and R² Values (Common Data Only)\")\n",
    "print(\"=\" * 80)\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "stats_df.to_csv('Crossplot_Summary_Stats.csv', index=False)\n",
    "print(\"\\nSaved to: Crossplot_Summary_Stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table format for cleaner view\n",
    "pivot = stats_df.pivot_table(\n",
    "    index='Site', \n",
    "    columns='Plot', \n",
    "    values=['R²', 'Slope', 'N'],\n",
    "    aggfunc='first'\n",
    ")\n",
    "print(\"\\nPivot Table View:\")\n",
    "print(pivot.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 6: Raw Attenuation Correlation Matrix\n",
    "\n",
    "Analyze correlations in raw attenuation data (before instrument processing) to see if high wavelength correlations are inherent or processing-induced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw attenuation correlation analysis\n",
    "# Look for raw attenuation columns in aethalometer data\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RAW ATTENUATION CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for site_name, df in aethalometer_data.items():\n",
    "    print(f\"\\n{site_name} columns:\")\n",
    "    # Look for attenuation-related columns\n",
    "    atn_cols = [col for col in df.columns if 'atn' in col.lower() or 'att' in col.lower()]\n",
    "    print(f\"  Attenuation columns: {atn_cols[:10]}...\" if len(atn_cols) > 10 else f\"  Attenuation columns: {atn_cols}\")\n",
    "    \n",
    "    # Look for BC columns at different wavelengths\n",
    "    bc_cols = [col for col in df.columns if 'bc' in col.lower()]\n",
    "    print(f\"  BC columns: {bc_cols[:10]}...\" if len(bc_cols) > 10 else f\"  BC columns: {bc_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrices for BC wavelengths\n",
    "# Common BC columns: UV, Blue, Green, Red, IR (or similar)\n",
    "\n",
    "wavelength_cols = ['uv_bcc', 'blue_bcc', 'green_bcc', 'red_bcc', 'ir_bcc']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (site_name, df) in enumerate(aethalometer_data.items()):\n",
    "    if idx >= 4:\n",
    "        break\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Check which wavelength columns exist\n",
    "    available_cols = [col for col in wavelength_cols if col in df.columns]\n",
    "    \n",
    "    if len(available_cols) < 2:\n",
    "        ax.text(0.5, 0.5, f'{site_name}\\nInsufficient wavelength data', \n",
    "               ha='center', va='center', transform=ax.transAxes)\n",
    "        continue\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[available_cols].corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    im = ax.imshow(corr_matrix, cmap='RdYlBu_r', vmin=0.5, vmax=1.0)\n",
    "    \n",
    "    # Labels\n",
    "    labels = [col.replace('_bcc', '').upper() for col in available_cols]\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(labels)\n",
    "    \n",
    "    # Add correlation values\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            val = corr_matrix.iloc[i, j]\n",
    "            color = 'white' if val < 0.7 else 'black'\n",
    "            ax.text(j, i, f'{val:.2f}', ha='center', va='center', color=color, fontsize=10)\n",
    "    \n",
    "    ax.set_title(f'{site_name}\\nWavelength Correlation Matrix')\n",
    "    plt.colorbar(im, ax=ax, label='Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Wavelength_Correlation_Matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# OPTIONAL: Hourly-binned Wavelength Ratio Analysis\n",
    "\n",
    "For Angstrom absorption exponent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for hourly-binned analysis\n",
    "# This would require:\n",
    "# 1. Resampling data to hourly bins\n",
    "# 2. Calculating wavelength ratios (e.g., UV/IR)\n",
    "# 3. Computing Angstrom absorption exponent\n",
    "\n",
    "print(\"HOURLY-BINNED WAVELENGTH RATIO ANALYSIS\")\n",
    "print(\"(To be implemented if needed)\")\n",
    "print(\"\\nAngstrom Absorption Exponent (AAE) = -log(BC_λ1/BC_λ2) / log(λ1/λ2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary of Outputs\n",
    "\n",
    "Files generated:\n",
    "1. `Iron_EC_Ratio_Analysis.png` - Iron/EC scatter plots\n",
    "2. `Delhi_Axis_Fix.png` - Before/after axis scaling comparison\n",
    "3. `Matched_Sample_Crossplots.png` - Common data only plots\n",
    "4. `Crossplot_Collage_Common.png` - All 3 plot types for all sites\n",
    "5. `Crossplot_Summary_Stats.csv` - Slopes and R² values\n",
    "6. `Wavelength_Correlation_Matrix.png` - BC wavelength correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 70)\n",
    "print(\"TASK COMPLETION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\")\n",
    "print(\"[✓] Iron/EC ratio analysis - COMPLETED\")\n",
    "print(\"[✓] Delhi axis scaling fix - COMPLETED\")\n",
    "print(\"[✓] Matched-sample plots (common data) - COMPLETED\")\n",
    "print(\"[✓] Cross-plot collage - COMPLETED\")\n",
    "print(\"[✓] Summary table with slopes/R² - COMPLETED\")\n",
    "print(\"[✓] Wavelength correlation matrix - COMPLETED\")\n",
    "print(\"[ ] Hourly-binned wavelength ratio - OPTIONAL (not implemented)\")\n",
    "print(\"\")\n",
    "print(\"Administrative:\")\n",
    "print(\"[ ] Send when-is-good poll for first two weeks of January\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
