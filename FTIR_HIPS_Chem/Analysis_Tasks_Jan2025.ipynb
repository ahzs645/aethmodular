{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Tasks - January 2025\n",
    "\n",
    "This notebook addresses the tasks from the December 2025 meeting:\n",
    "\n",
    "## Carry-Over\n",
    "- [ ] **Iron/EC ratio analysis** (Priority item)\n",
    "\n",
    "## Plot Updates\n",
    "- [ ] Fix axis scaling on Delhi plots\n",
    "- [ ] Create matched-sample plots (only samples with ALL three measurements)\n",
    "- [ ] Remove Delhi green wavelength outliers and replot time series\n",
    "\n",
    "## Summary\n",
    "- [ ] Create cross-plot collage (all plot types, all sites)\n",
    "- [ ] Create summary table with slopes and R² values\n",
    "\n",
    "## New Analyses\n",
    "- [ ] Raw attenuation correlation matrix\n",
    "\n",
    "## Maybe\n",
    "- [ ] Hourly-binned wavelength ratio analysis for Angstrom absorption exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n# Get the directory where the notebook is located and add scripts to path\nnotebook_dir = os.path.dirname(os.path.abspath('__file__'))\nscripts_path = os.path.join(notebook_dir, 'scripts')\nif scripts_path not in sys.path:\n    sys.path.insert(0, scripts_path)\n\n# Core imports\nfrom config import SITES, MAC_VALUE\nfrom data_matching import (\n    load_aethalometer_data, \n    load_filter_data,\n    add_base_filter_id,\n    match_by_filter_id,\n    match_aeth_filter_data,\n    match_hips_with_smooth_raw,\n    match_all_parameters  # For getting data with ALL measurements\n)\nfrom flow_periods import add_flow_period, print_flow_period_summary\nfrom outliers import (\n    apply_exclusion_flags,\n    apply_threshold_flags,\n    get_clean_data,\n    print_exclusion_summary\n)\nfrom plotting import PlotConfig, crossplots, timeseries, distributions, comparisons\n\nprint(\"Imports successful!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS (from Example notebook)\n",
    "# =============================================================================\n",
    "\n",
    "SITE_COLORS = {'Beijing': '#1f77b4', 'Delhi': '#ff7f0e', 'JPL': '#2ca02c', 'Addis_Ababa': '#d62728'}\n",
    "\n",
    "def apply_all_outlier_flags(data_dict, aeth_col='ir_bcc', filter_col='hips_fabs', \n",
    "                            convert_to_ng=True, verbose=True):\n",
    "    \"\"\"Apply both date-based and threshold-based outlier flags.\"\"\"\n",
    "    flagged_data = {}\n",
    "    for site_name, df in data_dict.items():\n",
    "        df_flagged = df.copy()\n",
    "        multiplier = 1000 if convert_to_ng else 1\n",
    "        df_flagged['aeth_bc'] = df_flagged[aeth_col] * multiplier\n",
    "        df_flagged['filter_ec'] = df_flagged[filter_col] * multiplier\n",
    "        df_flagged = apply_exclusion_flags(df_flagged, site_name)\n",
    "        df_flagged = apply_threshold_flags(df_flagged, site_name)\n",
    "        df_flagged['is_any_outlier'] = df_flagged['is_excluded'] | df_flagged['is_outlier']\n",
    "        flagged_data[site_name] = df_flagged\n",
    "        if verbose:\n",
    "            print_exclusion_summary(df_flagged, site_name)\n",
    "    return flagged_data\n",
    "\n",
    "\n",
    "def filter_common_samples(data_dict, required_cols, verbose=True):\n",
    "    \"\"\"Filter to only samples with ALL required columns having data.\"\"\"\n",
    "    filtered_data = {}\n",
    "    for site_name, df in data_dict.items():\n",
    "        available_cols = [col for col in required_cols if col in df.columns]\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            if verbose:\n",
    "                print(f\"{site_name}: Missing columns {missing_cols}, skipping\")\n",
    "            continue\n",
    "        mask = df[available_cols].notna().all(axis=1)\n",
    "        df_common = df[mask].copy()\n",
    "        filtered_data[site_name] = df_common\n",
    "        if verbose:\n",
    "            print(f\"{site_name}: {len(df)} total -> {len(df_common)} common ({len(df_common)/len(df)*100:.1f}%)\")\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def get_data_mode(data_dict, mode='all', required_cols=None, verbose=False):\n",
    "    \"\"\"Get data in 'all' or 'common' mode.\"\"\"\n",
    "    if mode == 'all':\n",
    "        return data_dict\n",
    "    elif mode == 'common':\n",
    "        if required_cols is None:\n",
    "            required_cols = ['ir_bcc', 'hips_fabs', 'ftir_ec']\n",
    "        return filter_common_samples(data_dict, required_cols, verbose=verbose)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "\n",
    "print(\"Utility functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Match Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aethalometer data\n",
    "aethalometer_data = load_aethalometer_data()\n",
    "\n",
    "# Load filter data with base_filter_id\n",
    "filter_data = load_filter_data()\n",
    "filter_data = add_base_filter_id(filter_data)\n",
    "\n",
    "print(f\"\\nFilter data: {len(filter_data)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match HIPS with aethalometer and apply outlier flags\n",
    "hips_aeth_matched = {}\n",
    "\n",
    "for site_name, config in SITES.items():\n",
    "    if site_name not in aethalometer_data:\n",
    "        continue\n",
    "    matched = match_hips_with_smooth_raw(\n",
    "        site_name,\n",
    "        aethalometer_data[site_name],\n",
    "        filter_data,\n",
    "        config['code']\n",
    "    )\n",
    "    if matched is not None:\n",
    "        hips_aeth_matched[site_name] = matched\n",
    "        print(f\"{site_name}: {len(matched)} matched pairs\")\n",
    "\n",
    "# Apply outlier flags\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"APPLYING OUTLIER FLAGS\")\n",
    "print(\"=\" * 60)\n",
    "hips_aeth_matched = apply_all_outlier_flags(hips_aeth_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Match by FilterId for FTIR/HIPS/Iron analysis\nmatched_by_filter = {}\n\nfor site_name, config in SITES.items():\n    matched = match_by_filter_id(\n        filter_data, \n        site_code=config['code'],\n        params=['EC_ftir', 'HIPS_Fabs', 'ChemSpec_Iron_PM2.5']\n    )\n    if matched is not None:\n        matched['hips_fabs'] = matched['hips_fabs'] / MAC_VALUE\n        matched_by_filter[site_name] = matched\n        print(f\"{site_name}: {len(matched)} filters, columns: {list(matched.columns)}\")"
  },
  {
   "cell_type": "code",
   "id": "uaup5h40drr",
   "source": "# Match ALL parameters (HIPS, FTIR EC, Iron, Aethalometer) for common data analysis\n# This is needed for \"common data mode\" - samples with ALL measurements\nall_params_matched = {}\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"MATCHING ALL PARAMETERS (HIPS, FTIR EC, Iron, Aethalometer)\")\nprint(\"=\" * 60)\n\nfor site_name, config in SITES.items():\n    if site_name not in aethalometer_data:\n        print(f\"{site_name}: No aethalometer data\")\n        continue\n    matched = match_all_parameters(\n        site_name, \n        config['code'], \n        aethalometer_data[site_name], \n        filter_data\n    )\n    if matched is not None:\n        all_params_matched[site_name] = matched\n        print(f\"{site_name}: {len(matched)} matched days, columns: {list(matched.columns)}\")\n    else:\n        print(f\"{site_name}: No matched data\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Iron/EC Ratio Analysis - SEPARATE PLOTS FOR EACH SITE\nprint(\"=\" * 70)\nprint(\"IRON/EC RATIO ANALYSIS\")\nprint(\"=\" * 70)\n\niron_ec_stats = {}\n\n# Debug: show what columns we have\nprint(\"\\nChecking matched_by_filter data structure:\")\nfor site_name, df in matched_by_filter.items():\n    print(f\"  {site_name}: columns = {list(df.columns)}\")\n\n# Create SEPARATE plots for each site\nfor site_name, df in matched_by_filter.items():\n    color = SITE_COLORS.get(site_name, '#333333')\n    \n    # Get iron and EC data - check what columns exist\n    iron_col = None\n    if 'iron' in df.columns:\n        iron_col = 'iron'\n    elif 'chemspec_iron_pm2.5' in df.columns:\n        iron_col = 'chemspec_iron_pm2.5'\n    \n    ec_col = 'ftir_ec'\n    \n    if iron_col is None:\n        print(f\"\\n{site_name}: No iron column found, skipping\")\n        continue\n    if ec_col not in df.columns:\n        print(f\"\\n{site_name}: No FTIR EC column found, skipping\")\n        continue\n    \n    # Filter valid data\n    valid = df[[iron_col, ec_col]].notna().all(axis=1)\n    iron = df.loc[valid, iron_col]\n    ec = df.loc[valid, ec_col]\n    \n    if len(iron) < 3:\n        print(f\"\\n{site_name}: Insufficient data (n={len(iron)})\")\n        continue\n    \n    # Calculate ratio\n    ratio = iron / ec\n    \n    # Create figure for this site\n    fig, ax = plt.subplots(figsize=(8, 7))\n    \n    # Scatter plot\n    ax.scatter(ec, iron, c=color, alpha=0.7, s=60)\n    \n    # Regression\n    slope, intercept, r_value, _, _ = stats.linregress(ec, iron)\n    x_line = np.linspace(0, ec.max() * 1.05, 100)\n    ax.plot(x_line, slope * x_line + intercept, 'b-', lw=2,\n           label=f'R²={r_value**2:.3f}, slope={slope:.4f}')\n    \n    # Set axes to start at origin\n    ax.set_xlim(0, ec.max() * 1.05)\n    ax.set_ylim(0, iron.max() * 1.05)\n    \n    ax.set_xlabel('FTIR EC (µg/m³)', fontsize=12)\n    ax.set_ylabel('Iron (µg/m³)', fontsize=12)\n    ax.set_title(f'{site_name} - Iron vs FTIR EC\\n(n={len(ec)}, Mean Fe/EC ratio: {ratio.mean():.4f})', fontsize=14)\n    ax.legend(loc='upper left')\n    ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(f'Iron_EC_{site_name}.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    # Store stats\n    iron_ec_stats[site_name] = {\n        'n': len(ec),\n        'r2': r_value**2,\n        'slope': slope,\n        'mean_ratio': ratio.mean(),\n        'std_ratio': ratio.std(),\n        'median_ratio': ratio.median()\n    }\n    \n    print(f\"\\n{site_name}: n={len(ec)}, R²={r_value**2:.3f}, Mean Fe/EC={ratio.mean():.4f}\")\n\n# Print summary table\nprint(\"\\n\" + \"=\" * 80)\nprint(\"IRON/EC RATIO SUMMARY\")\nprint(\"=\" * 80)\nprint(f\"{'Site':<15} {'N':>6} {'R²':>8} {'Slope':>10} {'Mean Ratio':>12} {'Std':>10}\")\nprint(\"-\" * 80)\nfor site, s in iron_ec_stats.items():\n    print(f\"{site:<15} {s['n']:>6} {s['r2']:>8.3f} {s['slope']:>10.4f} {s['mean_ratio']:>12.4f} {s['std_ratio']:>10.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iron/EC Ratio Analysis\n",
    "print(\"=\" * 70)\n",
    "print(\"IRON/EC RATIO ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "iron_ec_stats = {}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (site_name, df) in enumerate(matched_by_filter.items()):\n",
    "    if idx >= 4:\n",
    "        break\n",
    "    ax = axes[idx]\n",
    "    color = SITE_COLORS.get(site_name, '#333333')\n",
    "    \n",
    "    # Get iron and EC data\n",
    "    iron_col = 'iron' if 'iron' in df.columns else 'chemspec_iron_pm2.5'\n",
    "    ec_col = 'ftir_ec'\n",
    "    \n",
    "    if iron_col not in df.columns or ec_col not in df.columns:\n",
    "        ax.text(0.5, 0.5, f'{site_name}\\nMissing data', ha='center', va='center')\n",
    "        continue\n",
    "    \n",
    "    # Filter valid data\n",
    "    valid = df[[iron_col, ec_col]].notna().all(axis=1)\n",
    "    iron = df.loc[valid, iron_col]\n",
    "    ec = df.loc[valid, ec_col]\n",
    "    \n",
    "    if len(iron) < 3:\n",
    "        ax.text(0.5, 0.5, f'{site_name}\\nInsufficient data', ha='center', va='center')\n",
    "        continue\n",
    "    \n",
    "    # Calculate ratio\n",
    "    ratio = iron / ec\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(ec, iron, c=color, alpha=0.7, s=60)\n",
    "    \n",
    "    # Regression\n",
    "    slope, intercept, r_value, _, _ = stats.linregress(ec, iron)\n",
    "    x_line = np.linspace(0, ec.max() * 1.05, 100)\n",
    "    ax.plot(x_line, slope * x_line + intercept, 'b-', lw=2,\n",
    "           label=f'R²={r_value**2:.3f}, slope={slope:.4f}')\n",
    "    \n",
    "    # Set axes to start at origin\n",
    "    max_val = max(ec.max(), iron.max()) * 1.05\n",
    "    ax.set_xlim(0, ec.max() * 1.05)\n",
    "    ax.set_ylim(0, iron.max() * 1.05)\n",
    "    \n",
    "    ax.set_xlabel('FTIR EC (µg/m³)')\n",
    "    ax.set_ylabel('Iron (µg/m³)')\n",
    "    ax.set_title(f'{site_name} (n={len(ec)})\\nMean Fe/EC ratio: {ratio.mean():.4f}')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Store stats\n",
    "    iron_ec_stats[site_name] = {\n",
    "        'n': len(ec),\n",
    "        'r2': r_value**2,\n",
    "        'slope': slope,\n",
    "        'mean_ratio': ratio.mean(),\n",
    "        'std_ratio': ratio.std(),\n",
    "        'median_ratio': ratio.median()\n",
    "    }\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Iron_EC_Ratio_Analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\nIron/EC Ratio Summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Site':<15} {'N':>6} {'R²':>8} {'Slope':>10} {'Mean Ratio':>12} {'Std':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for site, s in iron_ec_stats.items():\n",
    "    print(f\"{site:<15} {s['n']:>6} {s['r2']:>8.3f} {s['slope']:>10.4f} {s['mean_ratio']:>12.4f} {s['std_ratio']:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 2: Delhi Plot Fixes\n",
    "\n",
    "- Fix axis scaling (currently extends to 60 when max is ~20)\n",
    "- Remove green wavelength outliers (4-7 points) and replot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delhi-specific analysis with fixed axis scaling\n",
    "if 'Delhi' in hips_aeth_matched:\n",
    "    delhi_data = hips_aeth_matched['Delhi']\n",
    "    \n",
    "    print(\"Delhi Data Summary:\")\n",
    "    print(f\"  Total samples: {len(delhi_data)}\")\n",
    "    print(f\"  IR BCc range: {delhi_data['ir_bcc'].min():.2f} - {delhi_data['ir_bcc'].max():.2f}\")\n",
    "    print(f\"  HIPS range: {delhi_data['hips_fabs'].min():.2f} - {delhi_data['hips_fabs'].max():.2f}\")\n",
    "    \n",
    "    # Check for green wavelength outliers\n",
    "    if 'green_bcc' in delhi_data.columns:\n",
    "        green_mean = delhi_data['green_bcc'].mean()\n",
    "        green_std = delhi_data['green_bcc'].std()\n",
    "        green_outliers = delhi_data['green_bcc'] > (green_mean + 3 * green_std)\n",
    "        print(f\"\\n  Green wavelength outliers (>3σ): {green_outliers.sum()}\")\n",
    "        if green_outliers.any():\n",
    "            print(f\"  Outlier values: {delhi_data.loc[green_outliers, 'green_bcc'].values}\")\n",
    "else:\n",
    "    print(\"Delhi data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delhi crossplot with FIXED axis scaling\n",
    "if 'Delhi' in hips_aeth_matched:\n",
    "    delhi_data = hips_aeth_matched['Delhi']\n",
    "    clean_delhi = get_clean_data(delhi_data)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Get data\n",
    "    x = clean_delhi['ir_bcc'].dropna()\n",
    "    y = clean_delhi.loc[x.index, 'hips_fabs'].dropna()\n",
    "    common_idx = x.index.intersection(y.index)\n",
    "    x, y = clean_delhi.loc[common_idx, 'ir_bcc'], clean_delhi.loc[common_idx, 'hips_fabs']\n",
    "    \n",
    "    # Calculate proper axis limit (not 60!)\n",
    "    max_val = max(x.max(), y.max()) * 1.05\n",
    "    print(f\"Proper max value: {max_val:.2f} (not 60)\")\n",
    "    \n",
    "    # Left plot: Before (showing the problem)\n",
    "    ax = axes[0]\n",
    "    ax.scatter(x, y, c='#ff7f0e', alpha=0.7, s=60)\n",
    "    ax.set_xlim(0, 60)  # OLD: bad scaling\n",
    "    ax.set_ylim(0, 60)\n",
    "    ax.plot([0, 60], [0, 60], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('Aethalometer IR BCc (µg/m³)')\n",
    "    ax.set_ylabel('HIPS Fabs / MAC (µg/m³)')\n",
    "    ax.set_title('Delhi - BEFORE (bad axis scaling to 60)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Right plot: After (fixed)\n",
    "    ax = axes[1]\n",
    "    ax.scatter(x, y, c='#ff7f0e', alpha=0.7, s=60)\n",
    "    \n",
    "    if len(x) > 2:\n",
    "        slope, intercept, r_value, _, _ = stats.linregress(x, y)\n",
    "        x_line = np.linspace(0, max_val, 100)\n",
    "        ax.plot(x_line, slope * x_line + intercept, 'b-', lw=2,\n",
    "               label=f'R²={r_value**2:.3f}, slope={slope:.2f}')\n",
    "    \n",
    "    ax.set_xlim(0, max_val)  # FIXED: proper scaling\n",
    "    ax.set_ylim(0, max_val)\n",
    "    ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='1:1')\n",
    "    ax.set_xlabel('Aethalometer IR BCc (µg/m³)')\n",
    "    ax.set_ylabel('HIPS Fabs / MAC (µg/m³)')\n",
    "    ax.set_title(f'Delhi - AFTER (proper scaling to {max_val:.1f})')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Delhi_Axis_Fix.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Get COMMON data (samples with ALL three measurements)\n# Using all_params_matched which has HIPS, FTIR EC, Iron, and Aethalometer data\nprint(\"=\" * 70)\nprint(\"MATCHED-SAMPLE ANALYSIS (Common Data Mode)\")\nprint(\"=\" * 70)\nprint(\"\\nUsing all_params_matched data (from match_all_parameters):\")\n\n# Show what we have\nfor site_name, df in all_params_matched.items():\n    has_cols = [col for col in ['ir_bcc', 'hips_fabs', 'ftir_ec', 'iron'] if col in df.columns]\n    print(f\"  {site_name}: {len(df)} samples, columns: {has_cols}\")\n\n# Filter to samples with ALL three key measurements\ndata_common = {}\nrequired_cols = ['ir_bcc', 'hips_fabs', 'ftir_ec']\n\nprint(\"\\nFiltering to samples with ALL three measurements (Aeth, HIPS, FTIR EC):\")\nfor site_name, df in all_params_matched.items():\n    available = [col for col in required_cols if col in df.columns]\n    if len(available) < len(required_cols):\n        missing = [col for col in required_cols if col not in df.columns]\n        print(f\"  {site_name}: Missing {missing}, skipping\")\n        continue\n    \n    # Filter to rows with all required columns having data\n    mask = df[required_cols].notna().all(axis=1)\n    df_common = df[mask].copy()\n    \n    if len(df_common) > 0:\n        data_common[site_name] = df_common\n        print(f\"  {site_name}: {len(df)} total -> {len(df_common)} common samples\")\n    else:\n        print(f\"  {site_name}: No common samples\")\n\nprint(f\"\\nSites with common data: {list(data_common.keys())}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create SEPARATE matched-sample crossplots for each site\nif len(data_common) == 0:\n    print(\"No sites have common data!\")\nelse:\n    for site_name, df in data_common.items():\n        color = SITE_COLORS.get(site_name, '#333333')\n        \n        # Get data\n        x = df['ir_bcc'].dropna()\n        y = df['hips_fabs'].dropna()\n        common_idx = x.index.intersection(y.index)\n        x, y = df.loc[common_idx, 'ir_bcc'], df.loc[common_idx, 'hips_fabs']\n        \n        if len(x) < 3:\n            print(f\"{site_name}: Insufficient data (n={len(x)})\")\n            continue\n        \n        # Create figure for this site\n        fig, ax = plt.subplots(figsize=(8, 7))\n        \n        ax.scatter(x, y, c=color, alpha=0.7, s=60)\n        \n        # Regression\n        slope, intercept, r_value, _, _ = stats.linregress(x, y)\n        max_val = max(x.max(), y.max()) * 1.05\n        x_line = np.linspace(0, max_val, 100)\n        ax.plot(x_line, slope * x_line + intercept, 'b-', lw=2,\n               label=f'R²={r_value**2:.3f}, slope={slope:.2f}')\n        ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='1:1')\n        \n        ax.set_xlim(0, max_val)\n        ax.set_ylim(0, max_val)\n        ax.set_xlabel('Aethalometer IR BCc (µg/m³)', fontsize=12)\n        ax.set_ylabel('HIPS Fabs / MAC (µg/m³)', fontsize=12)\n        ax.set_title(f'{site_name} - HIPS vs Aethalometer\\n(COMMON DATA: n={len(x)}, all 3 measurements)', fontsize=14)\n        ax.legend(loc='upper left')\n        ax.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.savefig(f'Common_HIPS_vs_Aeth_{site_name}.png', dpi=150, bbox_inches='tight')\n        plt.show()\n        \n        print(f\"{site_name}: n={len(x)}, R²={r_value**2:.3f}, slope={slope:.2f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n# TASK 4: Cross-Plots (All Sites, All Types) - SEPARATE GRAPHS\n\nCreate individual plots for each site showing:\n1. HIPS vs Aethalometer\n2. FTIR EC vs Aethalometer  \n3. HIPS vs FTIR EC"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Create SEPARATE cross-plots for each site and plot type\nall_stats = []\n\nplot_configs = [\n    {'x': 'ir_bcc', 'y': 'hips_fabs', 'xlabel': 'Aethalometer IR BCc (µg/m³)', \n     'ylabel': 'HIPS Fabs / MAC (µg/m³)', 'title': 'HIPS vs Aethalometer'},\n    {'x': 'ir_bcc', 'y': 'ftir_ec', 'xlabel': 'Aethalometer IR BCc (µg/m³)', \n     'ylabel': 'FTIR EC (µg/m³)', 'title': 'FTIR EC vs Aethalometer'},\n    {'x': 'ftir_ec', 'y': 'hips_fabs', 'xlabel': 'FTIR EC (µg/m³)', \n     'ylabel': 'HIPS Fabs / MAC (µg/m³)', 'title': 'HIPS vs FTIR EC'},\n]\n\nif len(data_common) == 0:\n    print(\"No common data available!\")\nelse:\n    for site_name, df in data_common.items():\n        color = SITE_COLORS.get(site_name, '#333333')\n        print(f\"\\n{'='*60}\")\n        print(f\"{site_name}\")\n        print('='*60)\n        \n        for config in plot_configs:\n            # Check columns exist\n            if config['x'] not in df.columns or config['y'] not in df.columns:\n                print(f\"  {config['title']}: Missing columns, skipping\")\n                continue\n            \n            # Get valid data\n            valid = df[[config['x'], config['y']]].notna().all(axis=1)\n            x = df.loc[valid, config['x']]\n            y = df.loc[valid, config['y']]\n            \n            if len(x) < 3:\n                print(f\"  {config['title']}: Insufficient data (n={len(x)})\")\n                continue\n            \n            # Create figure\n            fig, ax = plt.subplots(figsize=(8, 7))\n            \n            ax.scatter(x, y, c=color, alpha=0.7, s=60)\n            \n            # Regression\n            slope, intercept, r_value, _, _ = stats.linregress(x, y)\n            max_val = max(x.max(), y.max()) * 1.05\n            x_line = np.linspace(0, max_val, 100)\n            ax.plot(x_line, slope * x_line + intercept, 'b-', lw=2,\n                   label=f'R²={r_value**2:.3f}, slope={slope:.2f}')\n            ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='1:1')\n            \n            ax.set_xlim(0, max_val)\n            ax.set_ylim(0, max_val)\n            ax.set_xlabel(config['xlabel'], fontsize=12)\n            ax.set_ylabel(config['ylabel'], fontsize=12)\n            ax.set_title(f\"{site_name} - {config['title']}\\n(n={len(x)}, R²={r_value**2:.3f})\", fontsize=14)\n            ax.legend(loc='upper left')\n            ax.grid(True, alpha=0.3)\n            \n            # Save with descriptive filename\n            safe_title = config['title'].replace(' ', '_').replace('/', '_')\n            plt.tight_layout()\n            plt.savefig(f\"{safe_title}_{site_name}.png\", dpi=150, bbox_inches='tight')\n            plt.show()\n            \n            # Store stats\n            all_stats.append({\n                'Site': site_name,\n                'Plot': config['title'],\n                'N': len(x),\n                'R²': r_value**2,\n                'Slope': slope,\n                'Intercept': intercept\n            })\n            \n            print(f\"  {config['title']}: n={len(x)}, R²={r_value**2:.3f}, slope={slope:.2f}\")\n\n# Create stats DataFrame\nstats_df = pd.DataFrame(all_stats)\nprint(f\"\\nTotal plots created: {len(all_stats)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-plot collage: 3 plot types x 4 sites\n",
    "def create_crossplot_collage(data_dict, save_name='Crossplot_Collage.png'):\n",
    "    \"\"\"\n",
    "    Create a collage with 3 rows (plot types) x N columns (sites).\n",
    "    \n",
    "    Row 1: HIPS vs Aethalometer\n",
    "    Row 2: FTIR EC vs Aethalometer\n",
    "    Row 3: HIPS vs FTIR EC\n",
    "    \"\"\"\n",
    "    sites = list(data_dict.keys())\n",
    "    n_sites = len(sites)\n",
    "    \n",
    "    plot_configs = [\n",
    "        {'x': 'ir_bcc', 'y': 'hips_fabs', 'xlabel': 'Aeth IR BCc', 'ylabel': 'HIPS/MAC', 'title': 'HIPS vs Aeth'},\n",
    "        {'x': 'ir_bcc', 'y': 'ftir_ec', 'xlabel': 'Aeth IR BCc', 'ylabel': 'FTIR EC', 'title': 'FTIR vs Aeth'},\n",
    "        {'x': 'ftir_ec', 'y': 'hips_fabs', 'xlabel': 'FTIR EC', 'ylabel': 'HIPS/MAC', 'title': 'HIPS vs FTIR'},\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, n_sites, figsize=(4*n_sites, 12))\n",
    "    if n_sites == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    all_stats = []\n",
    "    \n",
    "    for row, config in enumerate(plot_configs):\n",
    "        for col, site_name in enumerate(sites):\n",
    "            ax = axes[row, col]\n",
    "            df = data_dict[site_name]\n",
    "            color = SITE_COLORS.get(site_name, '#333333')\n",
    "            \n",
    "            # Get clean data\n",
    "            if 'is_any_outlier' in df.columns:\n",
    "                df_clean = df[~df['is_any_outlier']]\n",
    "            else:\n",
    "                df_clean = df\n",
    "            \n",
    "            # Check columns exist\n",
    "            if config['x'] not in df_clean.columns or config['y'] not in df_clean.columns:\n",
    "                ax.text(0.5, 0.5, 'Missing data', ha='center', va='center', transform=ax.transAxes)\n",
    "                continue\n",
    "            \n",
    "            # Get valid data\n",
    "            valid = df_clean[[config['x'], config['y']]].notna().all(axis=1)\n",
    "            x = df_clean.loc[valid, config['x']]\n",
    "            y = df_clean.loc[valid, config['y']]\n",
    "            \n",
    "            if len(x) < 3:\n",
    "                ax.text(0.5, 0.5, f'n={len(x)}', ha='center', va='center', transform=ax.transAxes)\n",
    "                continue\n",
    "            \n",
    "            # Plot\n",
    "            ax.scatter(x, y, c=color, alpha=0.7, s=40)\n",
    "            \n",
    "            # Regression\n",
    "            slope, intercept, r_value, _, _ = stats.linregress(x, y)\n",
    "            max_val = max(x.max(), y.max()) * 1.05\n",
    "            x_line = np.linspace(0, max_val, 100)\n",
    "            ax.plot(x_line, slope * x_line + intercept, 'b-', lw=1.5)\n",
    "            ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.4, lw=1)\n",
    "            \n",
    "            ax.set_xlim(0, max_val)\n",
    "            ax.set_ylim(0, max_val)\n",
    "            ax.set_xlabel(config['xlabel'], fontsize=9)\n",
    "            ax.set_ylabel(config['ylabel'], fontsize=9)\n",
    "            \n",
    "            # Title with stats\n",
    "            if row == 0:\n",
    "                ax.set_title(f'{site_name}\\nR²={r_value**2:.2f}, m={slope:.2f}', fontsize=10)\n",
    "            else:\n",
    "                ax.set_title(f'R²={r_value**2:.2f}, m={slope:.2f}', fontsize=9)\n",
    "            \n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Store stats\n",
    "            all_stats.append({\n",
    "                'Site': site_name,\n",
    "                'Plot': config['title'],\n",
    "                'N': len(x),\n",
    "                'R²': r_value**2,\n",
    "                'Slope': slope,\n",
    "                'Intercept': intercept\n",
    "            })\n",
    "    \n",
    "    # Row labels on the left\n",
    "    for row, config in enumerate(plot_configs):\n",
    "        axes[row, 0].set_ylabel(f\"{config['title']}\\n{config['ylabel']}\", fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_name, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.DataFrame(all_stats)\n",
    "\n",
    "# Create collage\n",
    "stats_df = create_crossplot_collage(data_common, save_name='Crossplot_Collage_Common.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Display summary table\nprint(\"=\" * 80)\nprint(\"SUMMARY TABLE: Slopes and R² Values (Common Data Only)\")\nprint(\"=\" * 80)\n\nif len(stats_df) > 0:\n    print(stats_df.to_string(index=False))\n    \n    # Save to CSV\n    stats_df.to_csv('Crossplot_Summary_Stats.csv', index=False)\n    print(\"\\nSaved to: Crossplot_Summary_Stats.csv\")\nelse:\n    print(\"No statistics to display (no common data found)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pivot table format for cleaner view\nif len(stats_df) > 0:\n    pivot = stats_df.pivot_table(\n        index='Site', \n        columns='Plot', \n        values=['R²', 'Slope', 'N'],\n        aggfunc='first'\n    )\n    print(\"\\nPivot Table View:\")\n    print(pivot.round(3))\nelse:\n    print(\"No data for pivot table\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table format for cleaner view\n",
    "pivot = stats_df.pivot_table(\n",
    "    index='Site', \n",
    "    columns='Plot', \n",
    "    values=['R²', 'Slope', 'N'],\n",
    "    aggfunc='first'\n",
    ")\n",
    "print(\"\\nPivot Table View:\")\n",
    "print(pivot.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TASK 6: Raw Attenuation Correlation Matrix\n",
    "\n",
    "Analyze correlations in raw attenuation data (before instrument processing) to see if high wavelength correlations are inherent or processing-induced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create SEPARATE correlation matrices for each site\nwavelength_cols = ['uv_bcc', 'blue_bcc', 'green_bcc', 'red_bcc', 'ir_bcc']\n\nfor site_name, df in aethalometer_data.items():\n    # Check which wavelength columns exist\n    available_cols = [col for col in wavelength_cols if col in df.columns]\n    \n    if len(available_cols) < 2:\n        print(f\"\\n{site_name}: Insufficient wavelength data ({len(available_cols)} columns)\")\n        continue\n    \n    # Calculate correlation matrix\n    corr_matrix = df[available_cols].corr()\n    \n    # Create figure for this site\n    fig, ax = plt.subplots(figsize=(8, 7))\n    \n    # Plot heatmap\n    im = ax.imshow(corr_matrix, cmap='RdYlBu_r', vmin=0.5, vmax=1.0)\n    \n    # Labels\n    labels = [col.replace('_bcc', '').upper() for col in available_cols]\n    ax.set_xticks(range(len(labels)))\n    ax.set_yticks(range(len(labels)))\n    ax.set_xticklabels(labels, rotation=45, ha='right', fontsize=11)\n    ax.set_yticklabels(labels, fontsize=11)\n    \n    # Add correlation values\n    for i in range(len(labels)):\n        for j in range(len(labels)):\n            val = corr_matrix.iloc[i, j]\n            color = 'white' if val < 0.7 else 'black'\n            ax.text(j, i, f'{val:.2f}', ha='center', va='center', color=color, fontsize=12)\n    \n    ax.set_title(f'{site_name}\\nBC Wavelength Correlation Matrix', fontsize=14)\n    plt.colorbar(im, ax=ax, label='Correlation')\n    \n    plt.tight_layout()\n    plt.savefig(f'Wavelength_Correlation_{site_name}.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(f\"\\n{site_name}: Correlation matrix created ({len(available_cols)} wavelengths)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrices for BC wavelengths\n",
    "# Common BC columns: UV, Blue, Green, Red, IR (or similar)\n",
    "\n",
    "wavelength_cols = ['uv_bcc', 'blue_bcc', 'green_bcc', 'red_bcc', 'ir_bcc']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (site_name, df) in enumerate(aethalometer_data.items()):\n",
    "    if idx >= 4:\n",
    "        break\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Check which wavelength columns exist\n",
    "    available_cols = [col for col in wavelength_cols if col in df.columns]\n",
    "    \n",
    "    if len(available_cols) < 2:\n",
    "        ax.text(0.5, 0.5, f'{site_name}\\nInsufficient wavelength data', \n",
    "               ha='center', va='center', transform=ax.transAxes)\n",
    "        continue\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[available_cols].corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    im = ax.imshow(corr_matrix, cmap='RdYlBu_r', vmin=0.5, vmax=1.0)\n",
    "    \n",
    "    # Labels\n",
    "    labels = [col.replace('_bcc', '').upper() for col in available_cols]\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(labels)\n",
    "    \n",
    "    # Add correlation values\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            val = corr_matrix.iloc[i, j]\n",
    "            color = 'white' if val < 0.7 else 'black'\n",
    "            ax.text(j, i, f'{val:.2f}', ha='center', va='center', color=color, fontsize=10)\n",
    "    \n",
    "    ax.set_title(f'{site_name}\\nWavelength Correlation Matrix')\n",
    "    plt.colorbar(im, ax=ax, label='Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Wavelength_Correlation_Matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# OPTIONAL: Hourly-binned Wavelength Ratio Analysis\n",
    "\n",
    "For Angstrom absorption exponent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n# Summary of Outputs\n\nFiles generated (separate plots for each site):\n- `Iron_EC_{site}.png` - Iron/EC scatter plots\n- `Delhi_Axis_Fix.png` - Before/after axis scaling comparison  \n- `Common_HIPS_vs_Aeth_{site}.png` - HIPS vs Aeth (common data only)\n- `HIPS_vs_Aethalometer_{site}.png` - All cross-plots\n- `FTIR_EC_vs_Aethalometer_{site}.png`\n- `HIPS_vs_FTIR_EC_{site}.png`\n- `Crossplot_Summary_Stats.csv` - Slopes and R² values\n- `Wavelength_Correlation_{site}.png` - BC wavelength correlations"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary of Outputs\n",
    "\n",
    "Files generated:\n",
    "1. `Iron_EC_Ratio_Analysis.png` - Iron/EC scatter plots\n",
    "2. `Delhi_Axis_Fix.png` - Before/after axis scaling comparison\n",
    "3. `Matched_Sample_Crossplots.png` - Common data only plots\n",
    "4. `Crossplot_Collage_Common.png` - All 3 plot types for all sites\n",
    "5. `Crossplot_Summary_Stats.csv` - Slopes and R² values\n",
    "6. `Wavelength_Correlation_Matrix.png` - BC wavelength correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 70)\n",
    "print(\"TASK COMPLETION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\")\n",
    "print(\"[✓] Iron/EC ratio analysis - COMPLETED\")\n",
    "print(\"[✓] Delhi axis scaling fix - COMPLETED\")\n",
    "print(\"[✓] Matched-sample plots (common data) - COMPLETED\")\n",
    "print(\"[✓] Cross-plot collage - COMPLETED\")\n",
    "print(\"[✓] Summary table with slopes/R² - COMPLETED\")\n",
    "print(\"[✓] Wavelength correlation matrix - COMPLETED\")\n",
    "print(\"[ ] Hourly-binned wavelength ratio - OPTIONAL (not implemented)\")\n",
    "print(\"\")\n",
    "print(\"Administrative:\")\n",
    "print(\"[ ] Send when-is-good poll for first two weeks of January\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}