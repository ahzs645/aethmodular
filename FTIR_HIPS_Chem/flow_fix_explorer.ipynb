{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Fix Period Explorer\n",
    "\n",
    "This notebook helps identify before/after flow fix time periods for each site by visualizing:\n",
    "- HIPS measurements over time\n",
    "- FTIR EC measurements over time  \n",
    "- Aethalometer BC measurements over time\n",
    "\n",
    "Use these plots to identify dates where data quality or instrument behavior changed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from scipy import stats\n",
    "\n",
    "# Add scripts folder to path\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "scripts_path = os.path.join(notebook_dir, 'scripts')\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.insert(0, scripts_path)\n",
    "\n",
    "# Core imports from modular scripts\n",
    "from config import SITES, MAC_VALUE, FLOW_FIX_PERIODS\n",
    "from data_matching import (\n",
    "    load_aethalometer_data, \n",
    "    load_filter_data,\n",
    "    add_base_filter_id,\n",
    "    match_all_parameters\n",
    ")\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Site colors\n",
    "SITE_COLORS = {\n",
    "    'Beijing': '#1f77b4', \n",
    "    'Delhi': '#ff7f0e', \n",
    "    'JPL': '#2ca02c', \n",
    "    'Addis_Ababa': '#d62728'\n",
    "}\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"Sites: {list(SITES.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aethalometer data\n",
    "aethalometer_data = load_aethalometer_data()\n",
    "print(f\"Loaded aethalometer data for: {list(aethalometer_data.keys())}\")\n",
    "\n",
    "# Load filter data\n",
    "filter_data = load_filter_data()\n",
    "filter_data = add_base_filter_id(filter_data)\n",
    "print(f\"Filter data: {len(filter_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match all parameters for each site\n",
    "all_params_data = {}\n",
    "\n",
    "for site_name in SITES:\n",
    "    if site_name not in aethalometer_data:\n",
    "        continue\n",
    "    \n",
    "    config = SITES[site_name]\n",
    "    df_aeth = aethalometer_data[site_name]\n",
    "    \n",
    "    matched = match_all_parameters(\n",
    "        site_name, config['code'], df_aeth, filter_data\n",
    "    )\n",
    "    \n",
    "    if matched is not None and len(matched) >= 3:\n",
    "        matched['date'] = pd.to_datetime(matched['date'])\n",
    "        matched = matched.sort_values('date')\n",
    "        all_params_data[site_name] = matched\n",
    "        \n",
    "        print(f\"{site_name}: {len(matched)} samples\")\n",
    "        print(f\"  Date range: {matched['date'].min().strftime('%Y-%m-%d')} to {matched['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    else:\n",
    "        print(f\"{site_name}: Insufficient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Flow Fix Period Configuration\n",
    "\n",
    "Show what's currently defined in `config.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CURRENT FLOW_FIX_PERIODS CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for site_name in SITES:\n",
    "    config = FLOW_FIX_PERIODS.get(site_name, {})\n",
    "    if config:\n",
    "        print(f\"\\n{site_name}:\")\n",
    "        print(f\"  Description: {config.get('description', 'N/A')}\")\n",
    "        print(f\"  Before end: {config.get('before_end', 'NOT SET')}\")\n",
    "        print(f\"  After start: {config.get('after_start', 'NOT SET')}\")\n",
    "        print(f\"  Notes: {config.get('notes', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"\\n{site_name}: No flow fix periods defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stacked Time Series Plots - All Sites\n",
    "\n",
    "Each site gets a figure with 3 stacked subplots:\n",
    "1. **HIPS Fabs** (converted to BC equivalent)\n",
    "2. **FTIR EC**\n",
    "3. **Aethalometer IR BC**\n",
    "\n",
    "Look for:\n",
    "- Sudden changes in data patterns\n",
    "- Gaps in data collection\n",
    "- Changes in variability or baseline\n",
    "- Dates where correlations might have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_stacked_timeseries(site_name, df, flow_config=None):\n    \"\"\"\n    Create stacked time series plot for a site showing HIPS, FTIR EC, and Aethalometer.\n    \n    Parameters:\n    -----------\n    site_name : str\n    df : DataFrame with date, hips_fabs, ftir_ec, ir_bcc columns\n    flow_config : dict with before_end and after_start dates (optional)\n    \"\"\"\n    color = SITE_COLORS.get(site_name, '#333333')\n    \n    fig, axes = plt.subplots(3, 1, figsize=(16, 12), sharex=True)\n    \n    # Data columns and labels\n    plot_configs = [\n        ('hips_fabs', 'HIPS Fabs / MAC (µg/m³)', '#9467bd'),  # Purple\n        ('ftir_ec', 'FTIR EC (µg/m³)', '#d62728'),            # Red\n        ('ir_bcc', 'Aethalometer IR BCc (µg/m³)', '#1f77b4')  # Blue\n    ]\n    \n    dates = df['date']\n    \n    for ax, (col, ylabel, plot_color) in zip(axes, plot_configs):\n        if col in df.columns:\n            valid_mask = df[col].notna()\n            valid_dates = dates[valid_mask]\n            valid_data = df.loc[valid_mask, col]\n            \n            # Scatter plot\n            ax.scatter(valid_dates, valid_data, c=plot_color, alpha=0.7, s=50, \n                      edgecolors='black', linewidth=0.3, label=f'n={len(valid_data)}')\n            \n            # Add rolling mean (30-day window)\n            if len(valid_data) > 10:\n                df_temp = pd.DataFrame({'date': valid_dates, 'value': valid_data}).set_index('date').sort_index()\n                rolling_mean = df_temp['value'].rolling(window='30D', min_periods=3).mean()\n                ax.plot(rolling_mean.index, rolling_mean.values, color='black', \n                       linewidth=2, alpha=0.7, label='30-day rolling mean')\n            \n            ax.set_ylabel(ylabel, fontsize=11)\n            ax.legend(loc='upper right', fontsize=9)\n            \n            # Add statistics text\n            stats_text = f\"Mean: {valid_data.mean():.2f}, Median: {valid_data.median():.2f}\"\n            ax.text(0.02, 0.95, stats_text, transform=ax.transAxes, fontsize=9,\n                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n        else:\n            ax.text(0.5, 0.5, f'{col} not available', transform=ax.transAxes,\n                   ha='center', va='center', fontsize=12, color='gray')\n            ax.set_ylabel(ylabel, fontsize=11)\n        \n        ax.grid(True, alpha=0.3)\n        ax.set_ylim(bottom=0)\n\n    # Format x-axis\n    axes[-1].set_xlabel('Date', fontsize=11)\n    axes[-1].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n    axes[-1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n    plt.setp(axes[-1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n    \n    # Title\n    date_range = f\"{dates.min().strftime('%Y-%m-%d')} to {dates.max().strftime('%Y-%m-%d')}\"\n    fig.suptitle(f'{site_name}: Time Series Overview\\n{date_range}', \n                fontsize=14, fontweight='bold', y=1.02)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return fig"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all sites\n",
    "for site_name in SITES:\n",
    "    if site_name in all_params_data:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"{site_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        flow_config = FLOW_FIX_PERIODS.get(site_name, {})\n",
    "        plot_stacked_timeseries(site_name, all_params_data[site_name], flow_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Rolling Correlation Analysis\n",
    "\n",
    "Calculate rolling correlation between measurements to identify when relationships changed.\n",
    "A sudden change in correlation might indicate instrument issues or fixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_rolling_correlation(site_name, df, window_days=60):\n    \"\"\"\n    Plot rolling correlation between measurement types over time.\n    \"\"\"\n    fig, axes = plt.subplots(3, 1, figsize=(16, 10), sharex=True)\n    \n    df = df.copy().set_index('date').sort_index()\n    \n    correlations = [\n        ('ir_bcc', 'ftir_ec', 'Aeth BC vs FTIR EC', '#1f77b4'),\n        ('hips_fabs', 'ftir_ec', 'HIPS vs FTIR EC', '#9467bd'),\n        ('hips_fabs', 'ir_bcc', 'HIPS vs Aeth BC', '#2ca02c')\n    ]\n    \n    for ax, (col1, col2, label, color) in zip(axes, correlations):\n        if col1 in df.columns and col2 in df.columns:\n            # Calculate rolling correlation\n            valid_mask = df[col1].notna() & df[col2].notna()\n            \n            if valid_mask.sum() > window_days // 2:\n                rolling_corr = df[col1].rolling(window=f'{window_days}D', min_periods=5).corr(df[col2])\n                \n                ax.plot(rolling_corr.index, rolling_corr.values, color=color, linewidth=2, alpha=0.8)\n                ax.fill_between(rolling_corr.index, rolling_corr.values, alpha=0.3, color=color)\n                \n                # Add reference lines\n                ax.axhline(y=1.0, color='green', linestyle='--', alpha=0.5, label='Perfect correlation')\n                ax.axhline(y=0.8, color='orange', linestyle=':', alpha=0.5, label='R=0.8')\n                ax.axhline(y=0.5, color='red', linestyle=':', alpha=0.5, label='R=0.5')\n                \n                # Overall correlation\n                overall_corr = df.loc[valid_mask, col1].corr(df.loc[valid_mask, col2])\n                ax.text(0.02, 0.95, f'Overall R: {overall_corr:.3f}', transform=ax.transAxes,\n                       fontsize=10, va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n            else:\n                ax.text(0.5, 0.5, 'Insufficient data for rolling correlation',\n                       transform=ax.transAxes, ha='center', va='center')\n        else:\n            ax.text(0.5, 0.5, f'Missing columns: {col1} or {col2}',\n                   transform=ax.transAxes, ha='center', va='center')\n        \n        ax.set_ylabel(f'{label}\\nCorrelation (R)', fontsize=10)\n        ax.set_ylim(-0.2, 1.1)\n        ax.grid(True, alpha=0.3)\n        ax.legend(loc='lower right', fontsize=8)\n\n    axes[-1].set_xlabel('Date', fontsize=11)\n    axes[-1].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n    axes[-1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n    plt.setp(axes[-1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n    \n    fig.suptitle(f'{site_name}: Rolling {window_days}-Day Correlation', \n                fontsize=14, fontweight='bold', y=1.02)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return fig"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rolling correlations for all sites\n",
    "for site_name in SITES:\n",
    "    if site_name in all_params_data:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"{site_name}: Rolling Correlation\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        plot_rolling_correlation(site_name, all_params_data[site_name], window_days=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ratio Time Series (Aeth/FTIR and HIPS/FTIR)\n",
    "\n",
    "Plot the ratio of measurements over time. Changes in the ratio might indicate calibration issues or flow problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_ratio_timeseries(site_name, df):\n    \"\"\"\n    Plot measurement ratios over time to identify systematic changes.\n    \"\"\"\n    fig, axes = plt.subplots(2, 1, figsize=(16, 8), sharex=True)\n    \n    df = df.copy()\n    dates = df['date']\n    \n    ratios = [\n        ('ir_bcc', 'ftir_ec', 'Aeth BC / FTIR EC', '#1f77b4'),\n        ('hips_fabs', 'ftir_ec', 'HIPS / FTIR EC', '#9467bd')\n    ]\n    \n    for ax, (num_col, denom_col, label, color) in zip(axes, ratios):\n        if num_col in df.columns and denom_col in df.columns:\n            # Calculate ratio (avoid division by zero)\n            valid_mask = (df[num_col].notna() & df[denom_col].notna() & \n                         (df[denom_col] > 0.01))  # Minimum threshold\n            \n            ratio = df.loc[valid_mask, num_col] / df.loc[valid_mask, denom_col]\n            valid_dates = dates[valid_mask]\n            \n            # Remove extreme outliers for visualization\n            q1, q3 = ratio.quantile(0.05), ratio.quantile(0.95)\n            display_mask = (ratio >= q1 * 0.5) & (ratio <= q3 * 2)\n            \n            ax.scatter(valid_dates[display_mask], ratio[display_mask], \n                      c=color, alpha=0.6, s=50, edgecolors='black', linewidth=0.3)\n            \n            # Rolling mean\n            df_temp = pd.DataFrame({'date': valid_dates, 'ratio': ratio}).set_index('date').sort_index()\n            rolling_mean = df_temp['ratio'].rolling(window='30D', min_periods=3).mean()\n            ax.plot(rolling_mean.index, rolling_mean.values, color='black', \n                   linewidth=2, alpha=0.8, label='30-day rolling mean')\n            \n            # Reference line at 1.0\n            ax.axhline(y=1.0, color='green', linestyle='--', linewidth=2, alpha=0.7, label='Ratio = 1.0')\n            \n            # Stats\n            mean_ratio = ratio.mean()\n            median_ratio = ratio.median()\n            ax.text(0.02, 0.95, f'Mean: {mean_ratio:.2f}, Median: {median_ratio:.2f}, n={len(ratio)}',\n                   transform=ax.transAxes, fontsize=10, va='top',\n                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n        else:\n            ax.text(0.5, 0.5, f'Missing columns', transform=ax.transAxes, ha='center', va='center')\n        \n        ax.set_ylabel(label, fontsize=11)\n        ax.grid(True, alpha=0.3)\n        ax.legend(loc='upper right', fontsize=9)\n        ax.set_ylim(0, 3)  # Reasonable range for ratios\n\n    axes[-1].set_xlabel('Date', fontsize=11)\n    axes[-1].xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n    axes[-1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n    plt.setp(axes[-1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n    \n    fig.suptitle(f'{site_name}: Measurement Ratios Over Time', \n                fontsize=14, fontweight='bold', y=1.02)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return fig"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ratio time series for all sites\n",
    "for site_name in SITES:\n",
    "    if site_name in all_params_data:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"{site_name}: Measurement Ratios\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        plot_ratio_timeseries(site_name, all_params_data[site_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interactive Date Range Explorer\n",
    "\n",
    "Use this cell to test different before/after dates and see the impact on correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_flow_fix_dates(site_name, df, before_end, after_start):\n",
    "    \"\"\"\n",
    "    Test specific before/after dates and calculate statistics for each period.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    site_name : str\n",
    "    df : DataFrame\n",
    "    before_end : str, date string (e.g., '2023-06-15')\n",
    "    after_start : str, date string (e.g., '2023-07-01')\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    before_dt = pd.to_datetime(before_end)\n",
    "    after_dt = pd.to_datetime(after_start)\n",
    "    \n",
    "    before_data = df[df['date'] <= before_dt]\n",
    "    after_data = df[df['date'] >= after_dt]\n",
    "    gap_data = df[(df['date'] > before_dt) & (df['date'] < after_dt)]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{site_name}: Testing Flow Fix Dates\")\n",
    "    print(f\"  Before end: {before_end}\")\n",
    "    print(f\"  After start: {after_start}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"\\nSample counts:\")\n",
    "    print(f\"  Before: {len(before_data)}\")\n",
    "    print(f\"  Gap: {len(gap_data)}\")\n",
    "    print(f\"  After: {len(after_data)}\")\n",
    "    \n",
    "    # Calculate correlations for each period\n",
    "    comparisons = [\n",
    "        ('ir_bcc', 'ftir_ec', 'Aeth BC vs FTIR EC'),\n",
    "        ('hips_fabs', 'ftir_ec', 'HIPS vs FTIR EC'),\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'Comparison':<25s} {'Before R²':<12s} {'After R²':<12s} {'ΔR²':<12s}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for col1, col2, label in comparisons:\n",
    "        if col1 in df.columns and col2 in df.columns:\n",
    "            # Before period\n",
    "            valid_before = before_data[col1].notna() & before_data[col2].notna()\n",
    "            if valid_before.sum() >= 3:\n",
    "                r_before = before_data.loc[valid_before, col1].corr(before_data.loc[valid_before, col2])\n",
    "                r2_before = r_before ** 2\n",
    "            else:\n",
    "                r2_before = np.nan\n",
    "            \n",
    "            # After period\n",
    "            valid_after = after_data[col1].notna() & after_data[col2].notna()\n",
    "            if valid_after.sum() >= 3:\n",
    "                r_after = after_data.loc[valid_after, col1].corr(after_data.loc[valid_after, col2])\n",
    "                r2_after = r_after ** 2\n",
    "            else:\n",
    "                r2_after = np.nan\n",
    "            \n",
    "            delta = r2_after - r2_before if not (np.isnan(r2_before) or np.isnan(r2_after)) else np.nan\n",
    "            \n",
    "            print(f\"{label:<25s} {r2_before:<12.3f} {r2_after:<12.3f} {delta:<+12.3f}\")\n",
    "            \n",
    "            results[label] = {\n",
    "                'before_r2': r2_before,\n",
    "                'after_r2': r2_after,\n",
    "                'delta': delta,\n",
    "                'n_before': valid_before.sum(),\n",
    "                'n_after': valid_after.sum()\n",
    "            }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TEST YOUR DATES HERE\n",
    "# ============================================================\n",
    "# Modify these dates based on what you see in the plots above\n",
    "# Then run this cell to see the impact on correlations\n",
    "\n",
    "# Example: Test dates for Beijing\n",
    "if 'Beijing' in all_params_data:\n",
    "    test_flow_fix_dates(\n",
    "        'Beijing',\n",
    "        all_params_data['Beijing'],\n",
    "        before_end='2023-06-01',  # <-- MODIFY THIS\n",
    "        after_start='2023-07-01'   # <-- MODIFY THIS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test dates for JPL\n",
    "if 'JPL' in all_params_data:\n",
    "    test_flow_fix_dates(\n",
    "        'JPL',\n",
    "        all_params_data['JPL'],\n",
    "        before_end='2023-06-01',  # <-- MODIFY THIS\n",
    "        after_start='2023-07-01'   # <-- MODIFY THIS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test dates for Delhi\n",
    "if 'Delhi' in all_params_data:\n",
    "    test_flow_fix_dates(\n",
    "        'Delhi',\n",
    "        all_params_data['Delhi'],\n",
    "        before_end='2023-06-01',  # <-- MODIFY THIS\n",
    "        after_start='2023-07-01'   # <-- MODIFY THIS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test dates for Addis_Ababa\n",
    "if 'Addis_Ababa' in all_params_data:\n",
    "    test_flow_fix_dates(\n",
    "        'Addis_Ababa',\n",
    "        all_params_data['Addis_Ababa'],\n",
    "        before_end='2023-06-01',  # <-- MODIFY THIS\n",
    "        after_start='2023-07-01'   # <-- MODIFY THIS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Data Availability by Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA AVAILABILITY SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Site':<15s} {'Date Range':<30s} {'n Total':<10s} {'HIPS':<8s} {'FTIR':<8s} {'Aeth':<8s}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for site_name in SITES:\n",
    "    if site_name in all_params_data:\n",
    "        df = all_params_data[site_name]\n",
    "        date_range = f\"{df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\"\n",
    "        n_hips = df['hips_fabs'].notna().sum() if 'hips_fabs' in df.columns else 0\n",
    "        n_ftir = df['ftir_ec'].notna().sum() if 'ftir_ec' in df.columns else 0\n",
    "        n_aeth = df['ir_bcc'].notna().sum() if 'ir_bcc' in df.columns else 0\n",
    "        \n",
    "        print(f\"{site_name:<15s} {date_range:<30s} {len(df):<10d} {n_hips:<8d} {n_ftir:<8d} {n_aeth:<8d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Recommended Flow Fix Dates\n",
    "\n",
    "Based on your analysis, update the `FLOW_FIX_PERIODS` dictionary in `scripts/config.py`:\n",
    "\n",
    "```python\n",
    "FLOW_FIX_PERIODS = {\n",
    "    'Beijing': {\n",
    "        'description': 'Flow rate correction',\n",
    "        'before_end': 'YYYY-MM-DD',    # <-- Fill in\n",
    "        'after_start': 'YYYY-MM-DD',   # <-- Fill in\n",
    "        'notes': 'Your notes here'\n",
    "    },\n",
    "    'JPL': {\n",
    "        'description': 'Flow rate correction',\n",
    "        'before_end': 'YYYY-MM-DD',    # <-- Fill in\n",
    "        'after_start': 'YYYY-MM-DD',   # <-- Fill in\n",
    "        'notes': 'Your notes here'\n",
    "    },\n",
    "    'Delhi': {\n",
    "        'description': 'Flow rate correction',\n",
    "        'before_end': 'YYYY-MM-DD',    # <-- Fill in (if applicable)\n",
    "        'after_start': 'YYYY-MM-DD',   # <-- Fill in (if applicable)\n",
    "        'notes': 'Your notes here'\n",
    "    },\n",
    "    'Addis_Ababa': {\n",
    "        'description': 'Flow rate correction',\n",
    "        'before_end': 'YYYY-MM-DD',    # <-- Fill in (if applicable)\n",
    "        'after_start': 'YYYY-MM-DD',   # <-- Fill in (if applicable)\n",
    "        'notes': 'Your notes here'\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary cell - fill in your recommended dates\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDED FLOW FIX DATES (fill in based on your analysis)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "recommended_dates = {\n",
    "    'Beijing': {\n",
    "        'before_end': 'YYYY-MM-DD',  # <-- FILL IN\n",
    "        'after_start': 'YYYY-MM-DD'  # <-- FILL IN\n",
    "    },\n",
    "    'JPL': {\n",
    "        'before_end': 'YYYY-MM-DD',  # <-- FILL IN\n",
    "        'after_start': 'YYYY-MM-DD'  # <-- FILL IN\n",
    "    },\n",
    "    'Delhi': {\n",
    "        'before_end': None,  # Set to None if no flow fix period\n",
    "        'after_start': None\n",
    "    },\n",
    "    'Addis_Ababa': {\n",
    "        'before_end': None,  # Set to None if no flow fix period\n",
    "        'after_start': None\n",
    "    }\n",
    "}\n",
    "\n",
    "for site_name, dates in recommended_dates.items():\n",
    "    print(f\"\\n{site_name}:\")\n",
    "    print(f\"  before_end: {dates['before_end']}\")\n",
    "    print(f\"  after_start: {dates['after_start']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}