{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ac5942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Multi-Site Filter Analysis\n",
      "============================================================\n",
      "Loading complete filter dataset from /Users/ahzs645/Github/aethmodular-clean/FTIR_HIPS_Chem/Filter Data/unified_filter_dataset.pkl...\n",
      "Dataset loaded successfully!\n",
      "   Total measurements: 44,493\n",
      "   Unique filters: 1,603\n",
      "   Sites: CHTS, ETAD, INDH, USPA\n",
      "   Date range: 2013-06-28 to 2024-12-08\n",
      "   Data sources: ChemSpec, FTIR, HIPS\n",
      "✅ Database loaded successfully\n",
      "📍 Sites available: CHTS, ETAD, INDH, USPA\n",
      "🔍 Checking data structure...\n",
      "Sample data columns from ETAD FTIR:\n",
      "   Columns: ['SampleDate', 'Concentration', 'Concentration_Units', 'FilterId', 'MDL', 'Uncertainty']\n",
      "   Shape: (190, 6)\n",
      "\n",
      "📋 DETAILED SITE ANALYSIS\n",
      "============================================================\n",
      "   Using filter column: FilterId for FTIR\n",
      "   Using filter column: FilterId for HIPS\n",
      "   Using filter column: FilterId for ChemSpec\n",
      "\n",
      "🌍 ETAD Site:\n",
      "   Total unique filters: 190\n",
      "   Filters by measurement type:\n",
      "      • FTIR: 190 filters\n",
      "      • HIPS: 190 filters\n",
      "      • ChemSpec: 188 filters\n",
      "   Filters with ALL measurements: 188\n",
      "   Date range: 2022-12-07 to 2024-09-21\n",
      "   Total measurements: 11374\n",
      "   Using filter column: FilterId for FTIR\n",
      "   Using filter column: FilterId for HIPS\n",
      "   Using filter column: FilterId for ChemSpec\n",
      "\n",
      "🌍 USPA Site:\n",
      "   Total unique filters: 265\n",
      "   Filters by measurement type:\n",
      "      • FTIR: 158 filters\n",
      "      • HIPS: 130 filters\n",
      "      • ChemSpec: 263 filters\n",
      "   Filters with ALL measurements: 128\n",
      "   Date range: 2021-11-09 to 2024-08-13\n",
      "   Total measurements: 13216\n",
      "   Using filter column: FilterId for FTIR\n",
      "   Using filter column: FilterId for HIPS\n",
      "   Using filter column: FilterId for ChemSpec\n",
      "\n",
      "🌍 INDH Site:\n",
      "   Total unique filters: 63\n",
      "   Filters by measurement type:\n",
      "      • FTIR: 63 filters\n",
      "      • HIPS: 63 filters\n",
      "      • ChemSpec: 27 filters\n",
      "   Filters with ALL measurements: 27\n",
      "   Date range: 2022-06-28 to 2024-06-30\n",
      "   Total measurements: 3100\n",
      "   Using filter column: FilterId for FTIR\n",
      "   Using filter column: FilterId for HIPS\n",
      "   Using filter column: FilterId for ChemSpec\n",
      "\n",
      "🌍 CHTS Site:\n",
      "   Total unique filters: 356\n",
      "   Filters by measurement type:\n",
      "      • FTIR: 186 filters\n",
      "      • HIPS: 163 filters\n",
      "      • ChemSpec: 341 filters\n",
      "   Filters with ALL measurements: 148\n",
      "   Date range: 2013-06-28 to 2024-12-08\n",
      "   Total measurements: 16803\n",
      "\n",
      "📊 SUMMARY TABLE FOR PRESENTATION\n",
      "============================================================\n",
      "\n",
      "                  Site  Filters  Complete Sets          Date Range                         Measurements\n",
      "Addis Ababa, Ethiopia      190            188 Dec 2022 - Sep 2024 FTIR-EC: 190, HIPS: 190, XRF/IC: 188\n",
      "    Pasadena/JPL, USA      265            128 Nov 2021 - Aug 2024 FTIR-EC: 158, HIPS: 130, XRF/IC: 263\n",
      "         Delhi, India       63             27 Jun 2022 - Jun 2024    FTIR-EC: 63, HIPS: 63, XRF/IC: 27\n",
      "       Beijing, China      356            148 Jun 2013 - Dec 2024 FTIR-EC: 186, HIPS: 163, XRF/IC: 341\n",
      "\n",
      "*Complete Sets = filters measured by all available methods at that site\n",
      "\n",
      "📊 DATA FOR POWERPOINT SLIDE\n",
      "============================================================\n",
      "\n",
      "Copy this table for your presentation:\n",
      "\n",
      "Addis Ababa, Ethiopia:\n",
      "  • Total Filters: 190\n",
      "  • Complete Sets: 188\n",
      "  • Date Range: Dec 2022 - Sep 2024\n",
      "  • Available: FTIR-EC: 190, HIPS: 190, XRF/IC: 188\n",
      "\n",
      "Pasadena/JPL, USA:\n",
      "  • Total Filters: 265\n",
      "  • Complete Sets: 128\n",
      "  • Date Range: Nov 2021 - Aug 2024\n",
      "  • Available: FTIR-EC: 158, HIPS: 130, XRF/IC: 263\n",
      "\n",
      "Delhi, India:\n",
      "  • Total Filters: 63\n",
      "  • Complete Sets: 27\n",
      "  • Date Range: Jun 2022 - Jun 2024\n",
      "  • Available: FTIR-EC: 63, HIPS: 63, XRF/IC: 27\n",
      "\n",
      "Beijing, China:\n",
      "  • Total Filters: 356\n",
      "  • Complete Sets: 148\n",
      "  • Date Range: Jun 2013 - Dec 2024\n",
      "  • Available: FTIR-EC: 186, HIPS: 163, XRF/IC: 341\n",
      "\n",
      "\n",
      "🔄 TRANSFERABILITY ASSESSMENT\n",
      "============================================================\n",
      "\n",
      "📅 Overlapping Time Periods:\n",
      "   ETAD ↔ USPA: 2022-12-07 to 2024-08-13 (615 days)\n",
      "   ETAD ↔ INDH: 2022-12-07 to 2024-06-30 (571 days)\n",
      "   ETAD ↔ CHTS: 2022-12-07 to 2024-09-21 (654 days)\n",
      "   USPA ↔ INDH: 2022-06-28 to 2024-06-30 (733 days)\n",
      "   USPA ↔ CHTS: 2021-11-09 to 2024-08-13 (1008 days)\n",
      "   INDH ↔ CHTS: 2022-06-28 to 2024-06-30 (733 days)\n",
      "\n",
      "📊 Measurement Type Coverage:\n",
      "\n",
      "FTIR:\n",
      "   ETAD: 190/190 filters (100.0% coverage)\n",
      "   USPA: 158/265 filters (59.6% coverage)\n",
      "   INDH: 63/63 filters (100.0% coverage)\n",
      "   CHTS: 186/356 filters (52.2% coverage)\n",
      "\n",
      "HIPS:\n",
      "   ETAD: 190/190 filters (100.0% coverage)\n",
      "   USPA: 130/265 filters (49.1% coverage)\n",
      "   INDH: 63/63 filters (100.0% coverage)\n",
      "   CHTS: 163/356 filters (45.8% coverage)\n",
      "\n",
      "ChemSpec:\n",
      "   ETAD: 188/190 filters (98.9% coverage)\n",
      "   USPA: 263/265 filters (99.2% coverage)\n",
      "   INDH: 27/63 filters (42.9% coverage)\n",
      "   CHTS: 341/356 filters (95.8% coverage)\n",
      "\n",
      "📈 SUMMARY STATISTICS\n",
      "============================================================\n",
      "Total filters across all sites: 874\n",
      "Total complete measurement sets: 491\n",
      "Overall completeness: 56.2%\n",
      "\n",
      "✅ Analysis complete!\n",
      "\n",
      "📝 Key Findings:\n",
      "   • Each filter can be measured by up to 3 different methods (FTIR, HIPS, XRF/IC)\n",
      "   • Not all filters have complete measurements across all methods\n",
      "   • ETAD has most complete recent dataset (Dec 2022 - Sep 2024)\n",
      "   • Overlapping time periods enable cross-site validation\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Multi-Site Filter Data Summary\n",
    "# This notebook extracts filter counts and data availability for all SPARTAN sites\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the data loader\n",
    "from data_loader_module import load_filter_database\n",
    "\n",
    "# Configuration\n",
    "PKL_PATH = '/Users/ahzs645/Github/aethmodular-clean/FTIR_HIPS_Chem/Filter Data/unified_filter_dataset.pkl'\n",
    "SITES = ['ETAD', 'USPA', 'INDH', 'CHTS']\n",
    "\n",
    "\n",
    "def normalize_filter_id(filter_id):\n",
    "    \"\"\"Normalize filter IDs so suffix variations like -# map to the same base filter.\"\"\"\n",
    "    if pd.isna(filter_id):\n",
    "        return None\n",
    "    filter_str = str(filter_id).strip()\n",
    "    if not filter_str:\n",
    "        return None\n",
    "    parts = filter_str.split('-')\n",
    "    if len(parts) >= 2:\n",
    "        return f\"{parts[0]}-{parts[1]}\"\n",
    "    return filter_str\n",
    "\n",
    "print(\"📊 Multi-Site Filter Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# %%\n",
    "# Load database\n",
    "loader = load_filter_database(PKL_PATH)\n",
    "print(f\"✅ Database loaded successfully\")\n",
    "print(f\"📍 Sites available: {', '.join(loader.get_available_sites())}\")\n",
    "\n",
    "# %%\n",
    "# Function to get detailed filter counts for a site\n",
    "def get_site_filter_details(site_code, loader):\n",
    "    \"\"\"Get detailed filter information for a site\"\"\"\n",
    "    \n",
    "    # Get site summary first\n",
    "    site_summary = loader.get_site_summary(site_code)\n",
    "    \n",
    "    if not site_summary:\n",
    "        return None\n",
    "    \n",
    "    # Get unique filters by method\n",
    "    filters_by_method = {}\n",
    "    all_filters = set()\n",
    "    \n",
    "    # Check each data source\n",
    "    for source in ['FTIR', 'HIPS', 'ChemSpec']:\n",
    "        # Try to get any parameter from this source to count filters\n",
    "        params = loader.list_available_parameters(site_code, source)\n",
    "        if params:\n",
    "            # Get data for first parameter to count unique filters\n",
    "            data = loader.get_parameter_data(site_code, params[0])\n",
    "            if len(data) > 0:\n",
    "                # Check what columns are available\n",
    "                if 'filter_id' in data.columns:\n",
    "                    filter_col = 'filter_id'\n",
    "                elif 'Filter_id' in data.columns:\n",
    "                    filter_col = 'Filter_id'\n",
    "                elif 'FilterID' in data.columns:\n",
    "                    filter_col = 'FilterID'\n",
    "                elif 'filter_ID' in data.columns:\n",
    "                    filter_col = 'filter_ID'\n",
    "                else:\n",
    "                    # Try to find any column with 'filter' in the name\n",
    "                    filter_cols = [col for col in data.columns if 'filter' in col.lower()]\n",
    "                    if filter_cols:\n",
    "                        filter_col = filter_cols[0]\n",
    "                        print(f\"   Using filter column: {filter_col} for {source}\")\n",
    "                    else:\n",
    "                        print(f\"   Warning: No filter ID column found for {source}\")\n",
    "                        print(f\"   Available columns: {list(data.columns)[:5]}...\")\n",
    "                        continue\n",
    "                \n",
    "                raw_filters = data[filter_col].dropna().unique()\n",
    "                normalized_filters = set()\n",
    "                for filter_id in raw_filters:\n",
    "                    normalized = normalize_filter_id(filter_id)\n",
    "                    if normalized:\n",
    "                        normalized_filters.add(normalized)\n",
    "\n",
    "                if normalized_filters:\n",
    "                    filters_by_method[source] = normalized_filters\n",
    "                    all_filters.update(normalized_filters)\n",
    "    \n",
    "    # Find filters with complete measurements\n",
    "    if filters_by_method:\n",
    "        all_methods = list(filters_by_method.keys())\n",
    "        if len(all_methods) > 1:\n",
    "            complete_filters = filters_by_method[all_methods[0]]\n",
    "            for method in all_methods[1:]:\n",
    "                complete_filters = complete_filters.intersection(filters_by_method[method])\n",
    "        else:\n",
    "            complete_filters = filters_by_method[all_methods[0]] if all_methods else set()\n",
    "    else:\n",
    "        complete_filters = set()\n",
    "    \n",
    "    total_filters = len(all_filters) if all_filters else site_summary.get('unique_filters', 0)\n",
    "\n",
    "    return {\n",
    "        'total_filters': total_filters,\n",
    "        'filters_by_method': {k: len(v) for k, v in filters_by_method.items()},\n",
    "        'complete_filters': len(complete_filters),\n",
    "        'date_range': (site_summary['date_range']['start'], site_summary['date_range']['end']),\n",
    "        'total_measurements': site_summary['total_measurements']\n",
    "    }\n",
    "\n",
    "# %%\n",
    "# Quick test to see what columns we actually have\n",
    "print(\"🔍 Checking data structure...\")\n",
    "test_site = 'ETAD'\n",
    "test_params = loader.list_available_parameters(test_site, 'FTIR')\n",
    "if test_params:\n",
    "    test_data = loader.get_parameter_data(test_site, test_params[0])\n",
    "    print(f\"Sample data columns from {test_site} FTIR:\")\n",
    "    print(f\"   Columns: {list(test_data.columns)}\")\n",
    "    print(f\"   Shape: {test_data.shape}\")\n",
    "\n",
    "# %%\n",
    "# Analyze each site\n",
    "site_summaries = {}\n",
    "\n",
    "print(\"\\n📋 DETAILED SITE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for site in SITES:\n",
    "    details = get_site_filter_details(site, loader)\n",
    "    if details:\n",
    "        site_summaries[site] = details\n",
    "        \n",
    "        print(f\"\\n🌍 {site} Site:\")\n",
    "        print(f\"   Total unique filters: {details['total_filters']}\")\n",
    "        \n",
    "        if details['filters_by_method']:\n",
    "            print(f\"   Filters by measurement type:\")\n",
    "            for method, count in details['filters_by_method'].items():\n",
    "                print(f\"      • {method}: {count} filters\")\n",
    "            \n",
    "            print(f\"   Filters with ALL measurements: {details['complete_filters']}\")\n",
    "            print(f\"   Date range: {details['date_range'][0].date()} to {details['date_range'][1].date()}\")\n",
    "            print(f\"   Total measurements: {details['total_measurements']}\")\n",
    "    else:\n",
    "        print(f\"\\n🌍 {site} Site: No data available\")\n",
    "\n",
    "# %%\n",
    "# Create summary table for presentation\n",
    "print(\"\\n📊 SUMMARY TABLE FOR PRESENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Build table data\n",
    "table_data = []\n",
    "for site in SITES:\n",
    "    if site in site_summaries:\n",
    "        s = site_summaries[site]\n",
    "        \n",
    "        # Get site location names\n",
    "        site_names = {\n",
    "            'ETAD': 'Addis Ababa, Ethiopia',\n",
    "            'USPA': 'Pasadena/JPL, USA',\n",
    "            'INDH': 'Delhi, India', \n",
    "            'CHTS': 'Beijing, China'\n",
    "        }\n",
    "        \n",
    "        # Format date range\n",
    "        date_str = f\"{s['date_range'][0].strftime('%b %Y')} - {s['date_range'][1].strftime('%b %Y')}\"\n",
    "        \n",
    "        # Format measurement counts\n",
    "        meas_list = []\n",
    "        for method in ['FTIR', 'HIPS', 'ChemSpec']:\n",
    "            if method in s['filters_by_method']:\n",
    "                count = s['filters_by_method'][method]\n",
    "                if method == 'FTIR':\n",
    "                    meas_list.append(f\"FTIR-EC: {count}\")\n",
    "                elif method == 'HIPS':\n",
    "                    meas_list.append(f\"HIPS: {count}\")\n",
    "                elif method == 'ChemSpec':\n",
    "                    meas_list.append(f\"XRF/IC: {count}\")\n",
    "        meas_str = \", \".join(meas_list)\n",
    "        \n",
    "        table_data.append({\n",
    "            'Site': site_names.get(site, site),\n",
    "            'Filters': s['total_filters'],\n",
    "            'Complete Sets': s['complete_filters'],\n",
    "            'Date Range': date_str,\n",
    "            'Measurements': meas_str\n",
    "        })\n",
    "\n",
    "# Create DataFrame for nice display\n",
    "df = pd.DataFrame(table_data)\n",
    "print(\"\\n\", df.to_string(index=False))\n",
    "\n",
    "print(\"\\n*Complete Sets = filters measured by all available methods at that site\")\n",
    "\n",
    "# %%\n",
    "# Generate data for PowerPoint slide\n",
    "print(\"\\n📊 DATA FOR POWERPOINT SLIDE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nCopy this table for your presentation:\\n\")\n",
    "\n",
    "for row in table_data:\n",
    "    print(f\"{row['Site']}:\")\n",
    "    print(f\"  • Total Filters: {row['Filters']}\")\n",
    "    print(f\"  • Complete Sets: {row['Complete Sets']}\")\n",
    "    print(f\"  • Date Range: {row['Date Range']}\")\n",
    "    print(f\"  • Available: {row['Measurements']}\")\n",
    "    print()\n",
    "\n",
    "# %%\n",
    "# Analysis for transferability\n",
    "print(\"\\n🔄 TRANSFERABILITY ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for overlapping time periods\n",
    "print(\"\\n📅 Overlapping Time Periods:\")\n",
    "all_dates = []\n",
    "for site in SITES:\n",
    "    if site in site_summaries:\n",
    "        start, end = site_summaries[site]['date_range']\n",
    "        all_dates.append((site, start, end))\n",
    "\n",
    "if len(all_dates) > 1:\n",
    "    # Find overlap periods\n",
    "    for i, (site1, start1, end1) in enumerate(all_dates):\n",
    "        for site2, start2, end2 in all_dates[i+1:]:\n",
    "            overlap_start = max(start1, start2)\n",
    "            overlap_end = min(end1, end2)\n",
    "            \n",
    "            if overlap_start < overlap_end:\n",
    "                overlap_days = (overlap_end - overlap_start).days\n",
    "                print(f\"   {site1} ↔ {site2}: {overlap_start.date()} to {overlap_end.date()} ({overlap_days} days)\")\n",
    "\n",
    "# %%\n",
    "# Filter availability comparison\n",
    "print(\"\\n📊 Measurement Type Coverage:\")\n",
    "all_methods = ['FTIR', 'HIPS', 'ChemSpec']\n",
    "\n",
    "for method in all_methods:\n",
    "    print(f\"\\n{method}:\")\n",
    "    for site in SITES:\n",
    "        if site in site_summaries:\n",
    "            count = site_summaries[site]['filters_by_method'].get(method, 0)\n",
    "            total = site_summaries[site]['total_filters']\n",
    "            pct = (count / total * 100) if total > 0 else 0\n",
    "            print(f\"   {site}: {count}/{total} filters ({pct:.1f}% coverage)\")\n",
    "\n",
    "# %%\n",
    "# Summary statistics for presentation\n",
    "print(\"\\n📈 SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_filters_all_sites = sum(s['total_filters'] for s in site_summaries.values())\n",
    "total_complete_sets = sum(s['complete_filters'] for s in site_summaries.values())\n",
    "\n",
    "print(f\"Total filters across all sites: {total_filters_all_sites}\")\n",
    "print(f\"Total complete measurement sets: {total_complete_sets}\")\n",
    "print(f\"Overall completeness: {total_complete_sets/total_filters_all_sites*100:.1f}%\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n✅ Analysis complete!\")\n",
    "print(\"\\n📝 Key Findings:\")\n",
    "print(\"   • Each filter can be measured by up to 3 different methods (FTIR, HIPS, XRF/IC)\")\n",
    "print(\"   • Not all filters have complete measurements across all methods\")\n",
    "print(\"   • ETAD has most complete recent dataset (Dec 2022 - Sep 2024)\")\n",
    "print(\"   • Overlapping time periods enable cross-site validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
