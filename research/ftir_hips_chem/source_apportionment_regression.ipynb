{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addis Ababa: BC/EC Method Comparison by Source Apportionment\n",
    "\n",
    "This notebook compares HIPS Fabs, FTIR EC, and Aethalometer BC measurements,\n",
    "stratified by dominant aerosol source type from PMF/source apportionment analysis.\n",
    "\n",
    "## Analysis Objectives:\n",
    "1. **Primary Regression Plots** — HIPS vs EC with all data\n",
    "2. **Source-Separated Regressions** — Filter by dominant source type\n",
    "3. **Threshold-Filtered Analysis** — Exclude \"mixed days\" using source contribution thresholds\n",
    "4. **Aethalometer Comparison** — Repeat all analyses with aethalometer BC\n",
    "5. **Source Contribution Visualization** — Daily source fraction bar charts\n",
    "\n",
    "## Source Categories:\n",
    "- Charcoal burning\n",
    "- Wood burning\n",
    "- Fossil fuel\n",
    "- Polluted marine\n",
    "- Sea salt\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom matplotlib.dates import MonthLocator, DateFormatter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Add scripts folder to path\nnotebook_dir = os.path.dirname(os.path.abspath('__file__'))\nscripts_path = os.path.join(notebook_dir, 'scripts')\nif scripts_path not in sys.path:\n    sys.path.insert(0, scripts_path)\n\nfrom config import SITES, MAC_VALUE\nfrom data_matching import (\n    load_aethalometer_data,\n    load_filter_data,\n    add_base_filter_id,\n    match_all_parameters,\n    load_etad_factors_with_filter_ids,\n)\nprint(\"Loaded config and data_matching modules\")\n\n# Configure matplotlib\nplt.style.use('seaborn-v0_8-darkgrid')\nplt.rcParams['figure.figsize'] = (12, 8)\nplt.rcParams['font.size'] = 11\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 13\n\n# Create output directories\ndef setup_directories():\n    dirs = {\n        'plots': 'output/plots/addis_ababa/source_regression',\n        'data': 'output/data/addis_ababa'\n    }\n    for dir_path in dirs.values():\n        os.makedirs(dir_path, exist_ok=True)\n    return dirs\n\ndirs = setup_directories()\nprint(\"Setup complete!\")\nprint(f\"MAC value: {MAC_VALUE} m²/g\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site configuration\n",
    "ADDIS_CONFIG = {\n",
    "    'name': 'Addis_Ababa',\n",
    "    'code': 'ETAD',\n",
    "    'timezone': 'Africa/Addis_Ababa',\n",
    "}\n",
    "\n",
    "# Ethiopian seasons\n",
    "SEASONS = {\n",
    "    'Dry Season': [10, 11, 12, 1, 2],\n",
    "    'Belg Rainy Season': [3, 4, 5],\n",
    "    'Kiremt Rainy Season': [6, 7, 8, 9]\n",
    "}\n",
    "SEASONS_ORDER = ['Dry Season', 'Belg Rainy Season', 'Kiremt Rainy Season']\n",
    "SEASON_COLORS = {'Dry Season': '#E67E22', 'Belg Rainy Season': '#27AE60', 'Kiremt Rainy Season': '#3498DB'}\n",
    "\n",
    "# Source apportionment categories and their colors\n",
    "SOURCE_CATEGORIES = {\n",
    "    'charcoal': {'label': 'Charcoal Burning', 'color': '#2C3E50', 'marker': 'o'},\n",
    "    'wood': {'label': 'Wood Burning', 'color': '#8B4513', 'marker': 's'},\n",
    "    'fossil_fuel': {'label': 'Fossil Fuel', 'color': '#7D3C98', 'marker': '^'},\n",
    "    'polluted_marine': {'label': 'Polluted Marine', 'color': '#2980B9', 'marker': 'D'},\n",
    "    'sea_salt': {'label': 'Sea Salt', 'color': '#1ABC9C', 'marker': 'v'},\n",
    "}\n",
    "SOURCE_ORDER = ['charcoal', 'wood', 'fossil_fuel', 'polluted_marine', 'sea_salt']\n",
    "\n",
    "# BC/EC measurement methods\n",
    "METHODS = {\n",
    "    'hips_fabs': {'label': 'HIPS Fabs/MAC', 'color': '#2ca02c', 'unit': 'µg/m³'},\n",
    "    'ftir_ec': {'label': 'FTIR EC', 'color': '#d62728', 'unit': 'µg/m³'},\n",
    "    'ir_bcc': {'label': 'Aeth IR BCc', 'color': '#1f77b4', 'unit': 'µg/m³'},\n",
    "    'uv_bcc': {'label': 'Aeth UV BCc', 'color': '#ff7f0e', 'unit': 'µg/m³'},\n",
    "}\n",
    "\n",
    "# Thresholds to test for dominant source filtering\n",
    "DOMINANCE_THRESHOLDS = [0.30, 0.40, 0.50, 0.60]  # 30%, 40%, 50%, 60%\n",
    "\n",
    "print(f\"Site: {ADDIS_CONFIG['name']}\")\n",
    "print(f\"Source categories: {', '.join(SOURCE_CATEGORIES.keys())}\")\n",
    "print(f\"Dominance thresholds to test: {DOMINANCE_THRESHOLDS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Data Loading\n\nLoad factor contributions (joined to Filter IDs via `oldDate`), then merge with\nFTIR EC, HIPS Fabs, and Aethalometer BC measurements via `base_filter_id`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# Load factor contributions with Filter IDs (joined via oldDate)\n# =============================================================================\nfactors_df = load_etad_factors_with_filter_ids()\n\n# Map GF columns to the _frac names used by the rest of the notebook\nFACTOR_TO_FRAC = {\n    'GF3 (Charcoal)':              'charcoal_frac',\n    'GF2 (Wood Burning)':          'wood_frac',\n    'GF5 (Fossil Fuel Combustion)':'fossil_fuel_frac',\n    'GF4 (Polluted Marine)':       'polluted_marine_frac',\n    'GF1 (Sea Salt Mixed)':        'sea_salt_frac',\n}\nfactors_df = factors_df.rename(columns=FACTOR_TO_FRAC)\nfrac_cols = list(FACTOR_TO_FRAC.values())\n\n# Normalize GF fractions to relative source contributions\n# (raw GFs are PM2.5 mass fractions — they sum to ~0.03-0.46, not 1.0)\nfrac_sum = factors_df[frac_cols].sum(axis=1)\nfor col in frac_cols:\n    factors_df[col] = factors_df[col] / frac_sum\n\n# =============================================================================\n# Load aethalometer + filter measurements and match by date\n# =============================================================================\naethalometer_data = load_aethalometer_data()\nfilter_data = load_filter_data()\nfilter_data = add_base_filter_id(filter_data)\n\ndf_aeth = aethalometer_data.get('Addis_Ababa')\nbc_df = match_all_parameters('Addis_Ababa', 'ETAD', df_aeth, filter_data)\n\n# =============================================================================\n# Merge BC/EC measurements with factor contributions via base_filter_id\n# =============================================================================\n# Get the base_filter_id for each bc_df date by looking up in the unified dataset\netad_filters = filter_data[filter_data['Site'] == 'ETAD'][['SampleDate', 'FilterId']].drop_duplicates()\netad_filters = etad_filters.rename(columns={'SampleDate': 'date', 'FilterId': 'base_filter_id'})\nbc_df['date'] = pd.to_datetime(bc_df['date'])\netad_filters['date'] = pd.to_datetime(etad_filters['date'])\n\nbc_with_id = pd.merge(bc_df, etad_filters, on='date', how='left')\n\n# Now merge with factor contributions on base_filter_id\nfactor_merge_cols = ['base_filter_id'] + frac_cols\ndf = pd.merge(bc_with_id, factors_df[factor_merge_cols].drop_duplicates(),\n              on='base_filter_id', how='inner')\n\n# =============================================================================\n# Add temporal features\n# =============================================================================\ndf['Month'] = df['date'].dt.month\ndf['Ethiopian_Season'] = df['Month'].map(lambda m:\n    'Dry Season' if m in SEASONS['Dry Season'] else\n    'Belg Rainy Season' if m in SEASONS['Belg Rainy Season'] else\n    'Kiremt Rainy Season'\n)\n\n# Determine dominant source for each sample (now using normalized fractions)\ndf['dominant_source'] = df[frac_cols].idxmax(axis=1).str.replace('_frac', '')\ndf['dominant_fraction'] = df[frac_cols].max(axis=1)\n\nprint(f\"\\nFinal dataset: {len(df)} samples\")\nprint(f\"Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\nprint(f\"\\nBC/EC availability:\")\nfor col in ['ftir_ec', 'hips_fabs', 'ir_bcc']:\n    if col in df.columns:\n        n = df[col].notna().sum()\n        print(f\"  {col}: {n} samples\")\n\nprint(f\"\\nDominant source distribution:\")\nprint(df['dominant_source'].value_counts().to_string())\nprint(f\"\\nDominant fraction stats: mean={df['dominant_fraction'].mean():.1%}, \"\n      f\"min={df['dominant_fraction'].min():.1%}, max={df['dominant_fraction'].max():.1%}\")\nprint(f\"Samples with ≥50% dominant: {(df['dominant_fraction'] >= 0.50).sum()}\")\nprint(f\"Samples with ≥30% dominant: {(df['dominant_fraction'] >= 0.30).sum()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Task 1: Primary Regression Plots (HIPS vs EC)\n",
    "\n",
    "**Goal**: Create baseline HIPS vs FTIR EC scatter plot with regression statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression(df, x_col, y_col, x_label, y_label, title, color_by=None,\n",
    "                    color_dict=None, ax=None, show_stats=True, force_through_origin=False):\n",
    "    \"\"\"\n",
    "    Create a regression scatter plot with statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame with data\n",
    "    x_col, y_col : column names\n",
    "    x_label, y_label : axis labels\n",
    "    title : plot title\n",
    "    color_by : column to color points by (optional)\n",
    "    color_dict : dict mapping color_by values to colors\n",
    "    ax : matplotlib axis (optional)\n",
    "    show_stats : whether to show regression statistics\n",
    "    force_through_origin : whether to force regression through origin\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 7))\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    \n",
    "    valid = df[[x_col, y_col]].dropna()\n",
    "    if color_by and color_by in df.columns:\n",
    "        valid = pd.merge(valid, df[[color_by]], left_index=True, right_index=True)\n",
    "    \n",
    "    if len(valid) < 3:\n",
    "        ax.text(0.5, 0.5, f'Insufficient data\\n(n={len(valid)})', \n",
    "                transform=ax.transAxes, ha='center', va='center', fontsize=14)\n",
    "        ax.set_title(title)\n",
    "        return fig, None\n",
    "    \n",
    "    x = valid[x_col].values\n",
    "    y = valid[y_col].values\n",
    "    \n",
    "    # Plot points\n",
    "    if color_by and color_by in valid.columns and color_dict:\n",
    "        for category in valid[color_by].unique():\n",
    "            mask = valid[color_by] == category\n",
    "            cat_info = color_dict.get(category, {'color': 'gray', 'label': category, 'marker': 'o'})\n",
    "            ax.scatter(valid.loc[mask, x_col], valid.loc[mask, y_col],\n",
    "                      s=60, alpha=0.7, color=cat_info.get('color', 'gray'),\n",
    "                      marker=cat_info.get('marker', 'o'),\n",
    "                      edgecolors='black', linewidth=0.3,\n",
    "                      label=f\"{cat_info.get('label', category)} (n={mask.sum()})\")\n",
    "    else:\n",
    "        ax.scatter(x, y, s=60, alpha=0.6, color='#3498DB', edgecolors='black', linewidth=0.3)\n",
    "    \n",
    "    # Regression\n",
    "    if force_through_origin:\n",
    "        # Linear regression through origin: y = slope * x\n",
    "        slope = np.sum(x * y) / np.sum(x * x)\n",
    "        intercept = 0\n",
    "        y_pred = slope * x\n",
    "        ss_res = np.sum((y - y_pred) ** 2)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "        r = np.sqrt(r_squared) * np.sign(slope)\n",
    "        p = stats.pearsonr(x, y)[1]\n",
    "        se = np.sqrt(ss_res / (len(x) - 1))\n",
    "    else:\n",
    "        slope, intercept, r, p, se = stats.linregress(x, y)\n",
    "        r_squared = r ** 2\n",
    "    \n",
    "    # Plot regression line and 1:1\n",
    "    ax_max = max(x.max(), y.max()) * 1.1\n",
    "    x_fit = np.linspace(0, ax_max, 100)\n",
    "    ax.plot(x_fit, slope * x_fit + intercept, 'k-', linewidth=2, alpha=0.7, label='Regression')\n",
    "    ax.plot([0, ax_max], [0, ax_max], 'k--', linewidth=1.5, alpha=0.4, label='1:1 line')\n",
    "    \n",
    "    # Statistics annotation\n",
    "    if show_stats:\n",
    "        sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "        if force_through_origin:\n",
    "            stats_text = f'y = {slope:.3f}x\\nR² = {r_squared:.3f} ({sig})\\nn = {len(valid)}'\n",
    "        else:\n",
    "            stats_text = f'y = {slope:.3f}x + {intercept:.3f}\\nR² = {r_squared:.3f} ({sig})\\nn = {len(valid)}'\n",
    "        ax.text(0.03, 0.97, stats_text, transform=ax.transAxes, fontsize=10, va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlim(0, ax_max)\n",
    "    ax.set_ylim(0, ax_max)\n",
    "    ax.set_xlabel(x_label, fontsize=12)\n",
    "    ax.set_ylabel(y_label, fontsize=12)\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    if color_by:\n",
    "        ax.legend(fontsize=8, loc='lower right')\n",
    "    \n",
    "    results = {\n",
    "        'slope': slope, 'intercept': intercept, 'r': r, 'r_squared': r_squared,\n",
    "        'p_value': p, 'se': se, 'n': len(valid)\n",
    "    }\n",
    "    \n",
    "    return fig, results\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TASK 1: PRIMARY REGRESSION — HIPS vs FTIR EC (ALL DATA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall baseline plot\n",
    "fig, results = plot_regression(\n",
    "    df, 'ftir_ec', 'hips_fabs',\n",
    "    'FTIR EC (µg/m³)', 'HIPS Fabs/MAC (µg/m³)',\n",
    "    'HIPS vs FTIR EC — All Data'\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dirs['plots'], 'hips_vs_ec_baseline.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "if results:\n",
    "    print(f\"\\nRegression Results:\")\n",
    "    print(f\"  Slope: {results['slope']:.4f}\")\n",
    "    print(f\"  Intercept: {results['intercept']:.4f}\")\n",
    "    print(f\"  R²: {results['r_squared']:.4f}\")\n",
    "    print(f\"  p-value: {results['p_value']:.2e}\")\n",
    "    print(f\"  n: {results['n']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Task 2: Source-Separated Regression Plots\n",
    "\n",
    "**Goal**: Create HIPS vs EC plots filtered by dominant source type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_source_separated_regressions(df, x_col, y_col, x_label, y_label, \n",
    "                                       sources=SOURCE_ORDER, source_info=SOURCE_CATEGORIES):\n",
    "    \"\"\"\n",
    "    Create panel of regression plots, one per dominant source.\n",
    "    \"\"\"\n",
    "    n_sources = len(sources)\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(n_sources / n_cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5.5*n_rows))\n",
    "    axes = axes.flatten() if n_sources > 1 else [axes]\n",
    "    \n",
    "    results_all = {}\n",
    "    \n",
    "    for idx, source in enumerate(sources):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Filter to dominant source\n",
    "        source_mask = df['dominant_source'] == source\n",
    "        source_data = df[source_mask].copy()\n",
    "        \n",
    "        if len(source_data) < 3:\n",
    "            ax.text(0.5, 0.5, f'{source_info[source][\"label\"]}\\n(n={len(source_data)})\\nInsufficient data',\n",
    "                   transform=ax.transAxes, ha='center', va='center', fontsize=11)\n",
    "            ax.set_title(source_info[source]['label'], fontsize=11, fontweight='bold',\n",
    "                        color=source_info[source]['color'])\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            continue\n",
    "        \n",
    "        valid = source_data[[x_col, y_col]].dropna()\n",
    "        \n",
    "        if len(valid) < 3:\n",
    "            ax.text(0.5, 0.5, f'{source_info[source][\"label\"]}\\n(n={len(valid)})\\nInsufficient data',\n",
    "                   transform=ax.transAxes, ha='center', va='center', fontsize=11)\n",
    "            ax.set_title(source_info[source]['label'], fontsize=11, fontweight='bold',\n",
    "                        color=source_info[source]['color'])\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            continue\n",
    "        \n",
    "        x = valid[x_col].values\n",
    "        y = valid[y_col].values\n",
    "        \n",
    "        # Scatter\n",
    "        ax.scatter(x, y, s=50, alpha=0.6, color=source_info[source]['color'],\n",
    "                  marker=source_info[source]['marker'], edgecolors='black', linewidth=0.3)\n",
    "        \n",
    "        # Regression\n",
    "        slope, intercept, r, p, se = stats.linregress(x, y)\n",
    "        \n",
    "        ax_max = max(x.max(), y.max()) * 1.1 if len(x) > 0 else 10\n",
    "        x_fit = np.linspace(0, ax_max, 100)\n",
    "        ax.plot(x_fit, slope * x_fit + intercept, 'k-', linewidth=1.5, alpha=0.7)\n",
    "        ax.plot([0, ax_max], [0, ax_max], 'k--', linewidth=1, alpha=0.3)\n",
    "        \n",
    "        # Stats\n",
    "        sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else 'ns'\n",
    "        ax.text(0.03, 0.97, f'y = {slope:.3f}x + {intercept:.2f}\\nR² = {r**2:.3f} ({sig})\\nn = {len(valid)}',\n",
    "                transform=ax.transAxes, fontsize=9, va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "        \n",
    "        ax.set_xlim(0, ax_max)\n",
    "        ax.set_ylim(0, ax_max)\n",
    "        ax.set_xlabel(x_label, fontsize=10)\n",
    "        ax.set_ylabel(y_label, fontsize=10)\n",
    "        ax.set_title(source_info[source]['label'], fontsize=11, fontweight='bold',\n",
    "                    color=source_info[source]['color'])\n",
    "        ax.set_aspect('equal')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        results_all[source] = {\n",
    "            'slope': slope, 'intercept': intercept, 'r': r, 'r_squared': r**2,\n",
    "            'p_value': p, 'n': len(valid)\n",
    "        }\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for idx in range(n_sources, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.suptitle(f'{y_label} vs {x_label} — By Dominant Source',\n",
    "                fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, results_all\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TASK 2: SOURCE-SEPARATED REGRESSION PLOTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# HIPS vs EC by source\n",
    "fig, source_results = plot_source_separated_regressions(\n",
    "    df, 'ftir_ec', 'hips_fabs',\n",
    "    'FTIR EC (µg/m³)', 'HIPS Fabs/MAC (µg/m³)'\n",
    ")\n",
    "plt.savefig(os.path.join(dirs['plots'], 'hips_vs_ec_by_source.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\nRegression Results by Dominant Source:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Source':<20s} {'n':>5s} {'Slope':>8s} {'Intercept':>10s} {'R²':>8s} {'p-value':>12s}\")\n",
    "print(\"-\" * 80)\n",
    "for source in SOURCE_ORDER:\n",
    "    if source in source_results:\n",
    "        r = source_results[source]\n",
    "        sig = '*' if r['p_value'] < 0.05 else ''\n",
    "        print(f\"{SOURCE_CATEGORIES[source]['label']:<20s} {r['n']:>5d} {r['slope']:>8.3f} \"\n",
    "              f\"{r['intercept']:>10.3f} {r['r_squared']:>8.3f} {r['p_value']:>11.2e}{sig}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Task 3: Threshold-Filtered Regressions\n",
    "\n",
    "**Goal**: Filter out \"mixed days\" — only keep days where dominant source exceeds threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_threshold_filtering(df, thresholds=DOMINANCE_THRESHOLDS):\n",
    "    \"\"\"\n",
    "    Analyze how threshold filtering affects sample counts.\n",
    "    \"\"\"\n",
    "    print(\"\\nThreshold Filtering Analysis:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Threshold':<12s}\", end='')\n",
    "    for source in SOURCE_ORDER:\n",
    "        print(f\" {SOURCE_CATEGORIES[source]['label'][:10]:>10s}\", end='')\n",
    "    print(f\" {'Total':>10s}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        filtered = df[df['dominant_fraction'] >= thresh]\n",
    "        print(f\"{thresh*100:.0f}%{'':<9s}\", end='')\n",
    "        for source in SOURCE_ORDER:\n",
    "            n = (filtered['dominant_source'] == source).sum()\n",
    "            print(f\" {n:>10d}\", end='')\n",
    "        print(f\" {len(filtered):>10d}\")\n",
    "\n",
    "\n",
    "def plot_threshold_comparison(df, x_col, y_col, x_label, y_label, \n",
    "                               thresholds=DOMINANCE_THRESHOLDS):\n",
    "    \"\"\"\n",
    "    Create comparison plots at different thresholds.\n",
    "    \"\"\"\n",
    "    n_thresh = len(thresholds)\n",
    "    fig, axes = plt.subplots(1, n_thresh + 1, figsize=(5*(n_thresh+1), 5))\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Plot 0: All data\n",
    "    ax = axes[0]\n",
    "    valid = df[[x_col, y_col]].dropna()\n",
    "    if len(valid) >= 3:\n",
    "        x, y = valid[x_col].values, valid[y_col].values\n",
    "        ax.scatter(x, y, s=40, alpha=0.5, color='gray', edgecolors='black', linewidth=0.2)\n",
    "        slope, intercept, r, p, se = stats.linregress(x, y)\n",
    "        ax_max = max(x.max(), y.max()) * 1.1\n",
    "        x_fit = np.linspace(0, ax_max, 100)\n",
    "        ax.plot(x_fit, slope * x_fit + intercept, 'k-', linewidth=1.5)\n",
    "        ax.plot([0, ax_max], [0, ax_max], 'k--', linewidth=1, alpha=0.3)\n",
    "        ax.text(0.03, 0.97, f'R² = {r**2:.3f}\\nn = {len(valid)}',\n",
    "                transform=ax.transAxes, fontsize=9, va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "        ax.set_xlim(0, ax_max)\n",
    "        ax.set_ylim(0, ax_max)\n",
    "        results['all'] = {'r_squared': r**2, 'n': len(valid), 'slope': slope}\n",
    "    ax.set_xlabel(x_label, fontsize=10)\n",
    "    ax.set_ylabel(y_label, fontsize=10)\n",
    "    ax.set_title('All Data', fontsize=11, fontweight='bold')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Threshold-filtered plots\n",
    "    for idx, thresh in enumerate(thresholds):\n",
    "        ax = axes[idx + 1]\n",
    "        filtered = df[df['dominant_fraction'] >= thresh]\n",
    "        valid = filtered[[x_col, y_col, 'dominant_source']].dropna()\n",
    "        \n",
    "        if len(valid) >= 3:\n",
    "            # Color by source\n",
    "            for source in SOURCE_ORDER:\n",
    "                mask = valid['dominant_source'] == source\n",
    "                if mask.sum() > 0:\n",
    "                    ax.scatter(valid.loc[mask, x_col], valid.loc[mask, y_col],\n",
    "                              s=40, alpha=0.6, color=SOURCE_CATEGORIES[source]['color'],\n",
    "                              marker=SOURCE_CATEGORIES[source]['marker'],\n",
    "                              edgecolors='black', linewidth=0.2,\n",
    "                              label=SOURCE_CATEGORIES[source]['label'][:8])\n",
    "            \n",
    "            x, y = valid[x_col].values, valid[y_col].values\n",
    "            slope, intercept, r, p, se = stats.linregress(x, y)\n",
    "            ax_max = max(x.max(), y.max()) * 1.1\n",
    "            x_fit = np.linspace(0, ax_max, 100)\n",
    "            ax.plot(x_fit, slope * x_fit + intercept, 'k-', linewidth=1.5)\n",
    "            ax.plot([0, ax_max], [0, ax_max], 'k--', linewidth=1, alpha=0.3)\n",
    "            ax.text(0.03, 0.97, f'R² = {r**2:.3f}\\nn = {len(valid)}',\n",
    "                    transform=ax.transAxes, fontsize=9, va='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "            ax.set_xlim(0, ax_max)\n",
    "            ax.set_ylim(0, ax_max)\n",
    "            results[f'{thresh*100:.0f}%'] = {'r_squared': r**2, 'n': len(valid), 'slope': slope}\n",
    "        \n",
    "        ax.set_xlabel(x_label, fontsize=10)\n",
    "        ax.set_title(f'≥{thresh*100:.0f}% Dominant', fontsize=11, fontweight='bold')\n",
    "        ax.set_aspect('equal')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == len(thresholds) - 1:\n",
    "            ax.legend(fontsize=6, loc='lower right')\n",
    "    \n",
    "    plt.suptitle(f'{y_label} vs {x_label} — Threshold Comparison',\n",
    "                fontsize=13, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, results\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TASK 3: THRESHOLD-FILTERED REGRESSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze thresholds\n",
    "analyze_threshold_filtering(df)\n",
    "\n",
    "# Plot threshold comparison for HIPS vs EC\n",
    "fig, thresh_results = plot_threshold_comparison(\n",
    "    df, 'ftir_ec', 'hips_fabs',\n",
    "    'FTIR EC (µg/m³)', 'HIPS Fabs/MAC (µg/m³)'\n",
    ")\n",
    "plt.savefig(os.path.join(dirs['plots'], 'hips_vs_ec_threshold_comparison.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\nR² by Threshold:\")\n",
    "for key, val in thresh_results.items():\n",
    "    print(f\"  {key}: R² = {val['r_squared']:.3f}, n = {val['n']}\")\n",
    "\n",
    "\n",
    "# Detailed threshold-filtered by source\n",
    "def plot_source_regressions_threshold_filtered(df, x_col, y_col, x_label, y_label, threshold=0.50):\n",
    "    \"\"\"\n",
    "    Plot source-separated regressions with threshold filter applied.\n",
    "    \"\"\"\n",
    "    filtered = df[df['dominant_fraction'] >= threshold].copy()\n",
    "    \n",
    "    print(f\"\\nFiltered to {threshold*100:.0f}%+ dominant: {len(filtered)} samples\")\n",
    "    print(f\"Source breakdown: {filtered['dominant_source'].value_counts().to_dict()}\")\n",
    "    \n",
    "    fig, results = plot_source_separated_regressions(\n",
    "        filtered, x_col, y_col, x_label, y_label\n",
    "    )\n",
    "    \n",
    "    plt.suptitle(f'{y_label} vs {x_label} — By Source (≥{threshold*100:.0f}% Dominant)',\n",
    "                fontsize=14, fontweight='bold', y=1.02)\n",
    "    \n",
    "    return fig, results\n",
    "\n",
    "\n",
    "# Plot with 50% threshold\n",
    "fig, thresh_source_results = plot_source_regressions_threshold_filtered(\n",
    "    df, 'ftir_ec', 'hips_fabs',\n",
    "    'FTIR EC (µg/m³)', 'HIPS Fabs/MAC (µg/m³)',\n",
    "    threshold=0.50\n",
    ")\n",
    "plt.savefig(os.path.join(dirs['plots'], 'hips_vs_ec_by_source_50pct.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Task 4: Aethalometer Comparison Plots\n",
    "\n",
    "**Goal**: Repeat all analyses for aethalometer (IR BCc and UV BCc) vs FTIR EC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TASK 4: AETHALOMETER COMPARISONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# IR BCc vs FTIR EC — All data\n",
    "print(\"\\n--- IR BCc vs FTIR EC ---\")\n",
    "fig, results_ir = plot_regression(\n",
    "    df, 'ftir_ec', 'ir_bcc',\n",
    "    'FTIR EC (µg/m³)', 'Aeth IR BCc (µg/m³)',\n",
    "    'Aethalometer IR BCc vs FTIR EC — All Data'\n",
    ")\n",
    "plt.savefig(os.path.join(dirs['plots'], 'aeth_ir_vs_ec_baseline.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# IR BCc by source\n",
    "fig, ir_source_results = plot_source_separated_regressions(\n",
    "    df, 'ftir_ec', 'ir_bcc',\n",
    "    'FTIR EC (µg/m³)', 'Aeth IR BCc (µg/m³)'\n",
    ")\n",
    "plt.savefig(os.path.join(dirs['plots'], 'aeth_ir_vs_ec_by_source.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# IR BCc threshold comparison\n",
    "fig, ir_thresh_results = plot_threshold_comparison(\n",
    "    df, 'ftir_ec', 'ir_bcc',\n",
    "    'FTIR EC (µg/m³)', 'Aeth IR BCc (µg/m³)'\n",
    ")\n",
    "plt.savefig(os.path.join(dirs['plots'], 'aeth_ir_vs_ec_threshold.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# UV BCc vs FTIR EC — All data\n",
    "if 'uv_bcc' in df.columns and df['uv_bcc'].notna().sum() > 3:\n",
    "    print(\"\\n--- UV BCc vs FTIR EC ---\")\n",
    "    fig, results_uv = plot_regression(\n",
    "        df, 'ftir_ec', 'uv_bcc',\n",
    "        'FTIR EC (µg/m³)', 'Aeth UV BCc (µg/m³)',\n",
    "        'Aethalometer UV BCc vs FTIR EC — All Data'\n",
    "    )\n",
    "    plt.savefig(os.path.join(dirs['plots'], 'aeth_uv_vs_ec_baseline.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # UV BCc by source\n",
    "    fig, uv_source_results = plot_source_separated_regressions(\n",
    "        df, 'ftir_ec', 'uv_bcc',\n",
    "        'FTIR EC (µg/m³)', 'Aeth UV BCc (µg/m³)'\n",
    "    )\n",
    "    plt.savefig(os.path.join(dirs['plots'], 'aeth_uv_vs_ec_by_source.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Aethalometer vs HIPS\n",
    "print(\"\\n--- Aeth IR BCc vs HIPS ---\")\n",
    "fig, results_aeth_hips = plot_regression(\n",
    "    df, 'hips_fabs', 'ir_bcc',\n",
    "    'HIPS Fabs/MAC (µg/m³)', 'Aeth IR BCc (µg/m³)',\n",
    "    'Aethalometer IR BCc vs HIPS — All Data'\n",
    ")\n",
    "plt.savefig(os.path.join(dirs['plots'], 'aeth_ir_vs_hips_baseline.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Task 5: Source Contribution Bar Charts\n",
    "\n",
    "**Goal**: Visualize daily source contributions as stacked or grouped bar charts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_source_contributions_bars(df, date_col='date', max_samples=60):\n",
    "    \"\"\"\n",
    "    Create bar chart of daily source contributions (OM fraction by source).\n",
    "    \n",
    "    Uses bars (not lines) since data is 1-in-3 day sampling.\n",
    "    \"\"\"\n",
    "    frac_cols = ['charcoal_frac', 'wood_frac', 'fossil_fuel_frac', \n",
    "                 'polluted_marine_frac', 'sea_salt_frac']\n",
    "    \n",
    "    # Filter to samples with source data\n",
    "    valid = df.dropna(subset=frac_cols).copy()\n",
    "    valid = valid.sort_values(date_col)\n",
    "    \n",
    "    if len(valid) == 0:\n",
    "        print(\"No valid source apportionment data\")\n",
    "        return None\n",
    "    \n",
    "    # Limit to manageable number for visualization\n",
    "    if len(valid) > max_samples:\n",
    "        valid = valid.tail(max_samples)\n",
    "        print(f\"Showing last {max_samples} samples\")\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "    \n",
    "    x = np.arange(len(valid))\n",
    "    width = 0.8\n",
    "    \n",
    "    # Bottom tracker for stacking\n",
    "    bottom = np.zeros(len(valid))\n",
    "    \n",
    "    source_names_map = {\n",
    "        'charcoal_frac': 'charcoal',\n",
    "        'wood_frac': 'wood',\n",
    "        'fossil_fuel_frac': 'fossil_fuel',\n",
    "        'polluted_marine_frac': 'polluted_marine',\n",
    "        'sea_salt_frac': 'sea_salt'\n",
    "    }\n",
    "    \n",
    "    for col in frac_cols:\n",
    "        source_key = source_names_map[col]\n",
    "        values = valid[col].values\n",
    "        ax.bar(x, values, width, bottom=bottom, \n",
    "               color=SOURCE_CATEGORIES[source_key]['color'],\n",
    "               label=SOURCE_CATEGORIES[source_key]['label'],\n",
    "               edgecolor='white', linewidth=0.5)\n",
    "        bottom += values\n",
    "    \n",
    "    # Format x-axis\n",
    "    date_labels = valid[date_col].dt.strftime('%m/%d')\n",
    "    ax.set_xticks(x[::3])  # Every 3rd label\n",
    "    ax.set_xticklabels(date_labels.iloc[::3], rotation=45, ha='right', fontsize=8)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Source Fraction', fontsize=12)\n",
    "    ax.set_title('Daily Source Contributions (OM Fraction)', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.01, 1), fontsize=9)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_source_contributions_summary(df):\n",
    "    \"\"\"\n",
    "    Summary visualization: seasonal average source contributions.\n",
    "    \"\"\"\n",
    "    frac_cols = ['charcoal_frac', 'wood_frac', 'fossil_fuel_frac', \n",
    "                 'polluted_marine_frac', 'sea_salt_frac']\n",
    "    \n",
    "    valid = df.dropna(subset=frac_cols + ['Ethiopian_Season'])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Panel 1: Overall average (pie chart)\n",
    "    ax = axes[0]\n",
    "    avg_fracs = [valid[col].mean() for col in frac_cols]\n",
    "    colors = [SOURCE_CATEGORIES[c.replace('_frac', '')]['color'] for c in frac_cols]\n",
    "    labels = [SOURCE_CATEGORIES[c.replace('_frac', '')]['label'] for c in frac_cols]\n",
    "    \n",
    "    wedges, texts, autotexts = ax.pie(avg_fracs, labels=None, autopct='%1.1f%%',\n",
    "                                       colors=colors, startangle=90,\n",
    "                                       wedgeprops={'edgecolor': 'white', 'linewidth': 1})\n",
    "    ax.legend(wedges, labels, loc='center left', bbox_to_anchor=(0.85, 0.5), fontsize=9)\n",
    "    ax.set_title(f'Overall Source Contributions\\n(n={len(valid)} samples)', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Panel 2: By season (grouped bars)\n",
    "    ax = axes[1]\n",
    "    \n",
    "    x = np.arange(len(SEASONS_ORDER))\n",
    "    n_sources = len(frac_cols)\n",
    "    width = 0.15\n",
    "    \n",
    "    for i, col in enumerate(frac_cols):\n",
    "        source_key = col.replace('_frac', '')\n",
    "        means = []\n",
    "        stds = []\n",
    "        for season in SEASONS_ORDER:\n",
    "            season_data = valid[valid['Ethiopian_Season'] == season][col]\n",
    "            means.append(season_data.mean() if len(season_data) > 0 else 0)\n",
    "            stds.append(season_data.std() if len(season_data) > 1 else 0)\n",
    "        \n",
    "        offset = (i - n_sources/2 + 0.5) * width\n",
    "        ax.bar(x + offset, means, width, yerr=stds, capsize=2,\n",
    "               color=SOURCE_CATEGORIES[source_key]['color'],\n",
    "               label=SOURCE_CATEGORIES[source_key]['label'],\n",
    "               edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Ethiopian Season', fontsize=11)\n",
    "    ax.set_ylabel('Mean Fraction', fontsize=11)\n",
    "    ax.set_title('Source Contributions by Season', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([s.replace(' Season', '') for s in SEASONS_ORDER], rotation=15)\n",
    "    ax.legend(fontsize=8, loc='upper right')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_dominant_source_timeseries(df):\n",
    "    \"\"\"\n",
    "    Time series showing which source is dominant each day.\n",
    "    \"\"\"\n",
    "    valid = df.dropna(subset=['dominant_source', 'dominant_fraction']).copy()\n",
    "    valid = valid.sort_values('date')\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 8), sharex=True,\n",
    "                              gridspec_kw={'height_ratios': [2, 1]})\n",
    "    \n",
    "    # Panel 1: Dominant fraction colored by source\n",
    "    ax = axes[0]\n",
    "    for source in SOURCE_ORDER:\n",
    "        mask = valid['dominant_source'] == source\n",
    "        if mask.sum() > 0:\n",
    "            ax.scatter(valid.loc[mask, 'date'], valid.loc[mask, 'dominant_fraction'],\n",
    "                      s=50, alpha=0.7, color=SOURCE_CATEGORIES[source]['color'],\n",
    "                      marker=SOURCE_CATEGORIES[source]['marker'],\n",
    "                      label=SOURCE_CATEGORIES[source]['label'],\n",
    "                      edgecolors='black', linewidth=0.3)\n",
    "    \n",
    "    ax.axhline(0.5, color='red', linestyle='--', linewidth=1, alpha=0.5, label='50% threshold')\n",
    "    ax.set_ylabel('Dominant Source Fraction', fontsize=11)\n",
    "    ax.set_title('Dominant Source Time Series', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=8, loc='upper right', ncol=2)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Panel 2: Source category (categorical)\n",
    "    ax = axes[1]\n",
    "    source_map = {s: i for i, s in enumerate(SOURCE_ORDER)}\n",
    "    valid['source_idx'] = valid['dominant_source'].map(source_map)\n",
    "    \n",
    "    for source in SOURCE_ORDER:\n",
    "        mask = valid['dominant_source'] == source\n",
    "        if mask.sum() > 0:\n",
    "            ax.scatter(valid.loc[mask, 'date'], valid.loc[mask, 'source_idx'],\n",
    "                      s=40, alpha=0.8, color=SOURCE_CATEGORIES[source]['color'],\n",
    "                      marker='|')\n",
    "    \n",
    "    ax.set_yticks(range(len(SOURCE_ORDER)))\n",
    "    ax.set_yticklabels([SOURCE_CATEGORIES[s]['label'] for s in SOURCE_ORDER], fontsize=9)\n",
    "    ax.set_xlabel('Date', fontsize=11)\n",
    "    ax.set_ylabel('Dominant Source', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TASK 5: SOURCE CONTRIBUTION VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Daily bar chart\n",
    "fig = plot_source_contributions_bars(df)\n",
    "if fig:\n",
    "    plt.savefig(os.path.join(dirs['plots'], 'source_contributions_daily.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Summary plots\n",
    "fig = plot_source_contributions_summary(df)\n",
    "plt.savefig(os.path.join(dirs['plots'], 'source_contributions_summary.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Dominant source time series\n",
    "fig = plot_dominant_source_timeseries(df)\n",
    "plt.savefig(os.path.join(dirs['plots'], 'dominant_source_timeseries.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print verification stats\n",
    "print(\"\\nSource Contribution Verification (check against Naveed's plot):\")\n",
    "print(\"=\" * 60)\n",
    "frac_cols = ['charcoal_frac', 'wood_frac', 'fossil_fuel_frac', \n",
    "             'polluted_marine_frac', 'sea_salt_frac']\n",
    "for col in frac_cols:\n",
    "    if col in df.columns:\n",
    "        vals = df[col].dropna()\n",
    "        print(f\"  {col}: mean={vals.mean():.3f}, median={vals.median():.3f}, \"\n",
    "              f\"min={vals.min():.3f}, max={vals.max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary Table: All Regression Results\n",
    "\n",
    "Compile results from all analyses into a comprehensive table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_results_table(results_dict):\n",
    "    \"\"\"\n",
    "    Compile all regression results into a summary table.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for analysis_name, results in results_dict.items():\n",
    "        if isinstance(results, dict):\n",
    "            if 'slope' in results:\n",
    "                # Single result\n",
    "                rows.append({\n",
    "                    'Analysis': analysis_name,\n",
    "                    'n': results.get('n', ''),\n",
    "                    'Slope': f\"{results.get('slope', 0):.3f}\",\n",
    "                    'Intercept': f\"{results.get('intercept', 0):.3f}\",\n",
    "                    'R²': f\"{results.get('r_squared', 0):.3f}\",\n",
    "                    'p-value': f\"{results.get('p_value', 1):.2e}\"\n",
    "                })\n",
    "            else:\n",
    "                # Multiple results (by source)\n",
    "                for sub_name, sub_results in results.items():\n",
    "                    if isinstance(sub_results, dict) and 'slope' in sub_results:\n",
    "                        rows.append({\n",
    "                            'Analysis': f\"{analysis_name} - {sub_name}\",\n",
    "                            'n': sub_results.get('n', ''),\n",
    "                            'Slope': f\"{sub_results.get('slope', 0):.3f}\",\n",
    "                            'Intercept': f\"{sub_results.get('intercept', 0):.3f}\",\n",
    "                            'R²': f\"{sub_results.get('r_squared', 0):.3f}\",\n",
    "                            'p-value': f\"{sub_results.get('p_value', 1):.2e}\"\n",
    "                        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Collect all results\n",
    "all_results = {\n",
    "    'HIPS vs EC (All)': results if 'results' in dir() else {},\n",
    "    'HIPS vs EC by Source': source_results if 'source_results' in dir() else {},\n",
    "    'Aeth IR vs EC (All)': results_ir if 'results_ir' in dir() else {},\n",
    "    'Aeth IR vs EC by Source': ir_source_results if 'ir_source_results' in dir() else {},\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SUMMARY: ALL REGRESSION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# summary_df = compile_results_table(all_results)\n",
    "# if len(summary_df) > 0:\n",
    "#     print(summary_df.to_string(index=False))\n",
    "    \n",
    "# Better summary approach\n",
    "print(\"\\nMethod Comparison Summary:\")\n",
    "print(\"-\" * 70)\n",
    "comparisons = [\n",
    "    ('HIPS vs EC', 'hips_fabs', 'ftir_ec'),\n",
    "    ('Aeth IR vs EC', 'ir_bcc', 'ftir_ec'),\n",
    "    ('Aeth IR vs HIPS', 'ir_bcc', 'hips_fabs'),\n",
    "]\n",
    "\n",
    "for label, y_col, x_col in comparisons:\n",
    "    valid = df[[x_col, y_col]].dropna()\n",
    "    if len(valid) >= 3:\n",
    "        slope, intercept, r, p, se = stats.linregress(valid[x_col], valid[y_col])\n",
    "        print(f\"\\n{label}:\")\n",
    "        print(f\"  n = {len(valid)}\")\n",
    "        print(f\"  Slope = {slope:.3f}\")\n",
    "        print(f\"  R² = {r**2:.3f}\")\n",
    "        print(f\"  p = {p:.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Export Data\n",
    "\n",
    "Save processed data for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged dataset\n",
    "output_path = os.path.join(dirs['data'], 'bc_ec_source_merged.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved merged dataset to: {output_path}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats = []\n",
    "for col in ['ftir_ec', 'hips_fabs', 'ir_bcc', 'uv_bcc']:\n",
    "    if col in df.columns:\n",
    "        vals = df[col].dropna()\n",
    "        if len(vals) > 0:\n",
    "            summary_stats.append({\n",
    "                'Variable': col,\n",
    "                'n': len(vals),\n",
    "                'Mean': vals.mean(),\n",
    "                'Std': vals.std(),\n",
    "                'Median': vals.median(),\n",
    "                'Min': vals.min(),\n",
    "                'Max': vals.max()\n",
    "            })\n",
    "\n",
    "stats_df = pd.DataFrame(summary_stats)\n",
    "stats_path = os.path.join(dirs['data'], 'bc_ec_summary_stats.csv')\n",
    "stats_df.to_csv(stats_path, index=False)\n",
    "print(f\"Saved summary statistics to: {stats_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPlots saved to: {dirs['plots']}\")\n",
    "print(f\"Data saved to: {dirs['data']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Appendix: Data Flow\n\n## How data is loaded and merged:\n\n1. **`load_etad_factors_with_filter_ids()`** loads both CSVs and joins on `oldDate`:\n   - `ETAD Factor Contributions .csv` (PMF fractions GF1-GF5 + concentrations K_F1-K_F5)\n   - `ETAD Filter ID.csv` (maps dates to FilterId like `ETAD-0035-3`)\n   - Produces `base_filter_id` (e.g., `ETAD-0035`) for joining to unified dataset\n\n2. **`match_all_parameters()`** loads FTIR EC, HIPS Fabs, and Aethalometer BC from the\n   unified filter dataset, matched by date\n\n3. **Final merge** joins BC/EC measurements to factor contributions on `base_filter_id`\n\n## Key parameters:\n- `DOMINANCE_THRESHOLDS`: List of thresholds to test (default: 30%, 40%, 50%, 60%)\n- `MAC_VALUE`: Mass absorption coefficient for HIPS conversion (default: 10 m²/g)"
  }
 ]
}